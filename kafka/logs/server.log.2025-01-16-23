[2025-01-16 22:15:57,669] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,669] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,669] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,669] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,669] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,669] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,686] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:15:57,687] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:15:57,687] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:15:57,687] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-16 22:15:57,689] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-16 22:15:57,690] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,691] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,691] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,691] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,691] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,691] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:15:57,691] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-16 22:15:57,704] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@9353778 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-16 22:15:57,708] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-16 22:15:57,708] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-16 22:15:57,711] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:15:57,719] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,720] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,720] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,721] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,721] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,721] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,721] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,722] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,722] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,722] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,724] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,724] INFO Server environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,724] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,725] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,726] INFO Server environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,726] INFO Server environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,730] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,730] INFO Server environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,730] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,730] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,730] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,735] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,735] INFO Server environment:user.name=mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,735] INFO Server environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,735] INFO Server environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,735] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,736] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,736] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,736] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,737] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,737] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,737] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,738] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,738] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,738] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,740] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-16 22:15:57,740] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,740] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,744] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-16 22:15:57,744] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-16 22:15:57,745] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:15:57,745] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:15:57,745] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:15:57,746] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:15:57,746] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:15:57,746] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:15:57,748] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,748] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,749] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-16 22:15:57,749] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-16 22:15:57,749] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir \tmp\zookeeper\version-2 snapdir \tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,755] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-16 22:15:57,756] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-16 22:15:57,759] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-16 22:15:57,792] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-16 22:15:57,810] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-16 22:15:57,811] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-16 22:15:57,811] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:15:57,811] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:15:57,815] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-16 22:15:57,816] INFO Snapshotting: 0x0 to \tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:15:57,821] INFO Snapshot loaded in 10 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:15:57,822] INFO Snapshotting: 0x0 to \tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:15:57,823] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:15:57,833] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-16 22:15:57,833] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-16 22:15:57,847] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-16 22:15:57,847] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-16 22:16:05,137] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:16:05,319] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:16:05,394] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:16:05,394] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:16:05,415] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:05,419] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,419] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,419] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,419] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,420] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,420] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,426] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,428] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,428] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,428] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,429] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,429] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,429] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,429] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,429] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,430] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,430] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,430] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,432] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:05,462] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:16:05,468] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:05,470] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:05,471] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:05,473] INFO Socket connection established, initiating session, client: /127.0.0.1:61120, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:05,480] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-16 22:16:05,490] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100049b1bfd0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:05,493] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:05,709] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:16:05,747] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:16:05,796] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:05,796] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:05,797] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:05,799] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:05,804] INFO [KafkaServer id=0] Rewriting ./tmp/kafka-logs\meta.properties (kafka.server.KafkaServer)
[2025-01-16 22:16:05,862] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:16:05,868] INFO No logs found to be loaded in D:\DA_project\kafka\.\tmp\kafka-logs (kafka.log.LogManager)
[2025-01-16 22:16:05,879] INFO Loaded 0 logs in 16ms (kafka.log.LogManager)
[2025-01-16 22:16:05,881] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:16:05,881] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:16:05,946] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:16:05,957] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:16:05,965] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2025-01-16 22:16:05,984] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:06,266] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:16:06,288] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:16:06,293] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:06,314] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,315] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,316] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,317] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,318] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,334] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:16:06,334] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:16:06,353] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:06,374] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1737040566366,1737040566366,1,0,0,72062658273935360,202,0,25
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:06,376] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:06,417] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,427] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,428] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,429] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:06,442] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:16:06,442] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2025-01-16 22:16:06,450] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:16:06,470] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:16:06,472] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:16:06,473] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:16:06,473] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:16:06,511] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:06,526] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:06,530] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:06,533] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:06,559] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:16:06,569] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:16:06,572] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:16:06,574] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:16:06,575] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:16:06,575] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:16:06,576] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:16:06,579] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:06,580] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:06,580] INFO Kafka startTimeMs: 1737040566576 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:06,582] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:16:06,738] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:06,753] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:10,973] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:16:11,157] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:16:11,233] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:16:11,234] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:16:11,255] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:11,260] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,261] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,261] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,262] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,262] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,262] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,270] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,272] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,272] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,273] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,273] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,273] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,274] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,274] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,274] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,275] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,275] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,275] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,277] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:11,308] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:16:11,313] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:11,315] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:11,316] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:11,318] INFO Socket connection established, initiating session, client: /127.0.0.1:61124, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:11,324] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100049b1bfd0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:11,327] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:11,497] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:16:11,538] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:16:11,593] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:11,594] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:11,594] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:11,596] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:11,601] INFO [KafkaServer id=1] Rewriting ./tmp/kafka-logs1\meta.properties (kafka.server.KafkaServer)
[2025-01-16 22:16:11,659] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:16:11,664] INFO No logs found to be loaded in D:\DA_project\kafka\.\tmp\kafka-logs1 (kafka.log.LogManager)
[2025-01-16 22:16:11,673] INFO Loaded 0 logs in 13ms (kafka.log.LogManager)
[2025-01-16 22:16:11,675] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:16:11,676] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:16:11,737] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:16:11,751] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:16:11,763] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:16:11,781] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:12,060] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:16:12,085] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:16:12,090] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:12,109] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,110] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,110] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,111] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,112] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,126] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:16:12,126] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:16:12,176] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:12,193] INFO Stat of the created znode at /brokers/ids/1 is: 45,45,1737040572187,1737040572187,1,0,0,72062658273935361,202,0,45
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:12,194] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 45 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:12,201] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:12,201] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:12,202] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:12,235] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,246] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,246] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,261] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:16:12,265] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:16:12,280] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:16:12,283] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:16:12,283] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:16:12,316] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:12,317] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:12,318] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:12,319] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:12,347] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:16:12,355] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:16:12,357] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:16:12,360] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:16:12,360] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:16:12,361] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:16:12,362] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:16:12,365] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:12,365] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:12,366] INFO Kafka startTimeMs: 1737040572362 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:12,368] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:16:12,537] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:12,551] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:17,044] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:16:17,226] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:16:17,305] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:16:17,306] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:16:17,328] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:17,332] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,333] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,333] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,334] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,334] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,335] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,348] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,351] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,352] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,352] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,352] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,353] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,353] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,354] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,354] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,354] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,355] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,355] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,357] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:16:17,387] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:16:17,393] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:17,394] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:17,396] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:17,398] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61129, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:17,404] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100049b1bfd0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:16:17,407] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:16:17,578] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:16:17,617] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:16:17,682] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:17,683] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:17,683] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:17,685] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:16:17,690] INFO [KafkaServer id=2] Rewriting ./tmp/kafka-logs2\meta.properties (kafka.server.KafkaServer)
[2025-01-16 22:16:17,753] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:16:17,759] INFO No logs found to be loaded in D:\DA_project\kafka\.\tmp\kafka-logs2 (kafka.log.LogManager)
[2025-01-16 22:16:17,768] INFO Loaded 0 logs in 14ms (kafka.log.LogManager)
[2025-01-16 22:16:17,770] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:16:17,771] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:16:17,836] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:16:17,852] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:16:17,864] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:16:17,884] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:18,182] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:16:18,208] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:16:18,213] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:18,232] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,233] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,234] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,235] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,235] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,249] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:16:18,250] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:16:18,296] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:18,310] INFO Stat of the created znode at /brokers/ids/2 is: 61,61,1737040578306,1737040578306,1,0,0,72062658273935362,202,0,61
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:18,312] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 61 (kafka.zk.KafkaZkClient)
[2025-01-16 22:16:18,315] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:18,316] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:18,317] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:18,356] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,365] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,366] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,379] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:16:18,383] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:16:18,397] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:16:18,399] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:16:18,399] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:16:18,432] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:16:18,433] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:18,434] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:18,435] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:16:18,453] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:16:18,459] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:16:18,461] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:16:18,463] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:16:18,464] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:16:18,464] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:16:18,465] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:16:18,468] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:18,469] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:18,469] INFO Kafka startTimeMs: 1737040578465 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:16:18,471] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:16:18,635] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:16:18,649] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:17:37,129] INFO Creating topic kafka-chat with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 0), 1 -> ArrayBuffer(0, 2), 2 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[2025-01-16 22:17:37,197] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,198] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,199] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,258] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:17:37,259] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:17:37,264] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:17:37,272] INFO Created log for partition kafka-chat-2 in D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2 with properties {} (kafka.log.LogManager)
[2025-01-16 22:17:37,272] INFO Created log for partition kafka-chat-1 in D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1 with properties {} (kafka.log.LogManager)
[2025-01-16 22:17:37,275] INFO [Partition kafka-chat-1 broker=0] No checkpointed highwatermark is found for partition kafka-chat-1 (kafka.cluster.Partition)
[2025-01-16 22:17:37,275] INFO [Partition kafka-chat-2 broker=2] No checkpointed highwatermark is found for partition kafka-chat-2 (kafka.cluster.Partition)
[2025-01-16 22:17:37,276] INFO Created log for partition kafka-chat-0 in D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0 with properties {} (kafka.log.LogManager)
[2025-01-16 22:17:37,278] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,278] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,280] INFO [Partition kafka-chat-0 broker=1] No checkpointed highwatermark is found for partition kafka-chat-0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,282] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,298] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:17:37,299] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:17:37,300] INFO Created log for partition kafka-chat-0 in D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 with properties {} (kafka.log.LogManager)
[2025-01-16 22:17:37,300] INFO Created log for partition kafka-chat-1 in D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1 with properties {} (kafka.log.LogManager)
[2025-01-16 22:17:37,301] INFO [Partition kafka-chat-0 broker=0] No checkpointed highwatermark is found for partition kafka-chat-0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,301] INFO [Partition kafka-chat-1 broker=2] No checkpointed highwatermark is found for partition kafka-chat-1 (kafka.cluster.Partition)
[2025-01-16 22:17:37,302] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,302] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,303] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:17:37,304] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,304] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,305] INFO Created log for partition kafka-chat-2 in D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2 with properties {} (kafka.log.LogManager)
[2025-01-16 22:17:37,306] INFO [Partition kafka-chat-2 broker=1] No checkpointed highwatermark is found for partition kafka-chat-2 (kafka.cluster.Partition)
[2025-01-16 22:17:37,306] INFO [Partition kafka-chat-2 broker=1] Log loaded for partition kafka-chat-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:17:37,309] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,326] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,326] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,328] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,329] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,330] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition kafka-chat-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,331] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition kafka-chat-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,332] INFO [UnifiedLog partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-01-16 22:17:37,332] INFO [UnifiedLog partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-01-16 22:17:37,335] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,338] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=2, host=127.0.0.1:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:17:37,341] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition kafka-chat-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,343] INFO [UnifiedLog partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-01-16 22:17:37,388] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition kafka-chat-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:17:37,390] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition kafka-chat-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,038] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:20:49,041] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:20:49,066] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,066] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,071] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,072] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,073] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 375 due to node 2 being disconnected (elapsed time since creation: 147ms, elapsed time since send: 147ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,076] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=231175556, epoch=375) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:20:49,082] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,082] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,082] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,083] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:20:49,086] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,089] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,089] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 40ms (kafka.server.KafkaServer)
[2025-01-16 22:20:49,091] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,093] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 375 due to node 0 being disconnected (elapsed time since creation: 184ms, elapsed time since send: 184ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,095] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=316734914, epoch=373) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:20:49,096] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:20:49,102] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,102] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:20:49,103] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:20:49,103] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:20:49,107] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,108] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:20:49,108] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:20:49,114] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,115] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 7 due to node 2 being disconnected (elapsed time since creation: 21ms, elapsed time since send: 21ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,116] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:20:49,117] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:20:49,117] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,119] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:20:49,120] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,121] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,121] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,123] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:20:49,124] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,124] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,124] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,126] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:20:49,127] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:20:49,128] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:20:49,128] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:20:49,128] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:20:49,130] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:20:49,130] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:20:49,131] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,131] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,131] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,132] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,133] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,133] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,134] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:20:49,134] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:20:49,135] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:20:49,136] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:20:49,136] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:20:49,137] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,138] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:20:49,138] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:20:49,139] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:20:49,139] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,140] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,140] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,140] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,141] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,141] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,142] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,142] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,142] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,143] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,143] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,143] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,144] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,145] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,145] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:20:49,149] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:20:49,149] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:20:49,149] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:20:49,151] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:20:49,152] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:20:49,152] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:20:49,152] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:20:49,154] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:20:49,155] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:20:49,155] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:20:49,155] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:20:49,156] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:20:49,157] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:20:49,158] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:20:49,159] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:20:49,159] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:20:49,169] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:20:49,178] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 1 with 0 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:20:49,206] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:20:49,211] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:20:49,212] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:20:49,212] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:20:49,213] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:20:49,220] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:20:49,326] INFO Session: 0x100049b1bfd0002 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:20:49,326] INFO EventThread shut down for session: 0x100049b1bfd0002 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:20:49,330] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:20:49,333] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,339] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,339] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,343] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,345] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,345] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,347] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,348] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,348] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,348] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,349] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,349] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:20:49,350] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:20:49,363] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:20:49,364] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:20:49,365] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:20:49,366] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:20:49,368] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:20:49,370] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:20:49,371] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:21:40,941] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:21:41,125] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:21:41,200] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:21:41,201] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:21:41,221] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:21:41,226] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,227] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,228] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,228] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,229] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,229] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,241] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,244] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,245] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,245] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,246] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,246] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,246] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,247] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,247] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,247] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,247] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,248] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,250] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:41,279] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:21:41,285] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:21:41,286] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:21:41,287] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:21:41,290] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61216, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:21:41,296] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100049b1bfd0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:21:41,299] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:21:41,460] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:21:41,497] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:21:41,557] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:41,558] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:41,558] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:41,561] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:41,602] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:21:41,613] INFO Skipping recovery of 2 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:21:41,669] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:21:41,670] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2025-01-16 22:21:41,671] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:21:41,677] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2025-01-16 22:21:41,688] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 70ms (1/2 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:21:41,694] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:21:41,696] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-01-16 22:21:41,696] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:21:41,697] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-01-16 22:21:41,699] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 9ms (2/2 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:21:41,703] INFO Loaded 2 logs in 99ms (kafka.log.LogManager)
[2025-01-16 22:21:41,705] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:21:41,706] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:21:41,768] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:21:41,786] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:21:41,802] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:21:41,824] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:42,152] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:21:42,169] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:21:42,175] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:42,193] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,194] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,195] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,196] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,197] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,210] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:21:42,211] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:21:42,250] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:21:42,264] INFO Stat of the created znode at /brokers/ids/2 is: 90,90,1737040902257,1737040902257,1,0,0,72062658273935363,202,0,90
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:21:42,265] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 90 (kafka.zk.KafkaZkClient)
[2025-01-16 22:21:42,267] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:42,268] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:42,269] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:42,306] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,313] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,314] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,326] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:21:42,330] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:21:42,345] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:21:42,348] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:21:42,348] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:21:42,378] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:42,379] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:42,380] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:42,385] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:42,415] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:21:42,434] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:21:42,437] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:21:42,440] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:21:42,440] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:21:42,441] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:21:42,442] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:21:42,446] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:21:42,447] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:21:42,447] INFO Kafka startTimeMs: 1737040902443 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:21:42,448] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:21:42,559] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 3 (kafka.cluster.Partition)
[2025-01-16 22:21:42,561] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 1 (kafka.cluster.Partition)
[2025-01-16 22:21:42,563] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:42,582] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:42,584] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),1,3)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:42,588] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),1,1)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:42,588] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:42,592] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:42,607] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:42,645] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,2  and version updated to 2 (kafka.cluster.Partition)
[2025-01-16 22:21:42,652] INFO [Partition kafka-chat-2 broker=1] ISR updated to 1,2  and version updated to 2 (kafka.cluster.Partition)
[2025-01-16 22:21:44,340] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:21:44,345] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:21:44,357] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:44,357] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:44,358] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)
[2025-01-16 22:21:44,361] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:44,362] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:44,363] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:21:44,364] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:44,364] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:21:44,364] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:21:44,365] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 484 due to node 1 being disconnected (elapsed time since creation: 513ms, elapsed time since send: 513ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:21:44,366] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:21:44,366] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=467654335, epoch=482) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:21:44,371] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:44,371] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:44,375] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:21:44,376] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:21:44,378] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:44,380] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:44,380] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:21:44,380] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:21:44,383] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,384] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,384] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,387] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:21:44,389] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,390] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,390] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,393] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:21:44,395] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:21:44,395] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:21:44,396] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:21:44,396] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:21:44,398] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:21:44,399] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:21:44,400] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,401] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,401] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,402] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,402] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,402] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,404] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:21:44,404] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:21:44,405] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:21:44,405] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:21:44,405] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:21:44,406] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:44,407] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:21:44,409] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:21:44,410] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:21:44,410] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,410] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,410] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,411] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,412] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,412] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,412] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,413] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,413] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,414] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,414] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,414] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,415] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,415] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,415] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:21:44,419] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:21:44,420] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:21:44,420] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:21:44,421] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:21:44,421] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:44,422] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:44,422] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:44,423] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:21:44,424] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:44,425] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:44,425] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:21:44,426] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:21:44,427] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:21:44,428] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:21:44,428] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:21:44,428] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:21:44,438] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 10 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:21:44,449] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 38 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:21:44,477] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:21:44,481] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:21:44,482] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:21:44,482] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:21:44,483] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:21:44,590] INFO Session: 0x100049b1bfd0001 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:21:44,590] INFO EventThread shut down for session: 0x100049b1bfd0001 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:21:44,594] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:21:44,597] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,603] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,603] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,608] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,609] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,609] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,610] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,611] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,611] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,612] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,612] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,612] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:21:44,613] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:21:44,624] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:21:44,625] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:21:44,626] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:21:44,627] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:21:44,629] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:21:44,630] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:21:44,631] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:22:34,906] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:22:35,084] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:22:35,159] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:22:35,160] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:22:35,182] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:22:35,188] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,189] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,189] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,190] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,190] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,190] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,201] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,204] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,204] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,205] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,205] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,205] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,206] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,206] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,206] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,206] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,206] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,207] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,209] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:35,238] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:22:35,244] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:22:35,245] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:22:35,246] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:22:35,248] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61245, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:22:35,253] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100049b1bfd0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:22:35,256] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:22:35,415] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:22:35,453] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:22:35,510] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:35,511] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:35,511] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:35,513] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:35,552] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:22:35,563] INFO Skipping recovery of 2 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:22:35,621] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 38 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:22:35,623] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 38 (kafka.log.UnifiedLog$)
[2025-01-16 22:22:35,623] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=38, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000038.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:22:35,629] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 38 (kafka.log.UnifiedLog$)
[2025-01-16 22:22:35,641] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=38) with 1 segments, local-log-start-offset 0 and log-end-offset 38 in 72ms (1/2 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:22:35,647] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 10 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:22:35,648] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 10 (kafka.log.UnifiedLog$)
[2025-01-16 22:22:35,649] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=10, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000010.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:22:35,650] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 10 (kafka.log.UnifiedLog$)
[2025-01-16 22:22:35,652] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=10) with 1 segments, local-log-start-offset 0 and log-end-offset 10 in 9ms (2/2 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:22:35,655] INFO Loaded 2 logs in 102ms (kafka.log.LogManager)
[2025-01-16 22:22:35,658] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:22:35,659] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:22:35,722] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:22:35,737] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:22:35,753] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:22:35,776] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:36,085] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:22:36,103] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:22:36,108] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:36,126] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,127] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,127] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,128] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,129] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,141] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:22:36,141] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:22:36,183] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:22:36,197] INFO Stat of the created znode at /brokers/ids/1 is: 111,111,1737040956191,1737040956191,1,0,0,72062658273935364,202,0,111
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:22:36,199] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 111 (kafka.zk.KafkaZkClient)
[2025-01-16 22:22:36,200] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:36,201] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:36,202] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:36,240] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,246] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,246] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,258] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:22:36,261] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:22:36,275] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:22:36,278] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:22:36,278] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:22:36,313] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:36,317] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:36,318] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:36,319] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:36,340] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:22:36,361] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:22:36,363] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:22:36,365] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:22:36,366] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:22:36,366] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:22:36,367] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:22:36,373] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:22:36,373] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:22:36,373] INFO Kafka startTimeMs: 1737040956368 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:22:36,375] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:22:36,489] INFO [Partition kafka-chat-2 broker=1] Log loaded for partition kafka-chat-2 with initial high watermark 10 (kafka.cluster.Partition)
[2025-01-16 22:22:36,491] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 38 (kafka.cluster.Partition)
[2025-01-16 22:22:36,492] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:36,512] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:36,514] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=2, host=127.0.0.1:9094),2,10)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:36,518] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),1,38)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:36,518] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:36,533] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:36,533] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:36,553] INFO [Partition kafka-chat-0 broker=0] ISR updated to 0,1  and version updated to 2 (kafka.cluster.Partition)
[2025-01-16 22:22:36,565] INFO [Partition kafka-chat-2 broker=2] ISR updated to 2,1  and version updated to 4 (kafka.cluster.Partition)
[2025-01-16 22:22:54,896] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:22:54,897] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:22:54,898] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:54,898] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 0ms (kafka.server.KafkaServer)
[2025-01-16 22:22:54,910] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:54,912] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:22:54,912] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:54,913] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:22:54,913] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:54,913] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:22:54,915] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:54,915] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:22:54,915] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:54,916] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:54,921] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:22:54,924] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:22:54,925] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:22:54,928] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:22:54,930] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,931] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,931] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,931] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:54,934] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:22:54,932] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:54,932] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:22:54,934] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,934] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,934] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,937] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:22:54,940] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:22:54,940] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:22:54,941] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:22:54,941] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:22:54,942] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:22:54,943] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:22:54,943] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,944] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,944] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,945] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,945] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,945] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,946] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:22:54,947] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:22:54,947] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:22:54,948] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:22:54,948] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:22:54,949] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:54,949] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:22:54,951] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:22:54,952] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:22:54,952] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,952] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,952] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,953] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,953] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,953] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,954] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,955] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,955] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,955] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,956] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,956] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,956] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,956] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,956] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:22:54,957] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:22:54,957] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:22:54,957] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:22:54,962] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:22:54,963] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:54,963] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:54,963] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:54,965] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:22:54,965] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:54,965] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:54,965] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:22:54,967] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:22:54,967] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:22:54,967] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:22:54,967] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:22:54,967] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:22:54,975] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 61 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:22:54,986] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 24 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:22:55,005] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:22:55,022] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:22:55,023] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:22:55,023] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:22:55,024] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:22:55,130] INFO Session: 0x100049b1bfd0000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:22:55,130] INFO EventThread shut down for session: 0x100049b1bfd0000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:22:55,132] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:22:55,133] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,134] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,134] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,135] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,135] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,135] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,136] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,136] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,136] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,136] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,137] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,137] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:22:55,138] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:22:55,145] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:22:55,145] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:22:55,146] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:22:55,146] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:22:55,147] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:22:55,148] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:22:55,148] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:23:10,314] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:23:10,487] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:23:10,561] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:23:10,563] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:23:10,586] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:23:10,591] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,591] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,592] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,592] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,592] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,592] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,604] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,607] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,607] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,608] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,608] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,608] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,608] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,609] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,609] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,609] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,609] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,610] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,612] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:23:10,644] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:23:10,650] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:23:10,652] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:23:10,652] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:23:10,655] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61268, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:23:10,659] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100049b1bfd0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:23:10,661] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:23:10,822] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:23:10,864] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:23:10,922] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:23:10,923] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:23:10,923] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:23:10,925] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:23:10,964] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:23:10,977] INFO Skipping recovery of 2 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:23:11,036] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 61 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:23:11,038] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 61 (kafka.log.UnifiedLog$)
[2025-01-16 22:23:11,039] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=61, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000061.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:23:11,045] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 61 (kafka.log.UnifiedLog$)
[2025-01-16 22:23:11,056] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=61) with 1 segments, local-log-start-offset 0 and log-end-offset 61 in 74ms (1/2 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:23:11,062] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:23:11,063] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 24 (kafka.log.UnifiedLog$)
[2025-01-16 22:23:11,064] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=24, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000024.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:23:11,065] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 24 (kafka.log.UnifiedLog$)
[2025-01-16 22:23:11,067] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=24) with 1 segments, local-log-start-offset 0 and log-end-offset 24 in 10ms (2/2 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:23:11,070] INFO Loaded 2 logs in 105ms (kafka.log.LogManager)
[2025-01-16 22:23:11,072] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:23:11,073] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:23:11,134] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:23:11,149] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:23:11,165] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:23:11,187] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:23:11,509] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:23:11,529] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:23:11,535] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:23:11,552] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,553] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,554] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,554] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,555] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,567] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:23:11,568] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:23:11,608] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:23:11,621] INFO Stat of the created znode at /brokers/ids/0 is: 135,135,1737040991616,1737040991616,1,0,0,72062658273935365,202,0,135
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:23:11,623] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 135 (kafka.zk.KafkaZkClient)
[2025-01-16 22:23:11,627] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,628] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,631] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,662] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,670] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,671] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,684] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:23:11,688] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:23:11,702] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:23:11,704] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:23:11,704] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:23:11,738] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:23:11,740] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,741] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,742] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,764] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:23:11,782] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:23:11,785] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:23:11,789] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:23:11,790] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:23:11,791] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:23:11,791] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:23:11,797] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:23:11,797] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:23:11,798] INFO Kafka startTimeMs: 1737040991793 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:23:11,800] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:23:11,925] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 24 (kafka.cluster.Partition)
[2025-01-16 22:23:11,927] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 61 (kafka.cluster.Partition)
[2025-01-16 22:23:11,929] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:23:11,947] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:23:11,949] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=2, host=127.0.0.1:9094),2,24)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:23:11,953] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),2,61)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:23:11,954] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:23:11,960] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:23:11,976] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:23:11,993] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:11,994] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:23:11,999] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:23:12,002] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:23:12,012] INFO [Partition kafka-chat-1 broker=2] ISR updated to 2,0  and version updated to 4 (kafka.cluster.Partition)
[2025-01-16 22:23:12,019] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,0  and version updated to 4 (kafka.cluster.Partition)
[2025-01-16 22:25:43,595] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(2), 2 -> ArrayBuffer(1), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(2), 5 -> ArrayBuffer(1), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(2), 8 -> ArrayBuffer(1), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(2), 11 -> ArrayBuffer(1), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(2), 14 -> ArrayBuffer(1), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(2), 17 -> ArrayBuffer(1), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(2), 20 -> ArrayBuffer(1), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(2), 23 -> ArrayBuffer(1), 24 -> ArrayBuffer(0), 25 -> ArrayBuffer(2), 26 -> ArrayBuffer(1), 27 -> ArrayBuffer(0), 28 -> ArrayBuffer(2), 29 -> ArrayBuffer(1), 30 -> ArrayBuffer(0), 31 -> ArrayBuffer(2), 32 -> ArrayBuffer(1), 33 -> ArrayBuffer(0), 34 -> ArrayBuffer(2), 35 -> ArrayBuffer(1), 36 -> ArrayBuffer(0), 37 -> ArrayBuffer(2), 38 -> ArrayBuffer(1), 39 -> ArrayBuffer(0), 40 -> ArrayBuffer(2), 41 -> ArrayBuffer(1), 42 -> ArrayBuffer(0), 43 -> ArrayBuffer(2), 44 -> ArrayBuffer(1), 45 -> ArrayBuffer(0), 46 -> ArrayBuffer(2), 47 -> ArrayBuffer(1), 48 -> ArrayBuffer(0), 49 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2025-01-16 22:25:43,687] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:25:43,687] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:25:43,691] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:25:43,699] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,699] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,704] INFO Created log for partition __consumer_offsets-37 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,704] INFO Created log for partition __consumer_offsets-35 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,706] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-01-16 22:25:43,706] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-01-16 22:25:43,706] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,706] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,711] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,716] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,716] INFO Created log for partition __consumer_offsets-3 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,718] INFO Created log for partition __consumer_offsets-7 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,718] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-01-16 22:25:43,719] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-01-16 22:25:43,719] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,720] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,720] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,721] INFO Created log for partition __consumer_offsets-5 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,722] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-01-16 22:25:43,723] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,733] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,735] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,735] INFO Created log for partition __consumer_offsets-22 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,736] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-01-16 22:25:43,737] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,737] INFO Created log for partition __consumer_offsets-20 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,737] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,738] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-01-16 22:25:43,738] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,738] INFO Created log for partition __consumer_offsets-18 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,740] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-01-16 22:25:43,740] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,749] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,749] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,750] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,751] INFO Created log for partition __consumer_offsets-41 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,751] INFO Created log for partition __consumer_offsets-10 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,752] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-01-16 22:25:43,752] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-01-16 22:25:43,752] INFO Created log for partition __consumer_offsets-39 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,753] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,753] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,753] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-01-16 22:25:43,754] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,793] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,794] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,795] INFO Created log for partition __consumer_offsets-31 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,796] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-01-16 22:25:43,796] INFO Created log for partition __consumer_offsets-9 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,796] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,797] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-01-16 22:25:43,797] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,800] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,802] INFO Created log for partition __consumer_offsets-29 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,803] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-01-16 22:25:43,804] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,808] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,810] INFO Created log for partition __consumer_offsets-24 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,811] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,811] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-01-16 22:25:43,813] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,813] INFO Created log for partition __consumer_offsets-46 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,815] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-01-16 22:25:43,817] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,819] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,820] INFO Created log for partition __consumer_offsets-44 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,821] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-01-16 22:25:43,822] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,824] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,826] INFO Created log for partition __consumer_offsets-27 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,827] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-01-16 22:25:43,827] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,827] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,828] INFO Created log for partition __consumer_offsets-1 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,829] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-01-16 22:25:43,830] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,833] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,835] INFO Created log for partition __consumer_offsets-14 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,836] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-01-16 22:25:43,836] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,837] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,838] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,839] INFO Created log for partition __consumer_offsets-42 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,839] INFO Created log for partition __consumer_offsets-16 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,840] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-01-16 22:25:43,840] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-01-16 22:25:43,841] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,841] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,844] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,846] INFO Created log for partition __consumer_offsets-2 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,846] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-01-16 22:25:43,847] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,851] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,852] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,853] INFO Created log for partition __consumer_offsets-12 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,854] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-01-16 22:25:43,854] INFO Created log for partition __consumer_offsets-19 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,855] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-01-16 22:25:43,855] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,855] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,856] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,858] INFO Created log for partition __consumer_offsets-23 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,859] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-01-16 22:25:43,859] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,866] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,866] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,866] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,868] INFO Created log for partition __consumer_offsets-34 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,868] INFO Created log for partition __consumer_offsets-33 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,869] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-01-16 22:25:43,869] INFO Created log for partition __consumer_offsets-38 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,869] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-01-16 22:25:43,870] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,870] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-01-16 22:25:43,870] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,870] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,879] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,880] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,881] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,881] INFO Created log for partition __consumer_offsets-8 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,882] INFO Created log for partition __consumer_offsets-48 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,882] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-01-16 22:25:43,883] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-01-16 22:25:43,883] INFO Created log for partition __consumer_offsets-4 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,883] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,883] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-01-16 22:25:43,883] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,884] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,892] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,893] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,893] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,894] INFO Created log for partition __consumer_offsets-11 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,894] INFO Created log for partition __consumer_offsets-25 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,895] INFO Created log for partition __consumer_offsets-21 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,895] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-01-16 22:25:43,895] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-01-16 22:25:43,896] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-01-16 22:25:43,896] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,896] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,896] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,907] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,907] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,908] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,909] INFO Created log for partition __consumer_offsets-40 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,910] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-01-16 22:25:43,909] INFO Created log for partition __consumer_offsets-26 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,910] INFO Created log for partition __consumer_offsets-36 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,910] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,910] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-01-16 22:25:43,911] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-01-16 22:25:43,911] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,912] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,921] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,922] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,923] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,923] INFO Created log for partition __consumer_offsets-43 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,924] INFO Created log for partition __consumer_offsets-47 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,924] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-01-16 22:25:43,924] INFO Created log for partition __consumer_offsets-6 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,925] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-01-16 22:25:43,925] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,925] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-01-16 22:25:43,925] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,926] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,937] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,938] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,938] INFO Created log for partition __consumer_offsets-17 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,939] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-01-16 22:25:43,940] INFO Created log for partition __consumer_offsets-45 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,941] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-01-16 22:25:43,941] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,941] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,944] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,946] INFO Created log for partition __consumer_offsets-13 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,947] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-01-16 22:25:43,948] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,953] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,953] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,955] INFO Created log for partition __consumer_offsets-32 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,956] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-01-16 22:25:43,956] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,956] INFO Created log for partition __consumer_offsets-15 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,957] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-01-16 22:25:43,958] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,958] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,959] INFO Created log for partition __consumer_offsets-28 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,961] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-01-16 22:25:43,962] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,963] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,967] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,970] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,970] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,971] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,975] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,974] INFO Created log for partition __consumer_offsets-30 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,977] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-01-16 22:25:43,979] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,980] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,977] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,979] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 10 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,981] INFO Created log for partition __consumer_offsets-49 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,982] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,983] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-01-16 22:25:43,984] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,983] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,984] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,987] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,988] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,985] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,989] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,991] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,991] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,992] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,992] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,993] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,993] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:25:43,990] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,995] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,995] INFO Created log for partition __consumer_offsets-0 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:25:43,995] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,996] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,996] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,996] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 7 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,997] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,996] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,997] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:25:43,997] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,997] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,999] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,998] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,999] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:43,999] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,000] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:43,999] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,001] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,000] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,002] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,001] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,002] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,002] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,003] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,003] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,003] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,004] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,004] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,005] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,005] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,005] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,005] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,006] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,007] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,007] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,007] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,008] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,008] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,009] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,009] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,008] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,010] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,010] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,010] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,011] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,011] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,009] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,012] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,016] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,013] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,013] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,012] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,018] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,017] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,019] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,017] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,018] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 11 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,019] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,019] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,019] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,019] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,021] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,022] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,021] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,021] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,023] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,021] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,022] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,024] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,022] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,025] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,023] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,025] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,025] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,024] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,027] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,026] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,027] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,028] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,030] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,031] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,028] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,029] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,030] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,032] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 11 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,033] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,034] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,034] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,035] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,035] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,036] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,036] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,038] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,038] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,039] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,039] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,040] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,040] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,041] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,041] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,043] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,042] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,044] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,043] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,044] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,044] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,046] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,045] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,048] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,048] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,050] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,050] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,050] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,052] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,052] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,053] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,054] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,055] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,055] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,057] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,057] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,057] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,059] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,059] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,060] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,062] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:25:44,158] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,196] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,243] INFO [GroupCoordinator 2]: Stabilized group kafka-sandbox generation 1 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:25:44,264] INFO [GroupCoordinator 2]: Assignment received from leader consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e for group kafka-sandbox for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:26:49,530] INFO [NodeToControllerChannelManager id=1 name=forwarding] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:26:49,532] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:27:37,488] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: Removing member consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:27:37,490] INFO [GroupCoordinator 2]: Group kafka-sandbox with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:27:37,493] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group kafka-sandbox through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:27:45,221] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:27:45,224] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 2 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:27:45,225] INFO [GroupCoordinator 2]: Stabilized group kafka-sandbox generation 3 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:27:45,231] INFO [GroupCoordinator 2]: Assignment received from leader consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948 for group kafka-sandbox for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:29:45,195] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:29:45,199] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:29:45,216] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:29:45,217] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:29:45,218] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:29:45,218] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:29:45,221] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2025-01-16 22:29:45,222] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:29:45,224] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,225] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 771 due to node 2 being disconnected (elapsed time since creation: 405ms, elapsed time since send: 405ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,225] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:29:45,227] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=513476412, epoch=771) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:29:45,228] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:29:45,228] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:29:45,231] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:29:45,231] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:29:45,232] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:29:45,234] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:29:45,235] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,235] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 771 due to node 1 being disconnected (elapsed time since creation: 245ms, elapsed time since send: 245ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,236] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,237] INFO [Controller id=2, targetBrokerId=0] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 0 being disconnected (elapsed time since creation: 12ms, elapsed time since send: 12ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,240] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,236] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=14273858, epoch=771) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:29:45,239] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:29:45,241] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:29:45,241] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:29:45,242] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:29:45,243] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:29:45,244] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:29:45,245] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:29:45,247] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,248] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,248] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,249] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:29:45,250] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,251] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,251] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,252] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:29:45,253] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:29:45,253] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:29:45,254] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:29:45,254] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:29:45,255] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:29:45,255] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:29:45,256] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,256] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,256] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,257] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,257] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,257] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,258] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:29:45,259] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:29:45,259] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:29:45,260] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:29:45,260] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:29:45,260] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:29:45,261] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:29:45,262] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:29:45,262] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:29:45,263] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,263] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,263] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,264] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,265] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,265] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,266] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,266] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,266] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,267] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,268] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,268] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,268] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,269] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,269] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:29:45,273] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:29:45,273] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:29:45,273] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:29:45,274] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:29:45,275] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:29:45,275] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:29:45,275] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:29:45,277] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:29:45,277] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:29:45,277] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:29:45,277] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:29:45,278] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:29:45,279] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:29:45,280] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:29:45,280] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:29:45,280] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:29:45,325] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 75 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:29:45,344] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,345] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,346] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,347] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 31 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:29:45,383] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:29:45,388] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:29:45,389] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:29:45,389] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:29:45,391] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:29:45,397] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:29:45,502] INFO Session: 0x100049b1bfd0005 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:29:45,502] INFO EventThread shut down for session: 0x100049b1bfd0005 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:29:45,503] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:29:45,504] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,506] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,506] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,507] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,507] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,507] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,508] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,509] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,509] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,510] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,510] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,510] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:29:45,512] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:29:45,540] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:29:45,549] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:29:45,550] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:29:45,556] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:29:45,560] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:29:45,562] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:29:45,563] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:30:02,267] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:30:02,443] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:30:02,521] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:30:02,522] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:30:02,545] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:02,552] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,553] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,553] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,553] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,553] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,554] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,566] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,568] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,568] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,569] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,569] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,569] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,569] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,570] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,570] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,570] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,570] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,571] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,572] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:02,602] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:30:02,605] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:02,610] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:02,611] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:02,613] INFO Socket connection established, initiating session, client: /127.0.0.1:61462, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:02,619] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100049b1bfd0006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:02,620] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:02,778] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:30:02,812] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:30:02,884] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:02,884] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:02,884] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:02,884] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:02,929] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:02,945] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:30:02,995] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000061.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:30:02,995] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 75 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:02,995] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 75 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:02,995] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=75, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000075.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:03,010] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 15ms for snapshot load and 0ms for segment recovery from offset 75 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,017] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=75) with 1 segments, local-log-start-offset 0 and log-end-offset 75 in 70ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,028] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000024.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:30:03,028] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 31 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,028] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 31 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,028] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=31, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000031.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:03,028] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 31 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,032] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=31) with 1 segments, local-log-start-offset 0 and log-end-offset 31 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,037] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,040] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-0, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,045] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,049] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-12, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,054] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,058] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-15, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,063] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,065] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-18, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,068] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,071] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-21, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,074] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,075] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-24, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,078] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,083] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-27, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,086] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,088] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-3, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,092] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,094] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-30, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,098] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,099] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-33, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,103] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,105] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-36, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,108] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,112] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-39, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,112] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,117] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-42, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,121] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,123] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-45, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,126] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,129] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-48, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,132] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,133] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-6, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,134] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:03,140] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-9, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:30:03,143] INFO Loaded 19 logs in 210ms (kafka.log.LogManager)
[2025-01-16 22:30:03,145] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:30:03,145] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:30:03,210] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:03,228] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:03,245] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:30:03,267] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:03,613] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:30:03,635] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:30:03,643] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:03,662] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,663] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,663] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,664] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,665] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,670] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:03,670] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:03,715] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:30:03,735] INFO Stat of the created znode at /brokers/ids/0 is: 279,279,1737041403730,1737041403730,1,0,0,72062658273935366,202,0,279
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:30:03,737] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 279 (kafka.zk.KafkaZkClient)
[2025-01-16 22:30:03,739] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:03,739] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:03,740] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:03,778] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,785] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,786] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,799] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:03,808] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:03,823] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:03,825] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:03,826] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:03,854] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:03,855] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:03,856] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:03,864] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:03,896] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:03,914] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:30:03,916] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:30:03,918] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:30:03,919] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:30:03,919] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:30:03,920] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:30:03,923] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:03,923] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:03,924] INFO Kafka startTimeMs: 1737041403920 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:03,925] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:30:04,037] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,038] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,038] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:04,039] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,041] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,041] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,042] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,042] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,043] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,044] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,045] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 31 (kafka.cluster.Partition)
[2025-01-16 22:30:04,048] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,049] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,049] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,050] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,051] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,052] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,052] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,053] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:04,053] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 75 (kafka.cluster.Partition)
[2025-01-16 22:30:04,054] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:04,068] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:04,075] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:04,077] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=2, host=127.0.0.1:9094),3,31)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:04,082] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),3,75)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:04,082] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:04,126] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:04,138] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,0  and version updated to 6 (kafka.cluster.Partition)
[2025-01-16 22:30:04,142] INFO [Partition kafka-chat-1 broker=2] ISR updated to 2,0  and version updated to 6 (kafka.cluster.Partition)
[2025-01-16 22:30:04,193] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,194] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,196] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,197] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,197] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,198] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,199] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,200] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,200] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,201] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,201] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,202] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,202] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,203] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,204] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 6 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,206] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 6 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,207] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 6 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,210] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 3 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,215] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,215] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,215] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,217] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,221] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,222] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,223] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,224] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:04,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,224] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:04,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:06,715] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:30:06,720] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:30:06,739] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:06,740] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:06,742] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:06,744] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2025-01-16 22:30:06,747] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:06,748] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:06,748] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:06,748] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:06,750] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:06,750] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:06,750] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:06,750] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:30:06,751] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:30:06,758] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,760] INFO [Controller id=2, targetBrokerId=1] Cancelled in-flight STOP_REPLICA request with correlation id 22 due to node 1 being disconnected (elapsed time since creation: 16ms, elapsed time since send: 16ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,762] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,762] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:30:06,763] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:06,763] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:30:06,763] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,764] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 884 due to node 2 being disconnected (elapsed time since creation: 85ms, elapsed time since send: 85ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,765] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=198444888, epoch=884) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:30:06,769] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:06,769] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:06,772] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:30:06,775] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,776] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,776] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,779] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:30:06,782] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,783] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,783] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,787] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:06,788] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:30:06,789] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:06,790] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:06,790] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:06,792] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:06,793] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:06,794] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,795] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,795] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,798] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,799] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,799] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,800] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:06,801] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:30:06,802] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:06,802] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:06,802] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:06,803] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:06,805] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:06,806] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:30:06,806] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:30:06,806] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,807] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,807] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,807] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,808] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,808] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,809] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,809] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,809] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,810] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,811] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,811] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,812] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,812] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,812] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:06,816] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:06,817] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:06,817] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:06,818] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:30:06,818] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:06,819] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:06,819] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:06,820] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:30:06,821] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:06,821] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:06,821] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:06,822] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:30:06,823] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:30:06,824] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:06,824] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:06,824] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:06,860] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 24 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:06,869] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,870] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,870] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:06,870] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 76 with 2 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:06,914] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:30:06,918] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:06,919] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:06,919] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:06,920] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:06,924] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:07,024] INFO Session: 0x100049b1bfd0004 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:07,024] INFO EventThread shut down for session: 0x100049b1bfd0004 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:07,025] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:07,026] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,028] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,028] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,028] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,029] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,029] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,030] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,031] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,031] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,032] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,032] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,032] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:07,034] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:30:07,041] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:30:07,041] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:30:07,042] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:30:07,042] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:30:07,043] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:30:07,044] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:07,045] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:30:20,721] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:30:20,909] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:30:20,992] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:30:20,992] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:30:21,014] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:21,022] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,023] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,023] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,024] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,024] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,025] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,036] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,039] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,039] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,040] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,040] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,040] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,040] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,040] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,041] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,041] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,041] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,042] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,044] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:21,067] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:30:21,079] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:21,081] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:21,082] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:21,084] INFO Socket connection established, initiating session, client: /127.0.0.1:61487, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:21,086] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100049b1bfd0007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:21,092] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:21,242] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:30:21,291] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:30:21,343] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:21,343] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:21,343] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:21,343] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:21,395] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,415] INFO Skipping recovery of 18 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:30:21,475] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000038.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:30:21,476] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 76 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,476] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 76 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,476] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=76, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000076.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:21,476] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 76 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,497] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=76) with 1 segments, local-log-start-offset 0 and log-end-offset 76 in 73ms (1/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,503] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000010.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:30:21,503] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 24 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,505] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 24 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,506] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=24, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000024.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:21,507] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 24 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,508] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=24) with 1 segments, local-log-start-offset 0 and log-end-offset 24 in 10ms (2/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,511] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,517] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-11, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,522] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,525] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-14, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,528] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,533] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-17, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,537] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,538] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-2, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,543] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,545] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-20, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,548] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,550] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-23, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (8/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,554] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,555] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-26, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,560] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,562] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-29, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,566] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,568] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-32, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,571] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,572] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-35, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (12/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,576] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,579] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-38, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,582] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,584] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-41, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,584] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,588] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-44, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (15/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,593] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,594] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-47, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,598] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,599] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-5, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (17/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,600] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:30:21,604] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-8, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:30:21,608] INFO Loaded 18 logs in 204ms (kafka.log.LogManager)
[2025-01-16 22:30:21,611] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:30:21,612] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:30:21,660] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:21,687] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:21,692] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:30:21,726] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:22,065] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:30:22,086] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:30:22,091] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:22,108] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,109] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,110] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,111] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,111] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,119] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:22,119] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:22,159] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:30:22,177] INFO Stat of the created znode at /brokers/ids/1 is: 333,333,1737041422159,1737041422159,1,0,0,72062658273935367,202,0,333
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:30:22,178] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 333 (kafka.zk.KafkaZkClient)
[2025-01-16 22:30:22,179] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:22,180] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:22,181] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:22,216] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,227] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,228] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,232] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,248] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,263] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:22,265] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:22,265] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:22,294] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:22,296] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:22,296] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:22,300] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:22,326] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:22,348] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:30:22,348] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:30:22,357] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:30:22,358] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:30:22,359] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:30:22,360] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:30:22,363] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:22,363] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:22,364] INFO Kafka startTimeMs: 1737041422360 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:22,365] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:30:22,475] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,475] INFO [Partition kafka-chat-2 broker=1] Log loaded for partition kafka-chat-2 with initial high watermark 24 (kafka.cluster.Partition)
[2025-01-16 22:30:22,475] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,475] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,475] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,491] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,492] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:22,492] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,493] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,494] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,495] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,495] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,496] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,497] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,497] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,498] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,498] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,499] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:30:22,499] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 76 (kafka.cluster.Partition)
[2025-01-16 22:30:22,500] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:22,507] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:22,509] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:22,520] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=2, host=127.0.0.1:9094),3,24)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:22,523] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),4,76)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:22,523] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:22,552] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:22,552] INFO [Partition kafka-chat-2 broker=2] ISR updated to 2,1  and version updated to 6 (kafka.cluster.Partition)
[2025-01-16 22:30:22,564] INFO [Partition kafka-chat-0 broker=0] ISR updated to 0,1  and version updated to 8 (kafka.cluster.Partition)
[2025-01-16 22:30:22,592] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,592] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,608] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,608] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,613] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,614] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,615] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,616] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,616] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,617] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,618] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,619] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,619] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 10 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,619] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,621] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 2, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,621] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,621] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 6 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,622] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,623] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 7 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,623] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,623] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,624] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,626] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 7 milliseconds for epoch 2, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,626] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,627] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,627] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,629] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,628] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,629] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,631] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,630] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,632] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,633] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,633] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,634] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 2 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,635] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,636] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,636] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,637] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,637] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,637] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,638] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,638] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,639] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,639] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:22,640] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,640] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:22,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:30:25,960] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:30:25,962] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:30:25,973] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:25,973] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:25,973] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)
[2025-01-16 22:30:25,974] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:25,977] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:25,977] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:25,978] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:25,979] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:25,978] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:30:25,979] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:25,980] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:30:25,984] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:25,985] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:25,986] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:30:25,986] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:25,986] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:30:25,989] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:30:25,990] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:30:25,992] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:30:25,995] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:25,996] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:25,996] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:25,997] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:30:25,998] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:25,998] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:25,998] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,000] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:26,001] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:30:26,001] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:26,001] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:26,001] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:30:26,003] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:30:26,003] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:26,004] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,004] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,004] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,005] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,005] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,005] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,006] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:30:26,007] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:30:26,008] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:26,008] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:26,008] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:30:26,009] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:26,010] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:30:26,010] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:30:26,010] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:30:26,011] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,011] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,011] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,012] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,013] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,013] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,014] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,014] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,014] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,015] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,015] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,015] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,016] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,016] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,016] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:30:26,020] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:26,021] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:26,021] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:30:26,022] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:30:26,022] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:26,022] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:26,022] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:26,024] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:30:26,025] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:26,025] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:26,025] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:30:26,026] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:30:26,027] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:30:26,028] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:26,028] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:26,028] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:30:26,066] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 25 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:26,089] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 20 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:26,098] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 33 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:30:26,127] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:30:26,132] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:26,133] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:26,133] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:30:26,134] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:26,249] INFO Session: 0x100049b1bfd0003 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:30:26,249] INFO EventThread shut down for session: 0x100049b1bfd0003 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:30:26,251] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:30:26,251] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,253] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,253] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,254] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,254] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,254] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,255] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,255] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,255] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,256] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,256] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,256] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:30:26,258] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:30:26,267] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:30:26,268] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:30:26,269] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:30:26,269] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:30:26,271] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:30:26,272] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:30:26,273] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:31:11,818] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:31:11,997] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:31:12,075] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:31:12,076] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:31:12,098] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:31:12,103] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,104] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,105] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,105] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,106] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,106] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,117] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,120] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,121] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,121] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,121] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,122] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,122] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,122] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,123] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,123] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,123] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,123] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,125] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:12,155] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:31:12,162] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:31:12,164] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:31:12,165] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:31:12,167] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61526, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:31:12,174] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100049b1bfd0008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:31:12,178] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:31:12,351] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:31:12,387] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:31:12,447] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:12,448] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:12,448] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:12,450] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:12,491] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,505] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:31:12,561] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:31:12,563] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 33 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,564] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 33 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,565] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=33, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000033.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:31:12,572] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 33 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,582] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=33) with 1 segments, local-log-start-offset 0 and log-end-offset 33 in 72ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,590] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:31:12,591] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 25 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,592] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 25 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,593] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=25, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000025.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:31:12,594] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 25 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,596] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=25) with 1 segments, local-log-start-offset 0 and log-end-offset 25 in 11ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,600] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,603] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-1, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,608] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,610] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-10, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,615] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,618] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-13, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,622] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,624] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-16, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,629] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,631] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-19, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,635] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,637] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-22, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,642] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,643] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-25, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,647] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,649] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-28, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,654] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,656] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-31, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,660] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 20 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,661] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 20 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,662] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=20, file=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000020.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:31:12,663] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 20 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,664] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=20) with 1 segments, local-log-start-offset 0 and log-end-offset 20 in 7ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,669] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,671] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-37, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,674] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,676] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-4, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,680] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,682] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-40, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,686] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,687] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-43, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,692] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,694] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-46, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,698] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,700] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-49, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,705] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:31:12,707] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-7, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:31:12,711] INFO Loaded 19 logs in 219ms (kafka.log.LogManager)
[2025-01-16 22:31:12,713] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:31:12,714] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:31:12,779] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:31:12,796] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:31:12,811] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:31:12,832] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:13,223] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:31:13,242] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:31:13,247] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:13,265] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,266] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,267] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,267] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,269] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,279] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:31:13,280] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:31:13,324] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:31:13,338] INFO Stat of the created znode at /brokers/ids/2 is: 390,390,1737041473332,1737041473332,1,0,0,72062658273935368,202,0,390
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:31:13,339] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 390 (kafka.zk.KafkaZkClient)
[2025-01-16 22:31:13,346] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,347] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,349] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,388] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,395] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,396] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,409] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,418] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,438] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:31:13,441] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:31:13,441] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:31:13,465] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,466] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,466] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,481] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:13,513] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:31:13,531] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:31:13,533] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:31:13,536] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:31:13,537] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:31:13,537] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:31:13,538] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:31:13,541] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:31:13,541] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:31:13,542] INFO Kafka startTimeMs: 1737041473538 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:31:13,543] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:31:13,602] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:13,619] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 25 (kafka.cluster.Partition)
[2025-01-16 22:31:13,621] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,622] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,623] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,623] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,624] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,624] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,625] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,625] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 33 (kafka.cluster.Partition)
[2025-01-16 22:31:13,626] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,626] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,627] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 20 (kafka.cluster.Partition)
[2025-01-16 22:31:13,627] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,628] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,628] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,629] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,629] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,630] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,630] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:31:13,631] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:13,651] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:13,653] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),4,25)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:13,658] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),4,33)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:13,658] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:13,677] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:13,693] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:13,702] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,703] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:13,724] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,2  and version updated to 8 (kafka.cluster.Partition)
[2025-01-16 22:31:13,730] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:13,733] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:13,746] INFO [Partition kafka-chat-2 broker=1] ISR updated to 1,2  and version updated to 8 (kafka.cluster.Partition)
[2025-01-16 22:31:13,766] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,767] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,769] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,770] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,771] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,771] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,772] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,772] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,773] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,774] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,774] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 5 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,774] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,775] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,776] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,777] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,778] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,780] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,782] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,783] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,784] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,786] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,787] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,788] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,789] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,790] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,790] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,791] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,791] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,792] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,793] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,793] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,794] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,794] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,795] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,796] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,796] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,810] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:31:13,817] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:31:13,822] INFO [GroupCoordinator 2]: Loading group metadata for kafka-sandbox with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:13,826] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 38 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,827] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 37 milliseconds for epoch 2, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,828] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 37 milliseconds for epoch 2, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,829] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 37 milliseconds for epoch 2, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,830] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 37 milliseconds for epoch 2, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,831] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 37 milliseconds for epoch 2, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,832] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 36 milliseconds for epoch 2, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:13,833] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 36 milliseconds for epoch 2, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:31:45,758] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:31:45,762] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:31:45,776] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:45,776] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:31:45,777] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:45,777] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:45,780] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2025-01-16 22:31:45,781] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:45,782] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,784] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 63 due to node 1 being disconnected (elapsed time since creation: 265ms, elapsed time since send: 265ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,786] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:31:45,786] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=176192159, epoch=63) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:31:45,787] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:31:45,787] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:31:45,791] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:45,791] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:45,792] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:31:45,794] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:45,794] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,795] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 63 due to node 0 being disconnected (elapsed time since creation: 354ms, elapsed time since send: 354ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,796] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,797] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 2 being disconnected (elapsed time since creation: 12ms, elapsed time since send: 12ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,799] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,796] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=636731219, epoch=63) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:31:45,799] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:31:45,800] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:45,800] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:31:45,801] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:31:45,802] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:45,802] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:31:45,803] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:31:45,805] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,807] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,807] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,809] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:31:45,810] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,811] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,811] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,813] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:31:45,813] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:31:45,814] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:31:45,814] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:31:45,814] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:31:45,816] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:31:45,817] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:45,817] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,818] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,818] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,818] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,819] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,819] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,821] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:31:45,822] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:31:45,823] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:31:45,824] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:31:45,824] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:31:45,824] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:45,825] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:31:45,826] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:31:45,826] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:31:45,827] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,827] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,827] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,828] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,828] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,828] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,829] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,830] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,830] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,830] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,831] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,831] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,832] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,832] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,832] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:31:45,837] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:31:45,837] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:31:45,837] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:31:45,838] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:31:45,839] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:45,839] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:45,839] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:45,841] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:31:45,841] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:45,841] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:45,841] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:31:45,842] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:31:45,843] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:31:45,844] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:31:45,844] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:31:45,844] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:31:45,883] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 28 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:31:45,905] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,906] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,907] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:45,906] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 23 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:31:45,913] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 35 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:31:45,939] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:31:45,943] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:31:45,944] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:31:45,944] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:31:45,945] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:31:45,950] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:31:46,063] INFO Session: 0x100049b1bfd0008 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:31:46,063] INFO EventThread shut down for session: 0x100049b1bfd0008 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:31:46,064] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:31:46,065] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,066] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,066] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,066] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,067] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,067] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,067] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,068] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,068] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,068] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,069] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,069] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:31:46,070] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:31:46,078] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:31:46,079] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:31:46,080] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:31:46,080] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:31:46,082] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:31:46,082] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:31:46,083] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:32:01,147] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:32:01,315] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:32:01,387] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:32:01,388] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:32:01,408] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:32:01,412] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,413] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,414] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,414] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,414] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,415] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,427] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,429] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,430] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,430] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,431] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,431] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,431] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,431] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,432] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,432] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,433] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,433] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,435] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:01,463] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:32:01,469] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:32:01,471] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:32:01,472] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:32:01,474] INFO Socket connection established, initiating session, client: /127.0.0.1:61555, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:32:01,478] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100049b1bfd0009, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:32:01,481] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:32:01,634] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:32:01,672] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:32:01,745] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:01,746] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:01,746] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:01,748] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:01,789] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,801] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:32:01,856] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000033.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:32:01,858] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 35 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,860] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 35 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,860] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=35, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000035.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:32:01,867] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 35 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,878] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35) with 1 segments, local-log-start-offset 0 and log-end-offset 35 in 72ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,886] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000025.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:32:01,887] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 28 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,887] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 28 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,888] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=28, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000028.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:32:01,889] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 28 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,890] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=28) with 1 segments, local-log-start-offset 0 and log-end-offset 28 in 11ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,895] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,899] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-1, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,905] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,907] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-10, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,912] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,915] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-13, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,920] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,923] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-16, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,927] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,930] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-19, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,934] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,936] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-22, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,940] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,942] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-25, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,946] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,948] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-28, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,953] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,955] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-31, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,961] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000020.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:32:01,962] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 23 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,963] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 23 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,963] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=23, file=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000023.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:32:01,964] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 23 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,966] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=23) with 1 segments, local-log-start-offset 0 and log-end-offset 23 in 9ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,970] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,972] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-37, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,975] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,977] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-4, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,982] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,984] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-40, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,987] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,989] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-43, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,993] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:01,994] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-46, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:01,998] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:02,000] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-49, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:02,004] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:32:02,006] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-7, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:32:02,009] INFO Loaded 19 logs in 219ms (kafka.log.LogManager)
[2025-01-16 22:32:02,011] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:32:02,012] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:32:02,078] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:32:02,096] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:32:02,111] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:32:02,134] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:02,490] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:32:02,510] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:32:02,515] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:02,532] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,533] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,533] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,534] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,534] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,544] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:32:02,544] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:32:02,587] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:32:02,600] INFO Stat of the created znode at /brokers/ids/2 is: 445,445,1737041522595,1737041522595,1,0,0,72062658273935369,202,0,445
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:32:02,601] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 445 (kafka.zk.KafkaZkClient)
[2025-01-16 22:32:02,603] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:02,604] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:02,605] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:02,642] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,649] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,650] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,662] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:02,673] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:02,693] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:32:02,696] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:32:02,696] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:32:02,709] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:02,710] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:02,711] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:02,739] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:02,767] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:32:02,784] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:32:02,786] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:32:02,788] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:32:02,789] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:32:02,789] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:32:02,790] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:32:02,793] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:32:02,793] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:32:02,793] INFO Kafka startTimeMs: 1737041522790 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:32:02,795] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:32:02,877] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:02,897] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 28 (kafka.cluster.Partition)
[2025-01-16 22:32:02,900] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,901] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,902] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,902] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,903] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,903] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,904] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,904] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 35 (kafka.cluster.Partition)
[2025-01-16 22:32:02,905] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,905] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,906] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 23 (kafka.cluster.Partition)
[2025-01-16 22:32:02,906] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,907] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,907] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,908] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,909] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,909] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,910] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:32:02,911] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:02,930] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:02,932] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),5,28)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:02,935] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),5,35)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:02,935] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:02,939] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:02,946] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,2  and version updated to 10 (kafka.cluster.Partition)
[2025-01-16 22:32:02,965] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:02,972] INFO [Partition kafka-chat-2 broker=1] ISR updated to 1,2  and version updated to 10 (kafka.cluster.Partition)
[2025-01-16 22:32:03,021] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,022] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,023] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,024] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,024] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,025] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,025] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,025] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,026] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,026] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,027] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,027] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,027] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 3 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,028] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,029] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,029] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,029] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,030] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,031] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,031] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,032] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,032] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,033] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,033] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,034] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,034] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,035] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,035] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,036] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,036] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,037] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,037] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,038] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,038] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,039] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,039] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,040] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,040] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,041] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,041] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,042] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,053] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:32:03,059] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:32:03,062] INFO [GroupCoordinator 2]: Loading group metadata for kafka-sandbox with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:03,065] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 29 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,066] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,067] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,068] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 29 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,068] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,069] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 29 milliseconds for epoch 4, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,069] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:03,070] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 28 milliseconds for epoch 4, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:32:11,572] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:32:11,577] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:32:11,588] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:11,589] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:32:11,591] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:11,591] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:11,592] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2025-01-16 22:32:11,594] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:11,597] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,598] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 17 due to node 1 being disconnected (elapsed time since creation: 445ms, elapsed time since send: 445ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,599] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:32:11,600] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=731289295, epoch=17) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:32:11,601] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:32:11,600] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:32:11,604] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:11,604] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:11,605] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:32:11,606] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:11,606] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,607] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 16 due to node 0 being disconnected (elapsed time since creation: 486ms, elapsed time since send: 486ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,608] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,609] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 2 being disconnected (elapsed time since creation: 11ms, elapsed time since send: 11ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,610] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,608] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1007577501, epoch=16) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:32:11,611] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:32:11,612] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:11,612] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:32:11,613] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:32:11,614] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:11,615] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:32:11,616] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:32:11,618] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,618] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,618] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,620] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:32:11,621] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,622] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,622] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,625] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:32:11,626] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:32:11,627] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:32:11,628] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:32:11,628] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:32:11,629] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:32:11,630] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:11,631] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,632] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,632] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,633] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,635] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,635] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,636] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:32:11,637] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:32:11,638] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:32:11,639] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:32:11,639] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:32:11,640] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:11,641] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:32:11,642] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:32:11,643] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:32:11,643] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,644] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,644] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,645] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,646] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,646] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,647] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,648] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,648] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,649] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,649] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,649] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,650] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,651] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,651] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:32:11,656] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:32:11,657] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:32:11,657] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:32:11,659] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:32:11,660] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:11,661] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:11,661] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:11,663] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:32:11,664] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:11,665] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:11,665] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:32:11,666] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:32:11,667] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:32:11,669] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:32:11,670] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:32:11,670] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:32:11,710] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 29 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:32:11,712] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,713] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,713] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,736] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 25 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:32:11,770] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:32:11,773] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:32:11,774] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:32:11,774] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:32:11,776] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:32:11,779] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:32:11,884] INFO Session: 0x100049b1bfd0009 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:32:11,884] INFO EventThread shut down for session: 0x100049b1bfd0009 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:32:11,886] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:32:11,888] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,889] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,889] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,889] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,890] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,890] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,890] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,891] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,891] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,891] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,892] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,892] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:32:11,893] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:32:11,901] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:32:11,902] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:32:11,902] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:32:11,903] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:32:11,903] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:32:11,904] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:32:11,904] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:39:43,179] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:39:43,347] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:39:43,418] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:39:43,420] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:39:43,441] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:39:43,446] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,447] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,448] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,448] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,449] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,449] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,475] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,480] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,481] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,482] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,482] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,483] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,483] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,483] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,484] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,484] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,485] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,485] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,488] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:39:43,516] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:39:43,522] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:39:43,524] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:39:43,525] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:39:43,528] INFO Socket connection established, initiating session, client: /127.0.0.1:61662, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:39:43,533] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100049b1bfd000a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:39:43,536] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:39:43,695] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:39:43,732] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:39:43,820] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:39:43,821] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:39:43,822] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:39:43,823] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:39:43,865] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:43,879] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:39:43,937] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 35 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,939] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 35 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,940] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=35, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000035.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:39:43,947] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 35 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,959] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35) with 1 segments, local-log-start-offset 0 and log-end-offset 35 in 74ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:43,966] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000028.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:39:43,967] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 29 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,968] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 29 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,969] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=29, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000029.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:39:43,971] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 29 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,973] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=29) with 1 segments, local-log-start-offset 0 and log-end-offset 29 in 12ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:43,979] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,983] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-1, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:43,990] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:43,993] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-10, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:43,997] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,000] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-13, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,006] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,010] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-16, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,015] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,017] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-19, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,022] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,024] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-22, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,029] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,031] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-25, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,036] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,039] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-28, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,044] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,046] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-31, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,052] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000023.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:39:44,054] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 25 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,055] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 25 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,056] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=25, file=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000025.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:39:44,057] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 25 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,059] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=25) with 1 segments, local-log-start-offset 0 and log-end-offset 25 in 11ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,063] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,065] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-37, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,069] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,072] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-4, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,075] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,077] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-40, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,082] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,084] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-43, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,089] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,091] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-46, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,096] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,098] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-49, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,103] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:39:44,105] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-7, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:39:44,110] INFO Loaded 19 logs in 243ms (kafka.log.LogManager)
[2025-01-16 22:39:44,112] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:39:44,113] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:39:44,175] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:39:44,193] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:39:44,209] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:39:44,232] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:39:44,580] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:39:44,599] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:39:44,605] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:39:44,622] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,623] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,624] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,624] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,624] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,633] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:39:44,634] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:39:44,678] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:39:44,691] INFO Stat of the created znode at /brokers/ids/2 is: 500,500,1737041984685,1737041984685,1,0,0,72062658273935370,202,0,500
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:39:44,693] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 500 (kafka.zk.KafkaZkClient)
[2025-01-16 22:39:44,694] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:39:44,695] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:39:44,697] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:39:44,732] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,739] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,740] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,761] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:44,773] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:44,794] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:39:44,798] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:39:44,798] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:39:44,812] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:39:44,813] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:39:44,815] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:39:44,842] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:39:44,871] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:39:44,888] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:39:44,890] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:39:44,893] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:39:44,894] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:39:44,895] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:39:44,895] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:39:44,899] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:39:44,899] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:39:44,900] INFO Kafka startTimeMs: 1737041984896 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:39:44,902] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:39:44,996] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 29 (kafka.cluster.Partition)
[2025-01-16 22:39:44,999] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:39:45,001] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,002] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,003] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,004] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,005] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,006] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,007] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,008] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 35 (kafka.cluster.Partition)
[2025-01-16 22:39:45,009] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,010] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,010] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 25 (kafka.cluster.Partition)
[2025-01-16 22:39:45,011] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,012] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,013] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,013] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,014] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,015] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,016] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:39:45,017] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:39:45,034] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:39:45,036] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),6,29)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:39:45,041] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),6,35)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:39:45,041] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:39:45,046] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:39:45,072] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:39:45,077] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,2  and version updated to 12 (kafka.cluster.Partition)
[2025-01-16 22:39:45,081] INFO [Partition kafka-chat-2 broker=1] ISR updated to 1,2  and version updated to 12 (kafka.cluster.Partition)
[2025-01-16 22:39:45,131] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,133] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,135] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,136] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,138] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,139] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,140] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,141] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,142] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 6 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,142] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,144] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,145] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,147] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,148] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,150] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 8 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,150] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,152] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 4 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,153] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,155] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 2 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,156] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,159] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,159] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,163] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,163] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,164] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,166] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,167] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,167] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,170] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,172] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,173] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,174] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,175] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,177] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,177] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,179] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,180] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,181] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,182] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,183] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,190] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:39:45,199] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:39:45,204] INFO [GroupCoordinator 2]: Loading group metadata for kafka-sandbox with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:39:45,209] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 39 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,210] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 38 milliseconds for epoch 6, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,212] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 38 milliseconds for epoch 6, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,213] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 36 milliseconds for epoch 6, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,215] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 36 milliseconds for epoch 6, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,216] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 35 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,217] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 34 milliseconds for epoch 6, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:39:45,219] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 34 milliseconds for epoch 6, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:41:17,607] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 3 (__consumer_offsets-34) (reason: Removing member consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:17,610] INFO [GroupCoordinator 2]: Group kafka-sandbox with generation 4 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:17,623] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) has left group kafka-sandbox through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:26,106] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-b1c133ae-0de8-4067-ad6f-bf69884acd75 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:26,113] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 4 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-b1c133ae-0de8-4067-ad6f-bf69884acd75 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:26,117] INFO [GroupCoordinator 2]: Stabilized group kafka-sandbox generation 5 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:26,130] INFO [GroupCoordinator 2]: Assignment received from leader consumer-kafka-sandbox-1-b1c133ae-0de8-4067-ad6f-bf69884acd75 for group kafka-sandbox for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:27,673] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 5 (__consumer_offsets-34) (reason: Removing member consumer-kafka-sandbox-1-b1c133ae-0de8-4067-ad6f-bf69884acd75 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:27,674] INFO [GroupCoordinator 2]: Group kafka-sandbox with generation 6 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:41:27,675] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-kafka-sandbox-1-b1c133ae-0de8-4067-ad6f-bf69884acd75, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group kafka-sandbox through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:08,195] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-cde2a165-a309-4b0b-befd-c374fc097ed5 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:08,198] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 6 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-cde2a165-a309-4b0b-befd-c374fc097ed5 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:08,199] INFO [GroupCoordinator 2]: Stabilized group kafka-sandbox generation 7 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:08,204] INFO [GroupCoordinator 2]: Assignment received from leader consumer-kafka-sandbox-1-cde2a165-a309-4b0b-befd-c374fc097ed5 for group kafka-sandbox for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:10,186] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 7 (__consumer_offsets-34) (reason: Removing member consumer-kafka-sandbox-1-cde2a165-a309-4b0b-befd-c374fc097ed5 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:10,187] INFO [GroupCoordinator 2]: Group kafka-sandbox with generation 8 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:10,188] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-kafka-sandbox-1-cde2a165-a309-4b0b-befd-c374fc097ed5, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group kafka-sandbox through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:37,303] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:43:37,305] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:43:37,317] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:37,317] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:37,318] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:37,318] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:37,319] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)
[2025-01-16 22:43:37,322] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:37,324] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:37,325] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:37,326] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,325] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:37,327] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 457 due to node 1 being disconnected (elapsed time since creation: 198ms, elapsed time since send: 198ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,327] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:43:37,332] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,333] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 2 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,333] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,328] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=908012810, epoch=457) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:43:37,334] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:37,335] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:43:37,334] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:37,335] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:43:37,337] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:37,337] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,338] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 457 due to node 0 being disconnected (elapsed time since creation: 178ms, elapsed time since send: 178ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,339] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1196857177, epoch=457) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:43:37,342] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:37,342] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:37,344] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:37,344] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:37,345] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:43:37,347] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,347] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,347] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,348] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:43:37,349] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,349] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,349] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,351] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:43:37,351] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:43:37,352] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:37,352] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:37,352] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:37,353] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:43:37,354] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:37,354] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,355] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,355] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,355] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,356] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,356] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,357] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:37,358] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:43:37,358] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:37,359] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:37,359] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:37,359] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:37,361] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:37,361] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:37,362] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:37,362] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,363] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,363] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,364] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,364] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,364] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,365] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,365] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,365] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,366] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,366] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,366] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,367] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,367] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,367] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:37,372] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:37,372] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:37,373] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:37,375] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:43:37,375] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:37,376] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:37,376] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:37,378] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:43:37,378] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:37,379] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:37,379] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:37,380] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:43:37,380] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:43:37,381] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:37,381] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:37,381] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:37,419] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 55 with 2 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:37,439] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,440] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,441] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,447] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 31 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:37,454] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 70 with 2 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:37,483] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:43:37,486] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:37,487] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:37,487] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:37,489] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:43:37,493] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:37,596] INFO Session: 0x100049b1bfd000a closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:43:37,596] INFO EventThread shut down for session: 0x100049b1bfd000a (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:43:37,600] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:43:37,603] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,606] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,606] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,608] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,608] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,608] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,609] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,609] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,609] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,610] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,611] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,611] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:37,612] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:43:37,619] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:43:37,620] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:37,620] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:37,621] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:37,621] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:43:37,622] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:43:37,622] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:43:40,459] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:43:40,460] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:43:40,472] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:40,473] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:40,473] INFO [KafkaServer id=1] Controlled shutdown request returned after 8ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:43:40,473] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:40,477] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:40,478] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:40,479] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1569 due to node 0 being disconnected (elapsed time since creation: 285ms, elapsed time since send: 285ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:40,479] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=497637755, epoch=1569) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:43:40,482] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:40,482] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:43:40,483] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:40,484] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:41,954] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:43:41,960] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:43:41,967] INFO [KafkaServer id=0] Controlled shutdown request returned after 2ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:43:45,481] INFO [KafkaServer id=1] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:43:45,490] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:45,493] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:45,495] INFO [KafkaServer id=1] Controlled shutdown request returned after 11ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:43:45,497] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:45,498] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:46,976] INFO [KafkaServer id=0] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:43:46,985] INFO [KafkaServer id=0] Controlled shutdown request returned after 7ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:43:50,512] INFO [KafkaServer id=1] Retrying controlled shutdown (1 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:43:50,521] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:50,523] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:50,524] INFO [KafkaServer id=1] Controlled shutdown request returned after 10ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:43:50,526] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:50,527] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:50,528] WARN [KafkaServer id=1] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2025-01-16 22:43:50,529] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:50,530] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:50,530] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:50,531] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:43:50,536] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:43:50,537] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:43:50,539] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:43:50,541] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,541] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,541] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,543] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:43:50,543] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,544] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,544] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,545] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:43:50,546] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:43:50,546] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:50,547] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:50,547] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:50,548] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:43:50,548] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:50,549] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,549] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,549] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,550] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,550] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,550] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,551] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:50,552] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:43:50,552] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:50,552] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:50,552] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:50,553] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:50,554] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:50,555] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:50,555] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:50,555] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,556] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,556] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,556] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,557] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,557] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,557] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,558] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,558] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,559] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,559] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,559] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,560] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,560] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,560] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:50,565] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:50,565] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:50,565] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:50,566] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:43:50,567] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:50,567] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:50,567] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:50,569] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:43:50,569] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:50,569] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:50,569] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:50,570] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:43:50,571] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:43:50,572] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:50,572] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:50,572] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:50,607] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 55 with 2 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:50,621] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 159 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:50,666] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:43:50,670] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:50,671] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:50,671] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:50,673] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:43:50,779] INFO Session: 0x100049b1bfd0007 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:43:50,779] INFO EventThread shut down for session: 0x100049b1bfd0007 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:43:50,782] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:43:50,785] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,789] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,789] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,790] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,791] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,791] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,792] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,792] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,792] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,793] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,794] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,794] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:50,795] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:43:50,805] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:43:50,805] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:50,806] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:50,806] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:50,807] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:43:50,807] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:43:50,808] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:43:51,994] INFO [KafkaServer id=0] Retrying controlled shutdown (1 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:43:51,997] INFO [KafkaServer id=0] Controlled shutdown request returned after 2ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:43:51,999] WARN [KafkaServer id=0] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2025-01-16 22:43:52,000] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:52,001] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:52,001] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:43:52,002] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:43:52,005] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:43:52,007] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:43:52,008] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:43:52,010] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:43:52,011] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,012] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,012] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,013] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:43:52,014] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,014] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,014] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,016] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:43:52,016] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:43:52,017] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:52,017] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:52,017] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:43:52,018] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:43:52,018] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:52,019] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,019] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,019] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,020] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,020] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,020] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,021] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:43:52,022] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:43:52,023] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:52,023] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:52,023] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:43:52,024] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:52,024] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:43:52,025] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:52,025] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:43:52,026] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,026] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,026] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,027] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,027] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,027] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,028] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,028] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,028] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,029] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,029] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,029] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,030] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,030] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,030] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:43:52,035] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:52,035] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:52,035] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:43:52,036] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:43:52,036] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:52,037] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:52,037] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:52,039] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:43:52,039] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:52,039] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:52,039] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:43:52,040] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:43:52,041] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:43:52,042] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:52,042] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:52,042] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:43:52,088] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 159 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:52,110] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 70 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:43:52,141] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:43:52,144] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:52,145] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:52,145] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:43:52,146] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:43:52,264] INFO Session: 0x100049b1bfd0006 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:43:52,264] INFO EventThread shut down for session: 0x100049b1bfd0006 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:43:52,267] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:43:52,272] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,278] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,278] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,281] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,282] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,282] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,283] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,283] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,283] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,284] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,285] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,285] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:43:52,286] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:43:52,299] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:43:52,300] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:52,300] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:52,301] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:43:52,302] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:43:52,303] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:43:52,303] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:45:00,661] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,661] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,661] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,661] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,661] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,661] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,661] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:45:00,661] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:45:00,661] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:45:00,671] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-16 22:45:00,672] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-16 22:45:00,673] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,673] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,674] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,674] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,674] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,675] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:45:00,675] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-16 22:45:00,686] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@63355449 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-16 22:45:00,688] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-16 22:45:00,688] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-16 22:45:00,688] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:45:00,699] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,700] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,700] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,700] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,701] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,701] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,701] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,702] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,702] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,703] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,704] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,704] INFO Server environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,704] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,704] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,704] INFO Server environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,704] INFO Server environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,716] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,719] INFO Server environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,720] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,720] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,720] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,721] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,721] INFO Server environment:user.name=mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,721] INFO Server environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,721] INFO Server environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,722] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,724] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,724] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,724] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,726] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-16 22:45:00,727] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,727] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,728] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-16 22:45:00,729] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-16 22:45:00,729] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:45:00,729] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:45:00,729] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:45:00,729] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:45:00,729] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:45:00,729] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:45:00,734] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,734] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,735] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-16 22:45:00,735] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-16 22:45:00,735] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir \tmp\zookeeper\version-2 snapdir \tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,739] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-16 22:45:00,741] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-16 22:45:00,742] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-16 22:45:00,766] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-16 22:45:00,791] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-16 22:45:00,792] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-16 22:45:00,793] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:45:00,793] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:45:00,797] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-16 22:45:00,805] INFO Reading snapshot \tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2025-01-16 22:45:00,809] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2025-01-16 22:45:00,834] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-16 22:45:00,863] INFO 559 txns loaded in 43 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:45:00,864] INFO Snapshot loaded in 71 ms, highest zxid is 0x22f, digest is 289927295799 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:45:00,865] INFO Snapshotting: 0x22f to \tmp\zookeeper\version-2\snapshot.22f (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:45:00,868] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:45:00,874] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-16 22:45:00,874] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-16 22:45:00,889] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-16 22:45:17,600] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:45:17,785] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:45:17,864] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:45:17,865] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:45:17,887] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:17,891] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,892] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,893] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,893] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,894] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,895] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,905] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,908] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,908] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,908] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,908] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,909] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,909] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,909] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,910] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,910] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,910] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,910] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,912] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:17,941] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:45:17,947] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:17,949] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:17,950] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:17,952] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61896, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:17,957] INFO Creating new log file: log.230 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-16 22:45:17,965] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10004b5b4bf0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:17,968] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:18,148] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:45:18,185] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:45:18,245] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:18,245] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:18,246] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:18,248] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:18,292] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,304] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:45:18,365] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000075.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:18,367] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 159 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,367] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,368] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=159, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000159.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:18,375] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,386] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=159) with 1 segments, local-log-start-offset 0 and log-end-offset 159 in 76ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,394] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000031.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:18,395] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,395] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,396] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=70, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000070.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:18,397] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,398] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=70) with 1 segments, local-log-start-offset 0 and log-end-offset 70 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,403] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,405] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-0, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,411] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,413] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-12, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,418] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,421] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-15, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,425] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,427] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-18, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,432] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,434] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-21, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,439] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,440] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-24, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,444] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,446] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-27, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,452] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,454] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-3, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,458] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,460] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-30, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,463] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,465] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-33, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,469] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,470] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-36, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,474] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,476] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-39, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,480] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,482] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-42, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,486] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,487] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-45, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,490] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,492] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-48, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,497] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,499] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-6, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,504] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:18,505] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-9, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:45:18,508] INFO Loaded 19 logs in 214ms (kafka.log.LogManager)
[2025-01-16 22:45:18,511] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:45:18,512] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:45:18,575] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:45:18,592] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:45:18,609] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:45:18,633] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:19,001] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:45:19,021] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:45:19,026] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:19,043] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,044] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,045] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,046] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,046] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,056] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:45:19,056] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:45:19,091] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:19,108] INFO Stat of the created znode at /brokers/ids/0 is: 575,575,1737042319102,1737042319102,1,0,0,72062772505935872,202,0,575
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:19,109] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 575 (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:19,145] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,152] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,153] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,167] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,178] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,199] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:45:19,202] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:45:19,202] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:45:19,275] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:19,283] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:19,285] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:19,288] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:19,305] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:45:19,333] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:45:19,336] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:45:19,339] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:45:19,340] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:45:19,341] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:45:19,341] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:45:19,347] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:19,347] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:19,348] INFO Kafka startTimeMs: 1737042319342 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:19,351] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:45:19,468] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, kafka-chat-1, __consumer_offsets-36, __consumer_offsets-48, kafka-chat-0, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:19,469] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:19,478] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,485] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:19,488] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,490] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,494] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,498] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,502] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,505] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,509] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,512] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,517] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 70 (kafka.cluster.Partition)
[2025-01-16 22:45:19,522] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,527] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,531] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,535] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,538] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,542] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,545] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,549] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:19,552] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 159 (kafka.cluster.Partition)
[2025-01-16 22:45:19,559] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,562] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,563] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,564] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,564] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,565] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,566] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,567] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,568] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,568] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,569] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,570] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,571] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,572] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,572] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,574] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,575] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,575] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,576] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,576] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 3 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,578] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,579] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,581] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,581] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,583] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,583] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,583] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,585] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,586] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,587] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,588] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,588] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,589] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:19,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,590] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:19,591] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:20,014] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:45:20,207] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:45:20,287] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:45:20,288] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:45:20,308] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:20,313] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,315] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,315] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,316] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,316] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,316] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,327] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,329] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,329] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,329] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,330] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,330] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,330] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,331] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,331] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,332] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,332] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,332] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,334] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:20,364] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:45:20,370] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:20,371] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:20,372] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:20,374] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61900, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:20,382] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10004b5b4bf0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:20,384] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:20,551] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:45:20,593] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:45:20,653] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:20,654] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:20,654] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:20,656] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:20,699] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,713] INFO Skipping recovery of 18 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:45:20,767] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000076.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:20,769] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 159 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,770] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,770] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=159, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000159.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:20,777] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,787] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=159) with 1 segments, local-log-start-offset 0 and log-end-offset 159 in 68ms (1/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,797] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000024.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:20,797] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 55 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,798] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 55 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,798] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=55, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000055.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:20,799] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 55 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,801] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=55) with 1 segments, local-log-start-offset 0 and log-end-offset 55 in 12ms (2/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,806] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,809] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-11, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,815] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,817] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-14, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,822] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,824] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-17, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,829] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,831] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-2, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,836] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,838] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-20, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,843] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,845] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-23, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (8/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,850] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,852] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-26, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,855] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,858] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-29, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,863] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,866] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-32, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (11/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,870] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,872] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-35, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (12/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,877] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,879] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-38, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (13/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,883] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,884] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-41, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (14/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,888] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,890] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-44, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,895] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,897] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-47, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (16/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,904] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,905] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-5, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (17/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,909] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:20,912] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-8, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:45:20,915] INFO Loaded 18 logs in 214ms (kafka.log.LogManager)
[2025-01-16 22:45:20,917] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:45:20,918] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:45:20,980] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:45:20,995] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:45:21,011] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:45:21,033] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:21,374] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:45:21,391] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:45:21,396] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:21,414] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,415] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,415] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,416] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,416] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,425] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:45:21,426] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:45:21,466] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:21,483] INFO Stat of the created znode at /brokers/ids/1 is: 627,627,1737042321477,1737042321477,1,0,0,72062772505935873,202,0,627
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:21,485] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 627 (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:21,492] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:21,492] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:21,493] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:21,529] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,535] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,536] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,548] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,557] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,574] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:45:21,578] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:45:21,578] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:45:21,598] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:21,599] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:21,600] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:21,621] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:21,649] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:45:21,670] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:45:21,672] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:45:21,674] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:45:21,675] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:45:21,676] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:45:21,676] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:45:21,680] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:21,681] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:21,682] INFO Kafka startTimeMs: 1737042321677 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:21,688] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:45:21,797] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,798] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:21,798] INFO [Partition kafka-chat-2 broker=1] Log loaded for partition kafka-chat-2 with initial high watermark 55 (kafka.cluster.Partition)
[2025-01-16 22:45:21,799] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,800] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,801] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,801] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,802] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,802] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,803] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,804] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,804] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,805] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,805] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,806] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,807] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,807] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,808] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:21,811] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 159 (kafka.cluster.Partition)
[2025-01-16 22:45:21,814] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:21,829] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:21,834] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:45:21,837] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),5,159)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:21,858] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-8, kafka-chat-2, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:21,907] INFO [Partition kafka-chat-0 broker=0] ISR updated to 0,1  and version updated to 10 (kafka.cluster.Partition)
[2025-01-16 22:45:21,923] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,924] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,925] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,926] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,926] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,927] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,928] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,928] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,929] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,930] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,930] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,930] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 5 milliseconds for epoch 5, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,931] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,932] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 6 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,932] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,933] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 5 milliseconds for epoch 5, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,933] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,934] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 5 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,934] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,935] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds for epoch 5, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,935] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,936] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 4 milliseconds for epoch 5, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,936] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,937] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 3 milliseconds for epoch 5, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,937] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,938] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 2 milliseconds for epoch 5, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,938] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,939] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds for epoch 5, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,939] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,940] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,940] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,941] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,942] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,942] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,943] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,944] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,944] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,944] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,946] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,946] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,946] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,948] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,948] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,949] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,950] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 5 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:21,950] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 5, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,950] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 5 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:21,952] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds for epoch 5, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:22,659] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:45:22,829] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:45:22,900] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:45:22,901] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:45:22,921] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:22,926] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,927] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,927] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,928] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,928] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,929] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,941] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,943] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,944] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,944] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,944] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,945] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,945] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,945] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,946] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,946] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,946] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,946] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,949] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:45:22,977] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:45:22,983] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:22,985] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:22,986] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:22,988] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:61907, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:22,993] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10004b5b4bf0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:45:22,997] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:45:23,158] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:45:23,195] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:45:23,253] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:23,253] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:23,254] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:23,256] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:45:23,299] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,312] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:45:23,364] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000035.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:23,366] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 70 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,367] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,368] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=70, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000070.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:23,375] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,386] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=70) with 1 segments, local-log-start-offset 0 and log-end-offset 70 in 68ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,393] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000029.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:23,394] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 55 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,395] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 55 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,395] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=55, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000055.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:23,397] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 55 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,399] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=55) with 1 segments, local-log-start-offset 0 and log-end-offset 55 in 12ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,405] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,407] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-1, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,413] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,415] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-10, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,421] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,423] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-13, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,429] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,431] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-16, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,435] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,437] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-19, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,441] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,443] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-22, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,448] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,450] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-25, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,454] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,456] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-28, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,460] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,462] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-31, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,467] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000025.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:45:23,468] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 31 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,468] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 31 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,469] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=31, file=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34\00000000000000000031.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:45:23,470] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 31 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,471] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-34, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=31) with 1 segments, local-log-start-offset 0 and log-end-offset 31 in 8ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,475] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,477] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-37, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,481] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,483] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-4, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,487] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,489] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-40, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,494] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,495] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-43, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,500] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,501] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-46, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,504] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,506] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-49, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,510] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:45:23,512] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-7, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:45:23,516] INFO Loaded 19 logs in 215ms (kafka.log.LogManager)
[2025-01-16 22:45:23,518] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:45:23,519] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:45:23,579] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:45:23,597] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:45:23,611] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:45:23,630] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:23,953] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:45:23,976] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:45:23,976] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:23,998] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:23,999] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:23,999] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:23,999] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:24,000] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:24,009] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:45:24,010] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:45:24,048] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:24,065] INFO Stat of the created znode at /brokers/ids/2 is: 661,661,1737042324059,1737042324059,1,0,0,72062772505935874,202,0,661
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:24,065] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 661 (kafka.zk.KafkaZkClient)
[2025-01-16 22:45:24,065] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:24,065] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:24,072] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:24,109] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:24,116] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:24,116] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:24,132] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,135] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,148] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:45:24,161] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:45:24,161] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:45:24,177] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:24,177] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:24,178] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:45:24,201] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:45:24,227] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:45:24,258] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:45:24,260] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:45:24,260] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:45:24,260] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:45:24,264] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:45:24,264] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:45:24,267] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:24,267] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:24,268] INFO Kafka startTimeMs: 1737042324264 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:45:24,270] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:45:24,361] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 55 (kafka.cluster.Partition)
[2025-01-16 22:45:24,364] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,365] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,366] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,366] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,367] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,367] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,367] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:24,368] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,368] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 70 (kafka.cluster.Partition)
[2025-01-16 22:45:24,369] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,369] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,370] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 31 (kafka.cluster.Partition)
[2025-01-16 22:45:24,370] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,371] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,371] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,372] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,372] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,373] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,373] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:45:24,376] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:24,379] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:45:24,393] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:45:24,396] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=1, host=127.0.0.1:9093),10,55)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:24,400] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:45:24,400] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(BOebwcM7SIGiwrLcbzAIzA),BrokerEndPoint(id=0, host=127.0.0.1:9092),7,70)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:24,414] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,2  and version updated to 14 (kafka.cluster.Partition)
[2025-01-16 22:45:24,420] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:45:24,444] INFO [Partition kafka-chat-2 broker=1] ISR updated to 1,2  and version updated to 17 (kafka.cluster.Partition)
[2025-01-16 22:45:24,477] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,477] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,477] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,477] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,477] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,477] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,477] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,477] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,477] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,485] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,486] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,486] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds for epoch 9, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,486] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,487] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 9, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,487] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,488] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds for epoch 9, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,489] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 12 milliseconds for epoch 9, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,490] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,491] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,491] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds for epoch 9, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,491] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,492] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds for epoch 9, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,492] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,493] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds for epoch 9, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,493] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,494] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds for epoch 9, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,494] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,495] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds for epoch 9, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,495] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,497] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,497] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,497] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,498] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,498] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,500] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,500] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,500] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,501] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,501] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,501] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,501] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 9 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,501] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 9 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,515] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-44706d66-c418-44c8-b0f4-cc3b9bc5c77e, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:45:24,523] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-a6f2543e-fdd9-4b8e-abf4-e3bdcec05948, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:45:24,526] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-b1c133ae-0de8-4067-ad6f-bf69884acd75, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:45:24,527] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-cde2a165-a309-4b0b-befd-c374fc097ed5, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:45:24,529] INFO [GroupCoordinator 2]: Loading group metadata for kafka-sandbox with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:24,531] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 36 milliseconds for epoch 9, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,531] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 34 milliseconds for epoch 9, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,532] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 34 milliseconds for epoch 9, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,533] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 33 milliseconds for epoch 9, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,533] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 33 milliseconds for epoch 9, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,534] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 33 milliseconds for epoch 9, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,534] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 33 milliseconds for epoch 9, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:24,535] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 34 milliseconds for epoch 9, of which 34 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:45:52,773] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-31054f0f-9694-4837-b3fd-d1a4c875756e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:52,782] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 8 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-31054f0f-9694-4837-b3fd-d1a4c875756e with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:52,786] INFO [GroupCoordinator 2]: Stabilized group kafka-sandbox generation 9 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:52,798] INFO [GroupCoordinator 2]: Assignment received from leader consumer-kafka-sandbox-1-31054f0f-9694-4837-b3fd-d1a4c875756e for group kafka-sandbox for generation 9. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:54,448] INFO [GroupCoordinator 2]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 9 (__consumer_offsets-34) (reason: Removing member consumer-kafka-sandbox-1-31054f0f-9694-4837-b3fd-d1a4c875756e on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:54,451] INFO [GroupCoordinator 2]: Group kafka-sandbox with generation 10 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:45:54,452] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=consumer-kafka-sandbox-1-31054f0f-9694-4837-b3fd-d1a4c875756e, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group kafka-sandbox through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:31,530] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:48:31,536] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:48:31,563] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:31,564] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:31,565] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:31,565] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:31,569] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2025-01-16 22:48:31,569] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:31,571] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,573] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 365 due to node 1 being disconnected (elapsed time since creation: 193ms, elapsed time since send: 193ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,574] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:31,575] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=55820953, epoch=365) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:48:31,576] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:31,576] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:31,581] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:31,581] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:31,583] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:48:31,584] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:31,585] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,586] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 365 due to node 0 being disconnected (elapsed time since creation: 331ms, elapsed time since send: 331ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,587] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,588] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 2 being disconnected (elapsed time since creation: 15ms, elapsed time since send: 15ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,587] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=460562087, epoch=365) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:48:31,590] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,590] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:48:31,591] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:31,591] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:31,592] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:48:31,593] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:31,594] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:31,595] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:48:31,597] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,598] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,598] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,599] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:48:31,600] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,601] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,601] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,602] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:48:31,604] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:48:31,604] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:31,605] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:31,605] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:31,606] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:48:31,607] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:31,607] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,608] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,608] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,608] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,609] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,609] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,609] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:31,610] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:48:31,611] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:31,611] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:31,611] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:31,612] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:31,612] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:31,613] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:31,613] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:31,613] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,614] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,614] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,615] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,615] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,615] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,616] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,616] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,616] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,617] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,617] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,617] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,618] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,619] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,619] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:31,623] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:31,623] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:31,623] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:31,624] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:48:31,625] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:31,625] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:31,625] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:31,627] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:48:31,627] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:31,627] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:31,627] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:31,628] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:48:31,629] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:48:31,629] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:31,630] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:31,630] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:31,689] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 33 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:48:31,702] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,703] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,704] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,721] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:48:31,724] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:31,724] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:31,724] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:31,726] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:48:31,731] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:31,844] INFO Session: 0x10004b5b4bf0002 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:48:31,844] INFO EventThread shut down for session: 0x10004b5b4bf0002 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:48:31,845] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:48:31,846] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,848] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,848] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,849] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,849] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,849] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,850] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,851] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,851] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,852] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,852] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,852] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:31,854] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:48:31,864] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:48:31,865] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:31,865] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:31,866] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:31,867] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:48:31,868] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:48:31,869] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:48:33,116] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:48:33,118] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:48:33,134] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:33,135] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:33,135] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:33,136] INFO [KafkaServer id=1] Controlled shutdown request returned after 10ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:48:33,141] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:33,142] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:33,143] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 373 due to node 0 being disconnected (elapsed time since creation: 246ms, elapsed time since send: 246ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:33,145] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=161226153, epoch=373) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:48:33,150] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:33,150] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:48:33,153] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:33,154] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:34,347] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:48:34,353] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:48:34,364] INFO [KafkaServer id=0] Controlled shutdown request returned after 5ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:48:38,140] INFO [KafkaServer id=1] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:48:38,147] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:38,148] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:38,150] INFO [KafkaServer id=1] Controlled shutdown request returned after 7ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:48:38,151] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:38,152] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:39,372] INFO [KafkaServer id=0] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:48:39,384] INFO [KafkaServer id=0] Controlled shutdown request returned after 9ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:48:43,152] INFO [KafkaServer id=1] Retrying controlled shutdown (1 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:48:43,157] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:43,158] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:43,159] INFO [KafkaServer id=1] Controlled shutdown request returned after 6ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:48:43,161] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:43,161] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:43,162] WARN [KafkaServer id=1] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2025-01-16 22:48:43,162] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:43,163] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:43,163] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:43,165] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:48:43,171] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:48:43,172] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:48:43,173] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:48:43,174] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,175] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,175] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,176] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:48:43,176] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,177] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,177] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,178] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:48:43,179] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:48:43,179] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:43,180] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:43,180] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:43,181] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:48:43,181] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:43,182] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,182] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,182] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,183] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,184] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,184] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,185] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:43,186] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:48:43,186] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:43,187] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:43,187] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:43,187] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:43,188] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:43,189] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:43,189] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:43,190] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,190] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,190] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,191] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,191] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,191] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,192] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,192] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,192] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,193] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,193] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,193] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,194] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,194] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,194] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:43,198] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:43,198] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:43,198] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:43,199] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:48:43,200] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:43,200] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:43,200] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:43,203] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:48:43,203] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:43,204] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:43,204] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:43,205] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:48:43,205] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:48:43,206] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:43,207] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:43,207] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:43,289] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:48:43,293] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:43,294] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:43,294] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:43,296] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:48:43,415] INFO Session: 0x10004b5b4bf0001 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:48:43,415] INFO EventThread shut down for session: 0x10004b5b4bf0001 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:48:43,419] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:48:43,421] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,422] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,422] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,423] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,424] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,424] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,424] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,425] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,425] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,425] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,426] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,426] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:43,427] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:48:43,436] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:48:43,437] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:43,437] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:43,438] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:43,439] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:48:43,439] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:48:43,440] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:48:44,392] INFO [KafkaServer id=0] Retrying controlled shutdown (1 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:48:44,397] INFO [KafkaServer id=0] Controlled shutdown request returned after 3ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 22:48:44,399] WARN [KafkaServer id=0] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2025-01-16 22:48:44,400] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:44,401] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:44,401] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:48:44,402] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:48:44,405] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:48:44,408] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:48:44,409] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:48:44,411] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:48:44,412] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,412] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,412] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,414] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:48:44,414] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,415] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,415] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,416] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:48:44,417] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:48:44,418] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:44,418] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:44,418] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:48:44,419] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:48:44,420] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:44,420] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,421] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,421] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,421] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,422] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,422] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,423] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:48:44,423] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:48:44,424] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:44,424] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:44,424] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:48:44,425] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:44,426] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:48:44,426] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:44,427] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:48:44,427] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,427] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,427] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,428] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,428] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,428] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,429] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,429] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,429] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,430] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,430] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,430] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,431] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,432] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,432] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:48:44,436] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:44,437] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:44,437] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:48:44,438] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:48:44,438] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:44,439] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:44,439] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:44,440] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:48:44,440] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:44,441] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:44,441] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:48:44,442] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:48:44,442] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:48:44,443] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:44,443] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:44,443] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:48:44,529] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:48:44,534] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:44,535] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:44,535] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:48:44,537] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:48:44,643] INFO Session: 0x10004b5b4bf0000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:48:44,643] INFO EventThread shut down for session: 0x10004b5b4bf0000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:48:44,644] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:48:44,645] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,647] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,647] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,647] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,647] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,647] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,648] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,649] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,649] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,649] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,650] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,650] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:48:44,651] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:48:44,658] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:48:44,659] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:44,660] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:44,660] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:48:44,661] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:48:44,661] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:48:44,662] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:49:42,349] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:49:42,517] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:49:42,588] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:49:42,589] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:49:42,620] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:49:42,625] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,626] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,626] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,627] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,627] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,628] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,644] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,646] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,646] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,647] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,647] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,647] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,648] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,648] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,648] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,649] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,649] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,649] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,651] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:49:42,681] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:49:42,687] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:49:42,688] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:49:42,689] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:49:42,692] INFO Socket connection established, initiating session, client: /127.0.0.1:62014, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:49:42,697] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004b5b4bf0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:49:42,700] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:49:42,865] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:49:42,906] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:49:42,968] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:49:42,968] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:49:42,969] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:49:42,970] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:49:43,013] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,026] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:49:43,106] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 159 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,108] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,109] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=159, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000159.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:49:43,116] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,127] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=159) with 1 segments, local-log-start-offset 0 and log-end-offset 159 in 95ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,135] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,136] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,137] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=70, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000070.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:49:43,138] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,139] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=70) with 1 segments, local-log-start-offset 0 and log-end-offset 70 in 11ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,145] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,148] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-0, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,154] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,156] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-12, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,161] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,163] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-15, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,169] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,171] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-18, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,178] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,181] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-21, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,187] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,190] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-24, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,195] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,197] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-27, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,203] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,205] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-3, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,210] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,213] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-30, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,218] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,221] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-33, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,226] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,229] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-36, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,233] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,235] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-39, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,239] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,241] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-42, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,245] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,247] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-45, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,250] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,252] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-48, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,256] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,257] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-6, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,261] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:49:43,263] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-9, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:49:43,267] INFO Loaded 19 logs in 252ms (kafka.log.LogManager)
[2025-01-16 22:49:43,269] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:49:43,270] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:49:43,334] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:49:43,350] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:49:43,366] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:49:43,389] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:49:43,748] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:49:43,769] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:49:43,774] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:49:43,791] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,792] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,792] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,793] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,794] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,803] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:49:43,804] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:49:43,843] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:49:43,854] INFO Stat of the created znode at /brokers/ids/0 is: 736,736,1737042583851,1737042583851,1,0,0,72062772505935875,202,0,736
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:49:43,856] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 736 (kafka.zk.KafkaZkClient)
[2025-01-16 22:49:43,892] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,899] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,900] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,914] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:43,921] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:43,943] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:49:43,946] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:49:43,946] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:49:43,996] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:49:43,998] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:49:43,999] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:49:44,002] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:49:44,030] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:49:44,065] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:49:44,067] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:49:44,070] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:49:44,071] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:49:44,071] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:49:44,072] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:49:44,078] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:49:44,079] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:49:44,079] INFO Kafka startTimeMs: 1737042584073 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:49:44,081] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:49:44,166] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:49:44,191] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, kafka-chat-1, __consumer_offsets-36, __consumer_offsets-48, kafka-chat-0, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:49:44,203] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,213] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,214] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:49:44,217] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,220] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,223] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,227] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,230] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,234] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,237] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,244] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 70 (kafka.cluster.Partition)
[2025-01-16 22:49:44,248] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,251] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,254] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,257] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,261] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,264] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,267] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,270] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:49:44,273] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 159 (kafka.cluster.Partition)
[2025-01-16 22:49:44,280] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,281] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,283] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,284] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,284] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,285] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,285] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,286] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,286] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,287] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,288] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,288] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,288] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,289] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,289] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,290] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,291] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,291] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,293] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,294] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,294] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,295] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,296] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,297] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,298] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,298] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,298] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,299] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,301] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,301] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,301] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,302] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,303] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,303] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,304] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,304] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,304] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,305] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,305] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,306] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,307] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,307] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,309] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:49:44,309] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,309] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:49:44,311] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:50:33,155] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: kafka-chat-0, kafka-chat-1, kafka-chat-2. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:50:33,164] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:50:33,165] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:50:33,170] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:50:33,171] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:50:33,175] WARN Failed atomic move of D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 to D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.0103ba57fd6d4270887f127bc61efd01-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 -> D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.0103ba57fd6d4270887f127bc61efd01-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:332)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1437)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-16 22:50:33,181] ERROR Error while renaming dir for kafka-chat-0 in log dir D:\DA_project\kafka\.\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 -> D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.0103ba57fd6d4270887f127bc61efd01-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:422)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1437)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1575)
	Suppressed: java.nio.file.AccessDeniedException: D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 -> D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.0103ba57fd6d4270887f127bc61efd01-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:332)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1437)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2025-01-16 22:50:33,188] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\DA_project\kafka\.\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2025-01-16 22:50:33,195] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:50:33,196] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:50:33,202] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-30,__consumer_offsets-21,__consumer_offsets-33,__consumer_offsets-36,__consumer_offsets-48,__consumer_offsets-6,__consumer_offsets-0,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-9,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-39,__consumer_offsets-12 and stopped moving logs for partitions  because they are in the failed log directory D:\DA_project\kafka\.\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2025-01-16 22:50:33,203] WARN Stopping serving logs in dir D:\DA_project\kafka\.\tmp\kafka-logs (kafka.log.LogManager)
[2025-01-16 22:50:33,205] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:50:33,205] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:50:33,205] ERROR Shutdown broker because all log dirs in D:\DA_project\kafka\.\tmp\kafka-logs have failed (kafka.log.LogManager)
[2025-01-16 22:50:33,690] WARN Close of session 0x10004b5b4bf0003 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-16 22:50:51,724] INFO Expiring session 0x10004b5b4bf0003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:51:00,046] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:51:00,212] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:51:00,283] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:51:00,284] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:51:00,304] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:00,308] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,309] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,309] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,310] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,310] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,310] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,322] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,324] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,324] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,324] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,325] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,325] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,325] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,326] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,326] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,326] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,326] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,326] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,328] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:00,357] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:51:00,363] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:00,364] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:00,366] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:00,368] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62055, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:00,387] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10004b5b4bf0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:00,389] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:00,555] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:51:00,596] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:51:00,663] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:00,663] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:00,664] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:00,666] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:00,707] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,718] INFO Recovering 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:51:00,752] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for kafka-chat-0. (kafka.log.LogLoader)
[2025-01-16 22:51:00,754] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,755] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,756] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000159.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:51:00,757] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,791] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 159 with 2 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:51:00,802] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 159 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,803] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,803] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=159, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000159.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:51:00,806] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,816] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=159) with 1 segments, local-log-start-offset 0 and log-end-offset 159 in 92ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,819] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for kafka-chat-1. (kafka.log.LogLoader)
[2025-01-16 22:51:00,820] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,820] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,821] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000070.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:51:00,821] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,828] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 70 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:51:00,833] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 70 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,834] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,835] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=70, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000070.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:51:00,837] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 70 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,839] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=70) with 1 segments, local-log-start-offset 0 and log-end-offset 70 in 22ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,842] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-0. (kafka.log.LogLoader)
[2025-01-16 22:51:00,844] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,844] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,845] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,851] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,852] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,853] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,855] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-0, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,857] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-12. (kafka.log.LogLoader)
[2025-01-16 22:51:00,858] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,859] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,860] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,867] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,868] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,869] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,873] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-12, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,877] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-15. (kafka.log.LogLoader)
[2025-01-16 22:51:00,878] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,879] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,880] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,885] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,886] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,887] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,891] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-15, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,896] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-18. (kafka.log.LogLoader)
[2025-01-16 22:51:00,897] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,898] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,899] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,905] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,906] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,907] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,910] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-18, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,914] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-21. (kafka.log.LogLoader)
[2025-01-16 22:51:00,915] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,916] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,917] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,923] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,924] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,925] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,928] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-21, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,930] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-24. (kafka.log.LogLoader)
[2025-01-16 22:51:00,931] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,932] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,932] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,936] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,937] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,938] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,939] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-24, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,942] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-27. (kafka.log.LogLoader)
[2025-01-16 22:51:00,942] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,943] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,943] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,947] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,948] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,949] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,951] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-27, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,954] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-3. (kafka.log.LogLoader)
[2025-01-16 22:51:00,954] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,955] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,955] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,958] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,959] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,960] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,961] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-3, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,964] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-30. (kafka.log.LogLoader)
[2025-01-16 22:51:00,964] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,965] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,966] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,970] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,970] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,971] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,973] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-30, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,975] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-33. (kafka.log.LogLoader)
[2025-01-16 22:51:00,976] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,976] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,977] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,980] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,981] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,982] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,984] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-33, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,986] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-36. (kafka.log.LogLoader)
[2025-01-16 22:51:00,987] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,988] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,988] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,993] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,993] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,994] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:00,996] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-36, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:00,998] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-39. (kafka.log.LogLoader)
[2025-01-16 22:51:00,999] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,000] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,000] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,004] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,005] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,005] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,007] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-39, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:01,010] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-42. (kafka.log.LogLoader)
[2025-01-16 22:51:01,010] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,011] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,011] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,015] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,016] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,017] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,018] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-42, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:01,021] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-45. (kafka.log.LogLoader)
[2025-01-16 22:51:01,022] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,022] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,022] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,026] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,026] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,027] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,029] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-45, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:01,031] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-48. (kafka.log.LogLoader)
[2025-01-16 22:51:01,032] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,033] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,033] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,036] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,037] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,038] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,039] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-48, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:01,042] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-6. (kafka.log.LogLoader)
[2025-01-16 22:51:01,042] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,043] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,043] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,046] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,047] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,048] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,050] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-6, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:01,052] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for __consumer_offsets-9. (kafka.log.LogLoader)
[2025-01-16 22:51:01,053] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,053] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,054] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,058] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,058] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,059] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:01,061] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-9, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:51:01,064] INFO Loaded 19 logs in 356ms (unclean log dirs = ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs)) (kafka.log.LogManager)
[2025-01-16 22:51:01,067] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:51:01,068] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:51:01,128] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:51:01,143] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:51:01,157] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:51:01,175] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:01,490] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:51:01,507] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:51:01,511] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:01,529] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,530] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,531] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,531] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,531] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,541] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:51:01,541] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:51:01,578] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:51:01,591] INFO Stat of the created znode at /brokers/ids/0 is: 795,795,1737042661586,1737042661586,1,0,0,72062772505935876,202,0,795
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:51:01,592] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 795 (kafka.zk.KafkaZkClient)
[2025-01-16 22:51:01,628] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,637] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,637] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,652] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:01,660] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:01,681] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:51:01,684] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:51:01,684] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:51:01,747] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:51:01,749] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:51:01,749] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:01,752] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:51:01,784] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:51:01,811] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:51:01,813] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:51:01,817] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:51:01,818] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:51:01,818] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:51:01,819] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:51:01,823] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:01,824] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:01,824] INFO Kafka startTimeMs: 1737042661819 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:01,826] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:51:01,927] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:01,933] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:51:01,943] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:01,944] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,951] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,954] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,957] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,959] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,962] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,965] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,968] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,971] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,975] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,978] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,980] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,985] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,988] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,991] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,994] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:01,997] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:51:02,003] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 70 (kafka.cluster.Partition)
[2025-01-16 22:51:02,003] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 159 (kafka.cluster.Partition)
[2025-01-16 22:51:02,008] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,009] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,011] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,011] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,012] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,013] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,013] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,013] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,014] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,014] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,014] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,015] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,015] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,016] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,017] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,017] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,018] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,019] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,019] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,020] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,021] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,021] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,022] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,023] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,023] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,023] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,025] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,025] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,025] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,026] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,026] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,026] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,027] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,027] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,028] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,028] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,029] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,029] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,030] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,030] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,030] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,031] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,031] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,031] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,032] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:02,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,033] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,034] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:51:02,043] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: kafka-chat-0, kafka-chat-1. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:08,709] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='kafka-chat', numPartitions=3, replicationFactor=2, assignments=[], configs=[]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 2 larger than available brokers: 1.
[2025-01-16 22:51:19,549] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:51:19,722] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:51:19,793] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:51:19,794] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:51:19,813] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:19,818] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,819] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,820] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,821] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,821] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,821] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,831] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,834] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,835] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,835] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,835] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,835] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,835] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,836] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,836] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,836] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,836] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,837] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,838] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:19,867] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:51:19,872] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:19,874] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:19,875] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:19,877] INFO Socket connection established, initiating session, client: /127.0.0.1:62068, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:19,883] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004b5b4bf0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:19,886] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:20,036] INFO Cluster ID = DhNFLOehSsOe18ZpukuZXA (kafka.server.KafkaServer)
[2025-01-16 22:51:20,074] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:51:20,153] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:20,154] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:20,154] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:20,156] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:20,196] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,209] INFO Skipping recovery of 18 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:51:20,269] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 159 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,270] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,271] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=159, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000159.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:51:20,278] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 159 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,288] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=159) with 1 segments, local-log-start-offset 0 and log-end-offset 159 in 74ms (1/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,295] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 55 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,296] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 55 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,297] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=55, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000055.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:51:20,298] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 55 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,300] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=BOebwcM7SIGiwrLcbzAIzA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=55) with 1 segments, local-log-start-offset 0 and log-end-offset 55 in 10ms (2/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,305] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,308] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-11, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,314] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,316] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-14, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,321] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,323] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-17, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,328] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,330] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-2, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,334] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,335] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-20, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,340] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,342] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-23, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,346] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,348] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-26, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (9/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,354] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,356] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-29, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (10/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,359] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,360] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-32, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (11/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,365] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,367] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-35, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (12/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,371] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,372] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-38, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,376] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,377] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-41, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (14/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,381] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,384] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-44, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,387] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,389] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-47, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,393] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,395] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-5, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,398] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:51:20,400] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-8, topicId=fiIvqMSxT6SqhBjF5ijxKQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:51:20,404] INFO Loaded 18 logs in 207ms (kafka.log.LogManager)
[2025-01-16 22:51:20,406] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:51:20,407] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:51:20,468] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:51:20,483] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:51:20,501] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:51:20,524] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:20,891] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:51:20,909] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:51:20,914] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:20,931] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:20,932] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:20,933] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:20,933] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:20,934] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:20,943] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:51:20,944] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:51:20,985] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:51:20,997] INFO Stat of the created znode at /brokers/ids/1 is: 847,847,1737042680992,1737042680992,1,0,0,72062772505935877,202,0,847
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:51:20,999] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 847 (kafka.zk.KafkaZkClient)
[2025-01-16 22:51:21,005] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:51:21,006] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:51:21,007] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:51:21,010] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: kafka-chat-2, kafka-chat-0. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:21,037] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: kafka-chat-0, kafka-chat-1, kafka-chat-2. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:21,046] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:21,052] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:51:21,053] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:51:21,053] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:21,054] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:21,058] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:51:21,059] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:51:21,069] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:21,064] WARN Failed atomic move of D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 to D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.611d58168d2a4361b81deac3fbca8775-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 -> D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.611d58168d2a4361b81deac3fbca8775-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:332)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1437)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-16 22:51:21,071] ERROR Error while renaming dir for kafka-chat-0 in log dir D:\DA_project\kafka\.\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 -> D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.611d58168d2a4361b81deac3fbca8775-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:422)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1437)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1575)
	Suppressed: java.nio.file.AccessDeniedException: D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0 -> D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0.611d58168d2a4361b81deac3fbca8775-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:332)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1437)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2025-01-16 22:51:21,078] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:21,078] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\DA_project\kafka\.\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2025-01-16 22:51:21,092] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:51:21,093] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:51:21,096] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:51:21,100] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:51:21,100] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:51:21,101] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-30,__consumer_offsets-21,__consumer_offsets-33,__consumer_offsets-36,__consumer_offsets-48,__consumer_offsets-6,__consumer_offsets-0,__consumer_offsets-45,__consumer_offsets-27,__consumer_offsets-9,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-39,__consumer_offsets-12 and stopped moving logs for partitions  because they are in the failed log directory D:\DA_project\kafka\.\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2025-01-16 22:51:21,103] WARN Stopping serving logs in dir D:\DA_project\kafka\.\tmp\kafka-logs (kafka.log.LogManager)
[2025-01-16 22:51:21,106] ERROR Shutdown broker because all log dirs in D:\DA_project\kafka\.\tmp\kafka-logs have failed (kafka.log.LogManager)
[2025-01-16 22:51:21,142] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:21,176] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:51:21,192] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:51:21,194] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:51:21,197] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:51:21,198] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:51:21,198] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:51:21,199] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:51:21,202] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:21,202] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:21,202] INFO Kafka startTimeMs: 1737042681199 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:21,204] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:51:21,591] WARN Close of session 0x10004b5b4bf0004 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-16 22:51:27,264] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:51:27,265] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:51:27,269] INFO [KafkaServer id=1] No zk controller present in the metadata cache (kafka.server.KafkaServer)
[2025-01-16 22:51:30,424] WARN Session 0x10004b5b4bf0005 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 22:51:31,690] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:31,694] WARN Session 0x10004b5b4bf0005 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 22:51:32,276] INFO [KafkaServer id=1] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:51:32,276] INFO [KafkaServer id=1] No zk controller present in the metadata cache (kafka.server.KafkaServer)
[2025-01-16 22:51:33,037] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:33,037] WARN Session 0x10004b5b4bf0005 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 22:51:34,445] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:34,445] WARN Session 0x10004b5b4bf0005 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 22:51:35,773] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:35,773] WARN Session 0x10004b5b4bf0005 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 22:51:37,284] INFO [KafkaServer id=1] Retrying controlled shutdown (1 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 22:51:37,286] INFO [KafkaServer id=1] No zk controller present in the metadata cache (kafka.server.KafkaServer)
[2025-01-16 22:51:37,295] WARN [KafkaServer id=1] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2025-01-16 22:51:37,296] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:51:37,297] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:51:37,297] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:51:37,299] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:51:37,305] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:51:37,306] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:51:37,308] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:51:37,310] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,311] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,311] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,312] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:51:37,313] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,314] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,314] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,315] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:51:37,316] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:51:37,316] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:51:37,317] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:51:37,317] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:51:37,318] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:51:37,319] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:37,319] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,320] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,320] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,320] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,321] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,321] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,322] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:51:37,322] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:51:37,323] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:51:37,323] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:51:37,323] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:51:37,324] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:51:37,325] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:51:37,326] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:51:37,326] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:51:37,327] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,327] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,327] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,328] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,329] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,329] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,329] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,330] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,330] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,330] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,331] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,331] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,332] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,332] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,332] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:51:37,334] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:51:37,335] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:51:37,335] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:51:37,336] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:51:37,336] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:37,337] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:37,337] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:37,339] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:51:37,339] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:37,339] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:37,339] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:51:37,340] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:51:37,341] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:51:37,342] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:51:37,342] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:51:37,342] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:51:37,349] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:37,350] WARN Session 0x10004b5b4bf0005 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 22:51:37,429] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:51:37,433] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:51:37,434] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:51:37,434] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:51:37,435] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:37,563] INFO Session: 0x10004b5b4bf0005 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:51:37,563] INFO EventThread shut down for session: 0x10004b5b4bf0005 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:51:37,568] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:51:37,571] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,576] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,576] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,581] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,582] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,582] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,583] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,584] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,584] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,584] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,585] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,585] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:51:37,586] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:51:37,594] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:51:37,594] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:51:37,594] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:51:37,594] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:51:37,594] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:51:37,594] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:51:37,602] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:52:18,913] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,926] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,926] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,926] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,926] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,926] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:52:18,926] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:52:18,926] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-16 22:52:18,926] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-16 22:52:18,926] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-16 22:52:18,926] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,933] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,933] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,934] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,934] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-16 22:52:18,934] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-16 22:52:18,945] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@63355449 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-16 22:52:18,947] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-16 22:52:18,948] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-16 22:52:18,949] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:52:18,957] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,957] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,961] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,961] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,961] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,962] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,962] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,962] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,963] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,963] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,965] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,966] INFO Server environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,966] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,966] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,966] INFO Server environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,966] INFO Server environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,975] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,981] INFO Server environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,981] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,981] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,981] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,982] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,982] INFO Server environment:user.name=mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,982] INFO Server environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,983] INFO Server environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,983] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,983] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,983] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,984] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,984] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,984] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,985] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,985] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,985] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,985] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,985] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-16 22:52:18,988] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,988] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,990] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-16 22:52:18,990] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-16 22:52:18,991] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:52:18,992] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:52:18,992] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:52:18,993] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:52:18,993] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:52:18,993] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-16 22:52:18,995] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,996] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:18,996] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-16 22:52:18,996] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-16 22:52:18,996] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir .\tmp\zookeeper\version-2 snapdir .\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:19,002] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-16 22:52:19,003] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-16 22:52:19,005] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-16 22:52:19,026] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-16 22:52:19,056] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-16 22:52:19,057] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-16 22:52:19,058] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:52:19,058] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:52:19,063] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-16 22:52:19,064] INFO Snapshotting: 0x0 to .\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:52:19,068] INFO Snapshot loaded in 10 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-16 22:52:19,070] INFO Snapshotting: 0x0 to .\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-16 22:52:19,071] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 22:52:19,080] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-16 22:52:19,080] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-16 22:52:19,094] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-16 22:52:19,095] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-16 22:52:23,073] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:52:23,255] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:52:23,329] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:52:23,330] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:52:23,350] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:23,355] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,356] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,356] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,356] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,357] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,357] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,369] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,372] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,372] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,372] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,372] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,373] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,373] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,373] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,373] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,374] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,374] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,374] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,376] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:23,405] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:52:23,410] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:23,412] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:23,414] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:23,416] INFO Socket connection established, initiating session, client: /127.0.0.1:62084, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:23,422] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-16 22:52:23,430] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:23,433] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:23,645] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:52:23,690] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:52:23,777] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:23,777] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:23,778] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:23,780] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:23,785] INFO [KafkaServer id=0] Rewriting ./tmp/kafka-logs\meta.properties (kafka.server.KafkaServer)
[2025-01-16 22:52:23,850] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:52:23,857] INFO No logs found to be loaded in D:\DA_project\kafka\.\tmp\kafka-logs (kafka.log.LogManager)
[2025-01-16 22:52:23,869] INFO Loaded 0 logs in 18ms (kafka.log.LogManager)
[2025-01-16 22:52:23,871] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:52:23,873] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:52:23,941] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:52:23,958] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:52:23,967] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2025-01-16 22:52:23,989] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:24,292] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:52:24,318] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:52:24,324] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:24,343] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,344] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,345] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,345] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,346] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,357] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:52:24,358] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:52:24,376] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:24,395] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1737042744388,1737042744388,1,0,0,72062801224073216,202,0,25
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:24,396] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:24,440] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,447] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,448] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,449] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:24,461] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:24,462] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2025-01-16 22:52:24,469] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:24,484] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:52:24,485] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:52:24,487] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:52:24,487] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:52:24,525] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:24,535] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:24,539] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:24,543] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:24,568] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:52:24,579] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:52:24,581] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:52:24,584] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:52:24,584] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:52:24,585] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:52:24,586] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:52:24,590] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:24,590] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:24,591] INFO Kafka startTimeMs: 1737042744586 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:24,593] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:52:24,750] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:24,766] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:25,631] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:52:25,823] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:52:25,895] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:52:25,896] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:52:25,916] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:25,920] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,921] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,922] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,923] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,923] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,923] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,935] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,937] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,938] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,938] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,938] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,938] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,939] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,939] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,939] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,939] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,940] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,940] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,942] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:25,972] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:52:25,978] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:25,980] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:25,981] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:25,983] INFO Socket connection established, initiating session, client: /127.0.0.1:62092, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:25,990] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:25,994] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:26,157] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:52:26,195] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:52:26,284] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:26,284] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:26,285] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:26,288] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:26,294] INFO [KafkaServer id=1] Rewriting ./tmp/kafka-logs1\meta.properties (kafka.server.KafkaServer)
[2025-01-16 22:52:26,363] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:52:26,369] INFO No logs found to be loaded in D:\DA_project\kafka\.\tmp\kafka-logs1 (kafka.log.LogManager)
[2025-01-16 22:52:26,379] INFO Loaded 0 logs in 15ms (kafka.log.LogManager)
[2025-01-16 22:52:26,381] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:52:26,382] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:52:26,443] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:52:26,457] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:52:26,469] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:52:26,488] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:26,762] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:52:26,787] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:52:26,793] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:26,814] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,815] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,816] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,817] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,818] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,832] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:52:26,832] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:52:26,879] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:26,896] INFO Stat of the created znode at /brokers/ids/1 is: 45,45,1737042746889,1737042746889,1,0,0,72062801224073217,202,0,45
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:26,898] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 45 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:26,904] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:26,905] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:26,907] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:26,937] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,948] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,948] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:26,962] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:26,965] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:26,977] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:52:26,979] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:52:26,979] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:52:27,010] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:27,017] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:27,018] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:27,019] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:27,031] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:52:27,037] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:52:27,040] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:52:27,043] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:52:27,044] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:52:27,045] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:52:27,046] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:52:27,052] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:27,052] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:27,053] INFO Kafka startTimeMs: 1737042747047 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:27,055] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:52:27,238] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:27,252] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:28,677] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:52:28,848] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:52:28,921] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:52:28,922] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:52:28,942] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:28,947] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,947] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,948] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,948] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,948] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,949] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,960] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,962] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,963] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,963] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,963] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,963] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,964] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,964] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,964] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,964] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,965] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,965] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,967] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:52:28,995] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:52:29,001] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:29,003] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:29,005] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:29,007] INFO Socket connection established, initiating session, client: /127.0.0.1:62099, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:29,013] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:52:29,015] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:52:29,177] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:52:29,214] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:52:29,292] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:29,293] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:29,293] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:29,295] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:52:29,301] INFO [KafkaServer id=2] Rewriting ./tmp/kafka-logs2\meta.properties (kafka.server.KafkaServer)
[2025-01-16 22:52:29,368] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:52:29,374] INFO No logs found to be loaded in D:\DA_project\kafka\.\tmp\kafka-logs2 (kafka.log.LogManager)
[2025-01-16 22:52:29,384] INFO Loaded 0 logs in 15ms (kafka.log.LogManager)
[2025-01-16 22:52:29,385] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:52:29,386] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:52:29,447] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:52:29,458] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:52:29,471] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:52:29,489] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:29,758] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:52:29,780] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:52:29,786] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:29,817] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,822] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,822] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,825] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,826] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,849] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:52:29,850] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:52:29,908] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:29,923] INFO Stat of the created znode at /brokers/ids/2 is: 61,61,1737042749916,1737042749916,1,0,0,72062801224073218,202,0,61
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:29,925] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 61 (kafka.zk.KafkaZkClient)
[2025-01-16 22:52:29,929] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:29,929] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:29,930] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:29,963] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,972] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,973] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:29,987] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:29,992] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:30,005] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:52:30,008] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:52:30,008] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:52:30,041] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:30,042] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:30,042] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:52:30,043] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:52:30,065] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:52:30,072] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:52:30,075] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:52:30,078] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:52:30,079] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:52:30,079] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:52:30,080] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:52:30,085] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:30,085] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:30,086] INFO Kafka startTimeMs: 1737042750081 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:52:30,088] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:52:30,217] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:30,247] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:52:34,425] INFO Creating topic kafka-chat with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 2), 1 -> ArrayBuffer(0, 1), 2 -> ArrayBuffer(2, 0)) (kafka.zk.AdminZkClient)
[2025-01-16 22:52:34,496] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,496] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,497] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,562] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:34,564] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:34,564] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:34,577] INFO Created log for partition kafka-chat-1 in D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1 with properties {} (kafka.log.LogManager)
[2025-01-16 22:52:34,580] INFO Created log for partition kafka-chat-0 in D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0 with properties {} (kafka.log.LogManager)
[2025-01-16 22:52:34,581] INFO Created log for partition kafka-chat-2 in D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2 with properties {} (kafka.log.LogManager)
[2025-01-16 22:52:34,583] INFO [Partition kafka-chat-0 broker=1] No checkpointed highwatermark is found for partition kafka-chat-0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,584] INFO [Partition kafka-chat-1 broker=0] No checkpointed highwatermark is found for partition kafka-chat-1 (kafka.cluster.Partition)
[2025-01-16 22:52:34,587] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,587] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,587] INFO [Partition kafka-chat-2 broker=2] No checkpointed highwatermark is found for partition kafka-chat-2 (kafka.cluster.Partition)
[2025-01-16 22:52:34,591] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,614] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:34,616] INFO Created log for partition kafka-chat-2 in D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2 with properties {} (kafka.log.LogManager)
[2025-01-16 22:52:34,617] INFO [Partition kafka-chat-2 broker=0] No checkpointed highwatermark is found for partition kafka-chat-2 (kafka.cluster.Partition)
[2025-01-16 22:52:34,618] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:34,618] INFO [Partition kafka-chat-2 broker=0] Log loaded for partition kafka-chat-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,618] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:34,620] INFO Created log for partition kafka-chat-1 in D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-1 with properties {} (kafka.log.LogManager)
[2025-01-16 22:52:34,621] INFO [Partition kafka-chat-1 broker=1] No checkpointed highwatermark is found for partition kafka-chat-1 (kafka.cluster.Partition)
[2025-01-16 22:52:34,621] INFO Created log for partition kafka-chat-0 in D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-0 with properties {} (kafka.log.LogManager)
[2025-01-16 22:52:34,622] INFO [Partition kafka-chat-0 broker=2] No checkpointed highwatermark is found for partition kafka-chat-0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,622] INFO [Partition kafka-chat-1 broker=1] Log loaded for partition kafka-chat-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,622] INFO [Partition kafka-chat-0 broker=2] Log loaded for partition kafka-chat-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:34,623] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,625] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,625] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,651] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,652] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,653] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,654] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,655] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,657] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=1, host=127.0.0.1:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:34,661] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition kafka-chat-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,661] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition kafka-chat-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,662] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition kafka-chat-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,664] INFO [UnifiedLog partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-01-16 22:52:34,664] INFO [UnifiedLog partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-01-16 22:52:34,666] INFO [UnifiedLog partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2025-01-16 22:52:34,737] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition kafka-chat-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:34,742] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition kafka-chat-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:52:46,007] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(2), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(2), 6 -> ArrayBuffer(1), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(2), 9 -> ArrayBuffer(1), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(2), 12 -> ArrayBuffer(1), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(2), 15 -> ArrayBuffer(1), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(2), 18 -> ArrayBuffer(1), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(2), 21 -> ArrayBuffer(1), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(2), 24 -> ArrayBuffer(1), 25 -> ArrayBuffer(0), 26 -> ArrayBuffer(2), 27 -> ArrayBuffer(1), 28 -> ArrayBuffer(0), 29 -> ArrayBuffer(2), 30 -> ArrayBuffer(1), 31 -> ArrayBuffer(0), 32 -> ArrayBuffer(2), 33 -> ArrayBuffer(1), 34 -> ArrayBuffer(0), 35 -> ArrayBuffer(2), 36 -> ArrayBuffer(1), 37 -> ArrayBuffer(0), 38 -> ArrayBuffer(2), 39 -> ArrayBuffer(1), 40 -> ArrayBuffer(0), 41 -> ArrayBuffer(2), 42 -> ArrayBuffer(1), 43 -> ArrayBuffer(0), 44 -> ArrayBuffer(2), 45 -> ArrayBuffer(1), 46 -> ArrayBuffer(0), 47 -> ArrayBuffer(2), 48 -> ArrayBuffer(1), 49 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-16 22:52:46,083] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:46,084] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:46,087] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:52:46,092] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,093] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,094] INFO Created log for partition __consumer_offsets-37 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,095] INFO Created log for partition __consumer_offsets-35 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,096] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-01-16 22:52:46,098] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-01-16 22:52:46,098] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,098] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,099] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,101] INFO Created log for partition __consumer_offsets-3 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,105] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-01-16 22:52:46,106] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,108] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,109] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,110] INFO Created log for partition __consumer_offsets-5 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,111] INFO Created log for partition __consumer_offsets-7 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,111] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-01-16 22:52:46,112] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-01-16 22:52:46,112] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,113] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,118] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,120] INFO Created log for partition __consumer_offsets-18 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,121] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-01-16 22:52:46,122] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,123] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,125] INFO Created log for partition __consumer_offsets-22 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,126] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,127] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-01-16 22:52:46,128] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,129] INFO Created log for partition __consumer_offsets-20 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,131] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-01-16 22:52:46,132] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,137] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,140] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,140] INFO Created log for partition __consumer_offsets-39 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,141] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-01-16 22:52:46,142] INFO Created log for partition __consumer_offsets-10 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,142] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,143] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-01-16 22:52:46,144] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,144] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,146] INFO Created log for partition __consumer_offsets-41 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,147] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-01-16 22:52:46,148] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,154] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,154] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,156] INFO Created log for partition __consumer_offsets-31 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,156] INFO Created log for partition __consumer_offsets-9 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,157] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-01-16 22:52:46,157] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-01-16 22:52:46,158] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,158] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,160] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,162] INFO Created log for partition __consumer_offsets-29 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,163] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-01-16 22:52:46,164] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,168] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,169] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,170] INFO Created log for partition __consumer_offsets-46 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,171] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-01-16 22:52:46,171] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,171] INFO Created log for partition __consumer_offsets-24 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,172] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-01-16 22:52:46,173] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,175] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,177] INFO Created log for partition __consumer_offsets-44 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,178] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-01-16 22:52:46,179] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,184] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,185] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,187] INFO Created log for partition __consumer_offsets-1 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,188] INFO Created log for partition __consumer_offsets-27 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,188] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-01-16 22:52:46,189] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-01-16 22:52:46,189] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,189] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,190] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,192] INFO Created log for partition __consumer_offsets-14 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,193] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-01-16 22:52:46,193] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,199] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,199] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,200] INFO Created log for partition __consumer_offsets-16 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,201] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-01-16 22:52:46,201] INFO Created log for partition __consumer_offsets-42 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,202] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,202] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-01-16 22:52:46,203] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,204] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,205] INFO Created log for partition __consumer_offsets-2 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,207] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-01-16 22:52:46,207] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,214] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,214] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,216] INFO Created log for partition __consumer_offsets-12 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,216] INFO Created log for partition __consumer_offsets-19 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,217] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-01-16 22:52:46,218] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-01-16 22:52:46,218] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,218] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,221] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,223] INFO Created log for partition __consumer_offsets-23 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,224] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-01-16 22:52:46,225] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,230] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,232] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,234] INFO Created log for partition __consumer_offsets-33 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,235] INFO Created log for partition __consumer_offsets-34 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,236] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-01-16 22:52:46,236] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-01-16 22:52:46,237] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,237] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,239] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,240] INFO Created log for partition __consumer_offsets-38 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,241] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-01-16 22:52:46,242] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,249] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,250] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,251] INFO Created log for partition __consumer_offsets-48 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,252] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-01-16 22:52:46,253] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,253] INFO Created log for partition __consumer_offsets-4 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,255] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-01-16 22:52:46,255] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,256] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,257] INFO Created log for partition __consumer_offsets-8 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,258] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-01-16 22:52:46,259] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,267] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,267] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,269] INFO Created log for partition __consumer_offsets-25 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,270] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-01-16 22:52:46,269] INFO Created log for partition __consumer_offsets-21 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,270] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,271] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-01-16 22:52:46,271] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,272] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,273] INFO Created log for partition __consumer_offsets-11 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,274] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-01-16 22:52:46,275] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,282] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,284] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,284] INFO Created log for partition __consumer_offsets-40 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,285] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-01-16 22:52:46,285] INFO Created log for partition __consumer_offsets-36 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,286] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,286] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-01-16 22:52:46,287] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,290] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,292] INFO Created log for partition __consumer_offsets-26 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,294] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-01-16 22:52:46,294] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,298] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,300] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,300] INFO Created log for partition __consumer_offsets-6 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,301] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-01-16 22:52:46,302] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,302] INFO Created log for partition __consumer_offsets-43 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,303] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-01-16 22:52:46,304] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,305] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,306] INFO Created log for partition __consumer_offsets-47 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,308] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-01-16 22:52:46,308] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,312] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,314] INFO Created log for partition __consumer_offsets-45 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,315] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,315] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-01-16 22:52:46,316] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,317] INFO Created log for partition __consumer_offsets-13 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,318] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-01-16 22:52:46,319] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,321] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,322] INFO Created log for partition __consumer_offsets-17 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,323] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-01-16 22:52:46,324] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,327] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,329] INFO Created log for partition __consumer_offsets-15 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,330] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,330] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-01-16 22:52:46,331] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,332] INFO Created log for partition __consumer_offsets-28 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,333] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-01-16 22:52:46,334] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,334] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,335] INFO Created log for partition __consumer_offsets-32 in D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,336] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-01-16 22:52:46,337] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,341] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,342] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,343] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,343] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,345] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,345] INFO Created log for partition __consumer_offsets-30 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,345] INFO Created log for partition __consumer_offsets-49 in D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,346] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,346] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-01-16 22:52:46,346] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-01-16 22:52:46,347] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,347] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,348] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,347] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,349] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,349] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,350] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,351] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,352] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,352] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,352] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,353] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 7 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,355] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,354] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,357] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,357] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,357] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,358] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,357] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,359] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,358] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,359] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:52:46,360] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,359] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,361] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,360] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,362] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,361] INFO Created log for partition __consumer_offsets-0 in D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-16 22:52:46,361] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,363] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,363] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,362] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,364] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:52:46,364] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 6 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,364] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,364] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,365] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,365] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,366] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,366] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,368] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,367] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,369] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,368] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,368] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,369] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,370] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,370] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,370] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,370] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,371] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,371] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,372] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,372] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,372] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,373] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,373] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,373] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,374] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,374] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,375] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,375] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,375] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,376] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,376] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,374] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,377] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,374] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,376] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,378] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,377] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,379] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,379] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,379] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,378] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,379] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 4 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,380] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 7 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,380] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,380] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,380] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,381] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,381] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,381] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,381] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,382] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,382] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,383] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,383] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,384] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,383] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,384] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,384] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,385] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,385] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,385] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,386] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,386] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,386] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,387] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 4 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,387] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,388] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,387] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,388] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,388] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,389] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,389] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,390] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,390] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,390] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,391] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,391] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,391] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,392] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,392] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,393] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,393] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,393] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,395] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,395] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,395] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,395] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,395] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,395] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,397] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,397] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,397] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,397] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,397] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,399] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,399] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,399] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,400] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,401] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,401] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,402] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,403] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,403] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,404] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,405] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,405] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,405] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,407] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,407] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,407] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,409] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,409] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,409] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,411] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:52:46,468] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,480] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,493] INFO [GroupCoordinator 0]: Stabilized group kafka-sandbox generation 1 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:52:46,513] INFO [GroupCoordinator 0]: Assignment received from leader consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8 for group kafka-sandbox for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:23,122] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:53:23,127] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:53:23,157] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,158] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,162] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:23,163] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,164] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 96 due to node 2 being disconnected (elapsed time since creation: 63ms, elapsed time since send: 63ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,165] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=286831548, epoch=94) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:53:23,169] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:23,169] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:23,172] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,172] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:23,175] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,178] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 39ms (kafka.server.KafkaServer)
[2025-01-16 22:53:23,178] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:23,180] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,181] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 95 due to node 1 being disconnected (elapsed time since creation: 175ms, elapsed time since send: 175ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,183] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=235601114, epoch=95) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:53:23,183] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:23,190] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:23,190] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:23,191] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:23,191] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:23,193] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:53:23,193] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,195] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:23,197] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,198] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 2 being disconnected (elapsed time since creation: 16ms, elapsed time since send: 16ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,201] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,202] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:53:23,203] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:53:23,206] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:53:23,208] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,209] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,209] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,211] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:53:23,211] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,212] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,212] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,214] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:53:23,215] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:53:23,215] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:23,216] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:23,216] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:23,217] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:53:23,218] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:23,218] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,219] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,219] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,219] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,220] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,220] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,221] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:23,221] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:53:23,222] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:23,222] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:23,222] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:23,223] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,224] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:23,225] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:23,225] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:23,226] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,226] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,226] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,227] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,227] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,227] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,228] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,228] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,228] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,229] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,230] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,230] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,231] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,231] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,231] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:23,237] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:23,237] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:23,237] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:23,239] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:53:23,239] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:23,240] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:23,240] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:23,242] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:53:23,242] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:23,243] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:23,243] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:23,244] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:53:23,245] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:53:23,246] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:23,246] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:23,246] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:23,294] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 3 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:53:23,306] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 1 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:53:23,312] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,313] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,314] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,359] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:53:23,363] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:23,363] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:23,363] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:23,365] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:23,370] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:23,485] INFO Session: 0x10004bc647b0002 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:23,485] INFO EventThread shut down for session: 0x10004bc647b0002 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:53:23,488] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:23,491] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,497] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,497] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,501] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,503] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,503] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,506] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,507] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,507] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,508] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,508] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,508] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:23,509] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:53:23,519] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:53:23,520] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:53:23,520] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:53:23,521] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:53:23,522] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:53:23,522] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:53:23,523] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:53:38,218] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:53:38,420] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:53:38,495] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:53:38,496] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:53:38,517] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:38,522] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,522] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,523] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,523] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,524] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,524] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,537] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,540] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,540] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,541] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,541] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,542] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,542] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,542] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,542] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,543] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,543] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,543] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,545] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:38,575] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:53:38,581] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:53:38,583] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:38,584] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:53:38,586] INFO Socket connection established, initiating session, client: /127.0.0.1:62178, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:53:38,591] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:53:38,594] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:38,765] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:53:38,809] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:53:38,876] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:38,877] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:38,877] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:38,879] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:38,923] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:38,935] INFO Skipping recovery of 18 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:53:38,988] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:38,989] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:38,990] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-0\00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:53:38,997] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,007] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-0, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 67ms (1/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,013] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,014] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,014] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:53:39,016] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,018] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 10ms (2/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,023] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,026] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-11, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,033] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,035] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-14, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (4/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,041] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,043] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-17, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,048] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,050] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-2, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,054] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,056] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-20, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,059] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,062] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-23, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,066] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,069] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-26, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (9/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,073] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,075] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-29, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,081] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,083] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-32, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (11/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,086] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,087] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-35, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (12/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,092] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,093] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-38, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,097] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,099] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-41, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,103] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,105] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-44, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,109] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,111] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-47, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,114] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,116] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-5, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,120] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:53:39,121] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-8, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-16 22:53:39,125] INFO Loaded 18 logs in 200ms (kafka.log.LogManager)
[2025-01-16 22:53:39,127] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:53:39,128] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:53:39,190] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:39,208] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:39,223] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:53:39,246] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:39,583] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:53:39,600] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:53:39,605] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:39,622] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,623] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,623] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,624] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,625] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,635] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:39,636] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:39,678] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:53:39,692] INFO Stat of the created znode at /brokers/ids/2 is: 211,211,1737042819686,1737042819686,1,0,0,72062801224073219,202,0,211
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:53:39,694] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 211 (kafka.zk.KafkaZkClient)
[2025-01-16 22:53:39,699] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:39,699] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:39,700] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:39,738] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,745] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,746] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,757] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:39,767] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:39,783] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:53:39,786] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:39,786] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:53:39,816] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:39,816] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:39,817] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:39,842] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:39,878] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:39,901] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:53:39,903] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:53:39,907] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:53:39,907] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:53:39,908] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:53:39,909] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:53:39,914] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:53:39,915] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:53:39,915] INFO Kafka startTimeMs: 1737042819909 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:53:39,917] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-16 22:53:40,003] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:40,009] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,011] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 3 (kafka.cluster.Partition)
[2025-01-16 22:53:40,013] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,014] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,015] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,015] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,016] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,017] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,018] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,018] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,019] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,019] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,019] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,020] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,020] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,021] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,021] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:53:40,022] INFO [Partition kafka-chat-0 broker=2] Log loaded for partition kafka-chat-0 with initial high watermark 1 (kafka.cluster.Partition)
[2025-01-16 22:53:40,023] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:40,034] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:40,043] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:40,045] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=1, host=127.0.0.1:9093),1,1)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:40,049] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:40,049] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),1,3)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:40,082] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:40,102] INFO [Partition kafka-chat-2 broker=0] ISR updated to 0,2  and version updated to 2 (kafka.cluster.Partition)
[2025-01-16 22:53:40,109] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,2  and version updated to 2 (kafka.cluster.Partition)
[2025-01-16 22:53:40,135] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,136] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,137] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,138] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,138] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,139] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,139] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,140] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,140] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,141] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,141] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 44 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,141] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,142] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 4 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,142] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 14 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,143] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,143] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,144] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,144] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,145] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,146] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,146] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,147] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,147] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,148] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,149] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,149] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 38 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,150] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,151] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,151] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 2 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,152] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,153] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,153] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,154] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,154] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,154] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,155] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,155] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,156] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,157] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,157] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,157] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,158] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,158] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,158] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,159] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:40,159] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:40,161] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:53:44,969] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:53:44,975] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:53:44,985] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:44,986] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:44,991] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:44,992] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2025-01-16 22:53:44,996] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:44,997] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:44,997] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:44,998] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:44,999] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:44,999] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:53:45,000] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:45,002] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:53:45,002] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:45,009] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,009] INFO [Controller id=0, targetBrokerId=1] Cancelled in-flight STOP_REPLICA request with correlation id 18 due to node 1 being disconnected (elapsed time since creation: 18ms, elapsed time since send: 18ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,011] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,013] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:53:45,013] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:45,014] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:53:45,014] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,017] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 139 due to node 0 being disconnected (elapsed time since creation: 167ms, elapsed time since send: 167ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,018] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=382054399, epoch=137) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:53:45,022] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:45,022] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:53:45,023] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:53:45,025] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,025] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,025] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,026] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:53:45,027] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,028] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,028] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,030] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:53:45,030] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:53:45,030] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:45,031] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:45,031] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:53:45,033] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:53:45,033] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:45,034] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,034] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,034] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,035] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,035] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,035] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,036] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:53:45,037] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:53:45,037] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:45,038] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:45,038] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:53:45,038] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:45,039] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:53:45,040] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:45,040] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:53:45,041] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,041] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,041] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,042] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,042] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,042] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,043] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,043] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,043] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,044] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,045] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,045] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,046] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,046] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,046] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:53:45,051] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:45,051] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:45,051] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:53:45,052] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:53:45,052] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:45,053] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:45,053] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:45,054] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:53:45,055] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:45,055] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:45,055] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:53:45,056] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:53:45,057] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:53:45,058] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:45,058] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:45,058] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:53:45,106] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 2 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:53:45,124] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,125] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,125] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,127] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 4 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:53:45,160] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:53:45,165] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:45,166] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:45,166] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:53:45,167] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:45,172] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:53:45,282] INFO Session: 0x10004bc647b0001 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:53:45,282] INFO EventThread shut down for session: 0x10004bc647b0001 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:53:45,285] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:53:45,288] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,289] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,289] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,290] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,290] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,290] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,291] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,291] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,291] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,292] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,292] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,292] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:53:45,295] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:53:45,303] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:53:45,303] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:53:45,304] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:53:45,304] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:53:45,305] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:53:45,306] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:53:45,306] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:54:03,266] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:54:03,446] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:54:03,523] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:54:03,524] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:54:03,545] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:03,550] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,551] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,552] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,552] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,552] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,553] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,565] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,567] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,567] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,568] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,568] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,568] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,568] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,569] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,569] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,569] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,569] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,570] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,572] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:03,601] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:54:03,606] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:03,608] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:03,609] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:03,611] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62206, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:03,617] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10004bc647b0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:03,619] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:03,792] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:54:03,832] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:54:03,912] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:03,913] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:03,913] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:03,916] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:03,969] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:03,984] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:54:04,041] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,043] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,043] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:04,051] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,061] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 71ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,068] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,068] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,069] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-1\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:04,070] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,072] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-1, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 9ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,078] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,080] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,086] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,089] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,095] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,097] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,101] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,103] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,107] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,109] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,114] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,116] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,120] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,122] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,126] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,128] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,132] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,134] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,138] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,140] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,144] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,145] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,150] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,152] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,155] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,157] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,161] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,163] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,167] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,169] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,173] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,175] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,180] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:04,181] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:54:04,184] INFO Loaded 19 logs in 215ms (kafka.log.LogManager)
[2025-01-16 22:54:04,187] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:54:04,187] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:54:04,248] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:54:04,266] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:54:04,283] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:54:04,305] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:04,678] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:54:04,697] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:54:04,702] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:04,720] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,720] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,721] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,722] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,722] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,732] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:54:04,733] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:54:04,778] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:54:04,792] INFO Stat of the created znode at /brokers/ids/1 is: 265,265,1737042844787,1737042844787,1,0,0,72062801224073220,202,0,265
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:54:04,794] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 265 (kafka.zk.KafkaZkClient)
[2025-01-16 22:54:04,797] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:04,797] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:04,798] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:04,836] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,842] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,843] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,855] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:04,864] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:04,879] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:54:04,882] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:54:04,882] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:54:04,908] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:04,909] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:04,910] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:04,926] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:04,990] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:54:05,011] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:54:05,017] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:54:05,023] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:54:05,024] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:54:05,025] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:54:05,026] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:54:05,031] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:05,032] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:05,032] INFO Kafka startTimeMs: 1737042845026 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:05,034] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:54:05,095] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:05,129] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,131] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,131] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,132] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,133] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,134] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,134] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,135] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,136] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,138] INFO [Partition kafka-chat-1 broker=1] Log loaded for partition kafka-chat-1 with initial high watermark 4 (kafka.cluster.Partition)
[2025-01-16 22:54:05,140] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:05,140] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,141] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,142] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,143] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,144] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,145] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,146] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,146] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:05,147] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 2 (kafka.cluster.Partition)
[2025-01-16 22:54:05,151] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:05,174] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:05,177] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),2,2)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:05,180] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),1,4)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:05,180] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:05,211] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:05,216] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,1  and version updated to 2 (kafka.cluster.Partition)
[2025-01-16 22:54:05,231] INFO [Partition kafka-chat-0 broker=2] ISR updated to 2,1  and version updated to 4 (kafka.cluster.Partition)
[2025-01-16 22:54:05,266] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,267] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,268] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,269] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,269] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,270] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,270] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,271] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,271] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,272] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,272] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,273] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,273] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,274] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,274] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,275] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,276] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,276] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,277] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,278] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,278] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,279] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,280] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,280] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,282] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,282] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,283] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 3 milliseconds for epoch 2, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,283] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,284] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,284] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,285] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,285] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,285] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,286] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,287] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,287] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,288] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,288] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,289] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,290] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,290] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,290] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,291] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,292] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,292] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,293] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:05,293] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,293] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:05,296] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:12,199] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:54:12,204] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:54:12,215] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:12,215] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)
[2025-01-16 22:54:12,215] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:12,215] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:12,218] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:54:12,218] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:54:12,219] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:54:12,220] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:54:12,220] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:12,221] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:12,221] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:12,225] INFO [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:12,225] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:12,225] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:12,229] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:12,229] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:54:12,230] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:54:12,230] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:12,230] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:12,233] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:54:12,235] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,236] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,236] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,238] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:54:12,239] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,240] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,240] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,243] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:54:12,244] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:54:12,245] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:54:12,246] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:54:12,246] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:54:12,248] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:54:12,248] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:12,249] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,249] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,249] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,250] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,250] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,250] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,251] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:12,252] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:54:12,252] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:54:12,253] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:54:12,253] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:54:12,254] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:12,255] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:12,255] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:54:12,256] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:54:12,256] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,257] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,257] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,258] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,259] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,259] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,260] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,260] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,260] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,261] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,261] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,261] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,262] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,262] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,262] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:12,266] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:54:12,267] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:54:12,267] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:54:12,268] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:54:12,269] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:12,269] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:12,269] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:12,270] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:54:12,271] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:12,271] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:12,271] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:12,272] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:54:12,272] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:54:12,274] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:54:12,274] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:54:12,274] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:54:12,315] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 5 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:12,345] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 17 with 0 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:12,351] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 5 with 1 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:12,380] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:54:12,386] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:54:12,387] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:54:12,387] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:54:12,388] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:12,505] INFO Session: 0x10004bc647b0000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:12,505] INFO EventThread shut down for session: 0x10004bc647b0000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:12,506] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:12,506] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,508] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,508] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,508] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,509] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,509] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,509] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,509] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,509] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,510] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,511] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,511] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:12,512] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:54:12,522] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:54:12,523] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:54:12,523] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:54:12,524] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:54:12,525] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:54:12,525] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:12,526] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:54:41,293] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:54:41,479] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:54:41,560] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:54:41,561] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:54:41,582] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:41,587] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,588] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,588] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,589] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,589] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,589] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,601] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,603] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,604] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,604] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,604] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,605] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,605] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,605] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,605] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,606] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,606] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,606] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,608] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:54:41,638] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:54:41,644] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:41,646] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:41,647] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:41,649] INFO Socket connection established, initiating session, client: /127.0.0.1:62219, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:41,656] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:54:41,659] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:54:41,822] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:54:41,861] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:54:41,959] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:41,961] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:41,963] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:41,967] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:54:42,017] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,032] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:54:42,094] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,095] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,096] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:42,103] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,113] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 74ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,118] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,119] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,120] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:42,121] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,123] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 9ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,128] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,131] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,135] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,138] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,142] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,144] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,149] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,151] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,155] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,158] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,161] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,164] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,169] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,171] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,177] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,179] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,183] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,185] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,190] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 17 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,190] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,191] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=17, file=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000017.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:54:42,192] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 17 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,193] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17) with 1 segments, local-log-start-offset 0 and log-end-offset 17 in 8ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,197] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,199] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,202] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,205] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,208] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,210] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,214] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,216] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,220] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,223] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,226] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,228] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,231] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:54:42,232] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:54:42,236] INFO Loaded 19 logs in 217ms (kafka.log.LogManager)
[2025-01-16 22:54:42,239] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:54:42,239] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:54:42,304] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:54:42,320] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:54:42,335] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:54:42,358] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:42,706] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:54:42,723] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:54:42,728] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:42,746] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,746] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,747] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,748] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,748] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,758] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:54:42,758] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:54:42,800] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:54:42,815] INFO Stat of the created znode at /brokers/ids/0 is: 323,323,1737042882808,1737042882808,1,0,0,72062801224073221,202,0,323
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:54:42,817] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 323 (kafka.zk.KafkaZkClient)
[2025-01-16 22:54:42,823] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:42,824] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:42,825] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:42,861] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,868] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,869] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,881] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:42,890] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:42,909] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:54:42,912] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:54:42,912] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:54:42,928] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:42,928] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:42,929] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:42,958] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:54:42,999] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:54:43,024] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:54:43,026] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:54:43,030] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:54:43,031] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:54:43,031] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:54:43,032] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:54:43,038] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:43,038] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:43,039] INFO Kafka startTimeMs: 1737042883033 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:54:43,041] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:54:43,121] INFO [Partition kafka-chat-2 broker=0] Log loaded for partition kafka-chat-2 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-16 22:54:43,124] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,125] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,125] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,126] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,126] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,127] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,127] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,127] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-16 22:54:43,128] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,128] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,129] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 17 (kafka.cluster.Partition)
[2025-01-16 22:54:43,129] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,129] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,130] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,130] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,131] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,131] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,131] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:43,132] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:54:43,133] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:43,149] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:43,150] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),2,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:43,154] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=1, host=127.0.0.1:9093),2,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:43,154] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:54:43,163] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:43,165] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:43,166] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:43,169] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:54:43,179] INFO [Partition kafka-chat-2 broker=2] ISR updated to 2,0  and version updated to 4 (kafka.cluster.Partition)
[2025-01-16 22:54:43,187] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:54:43,188] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:54:43,198] INFO [Partition kafka-chat-1 broker=1] ISR updated to 1,0  and version updated to 4 (kafka.cluster.Partition)
[2025-01-16 22:54:43,226] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,227] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,228] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,228] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,229] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,230] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,230] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,232] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,233] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 4 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,233] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,234] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,234] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,235] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,235] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,236] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,236] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,237] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,238] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds for epoch 2, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,239] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,240] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,240] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,240] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,241] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,242] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,242] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,243] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,243] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,244] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,244] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,245] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,245] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,245] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,246] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,246] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,247] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,247] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,258] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:54:43,265] INFO [GroupCoordinator 0]: Loading group metadata for kafka-sandbox with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:54:43,269] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 28 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,270] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 28 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,270] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,271] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,272] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 27 milliseconds for epoch 2, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,272] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,273] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:54:43,274] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 26 milliseconds for epoch 2, of which 26 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:20,030] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:55:20,035] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:55:20,049] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:20,049] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:20,057] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:20,057] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:20,058] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:20,059] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:20,060] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2025-01-16 22:55:20,063] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:20,064] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:55:20,064] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:20,065] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:20,065] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:20,068] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:55:20,074] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:20,074] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,074] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,075] INFO [Controller id=2, targetBrokerId=1] Cancelled in-flight STOP_REPLICA request with correlation id 12 due to node 1 being disconnected (elapsed time since creation: 17ms, elapsed time since send: 17ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,075] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 147 due to node 2 being disconnected (elapsed time since creation: 273ms, elapsed time since send: 273ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,077] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,076] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=390759414, epoch=147) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:55:20,077] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:55:20,080] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:20,080] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:20,080] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:55:20,083] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:55:20,085] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,085] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,085] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,087] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:55:20,088] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,088] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,088] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,090] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:55:20,091] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:55:20,091] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:20,091] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:20,091] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:20,092] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:55:20,093] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:20,093] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,094] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,094] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,095] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,095] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,095] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,096] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:20,097] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:55:20,097] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:20,097] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:20,097] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:20,098] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:20,099] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:20,100] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:55:20,100] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:55:20,101] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,101] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,101] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,102] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,103] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,103] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,103] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,104] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,104] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,105] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,105] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,105] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,106] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,106] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,106] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:20,110] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:20,111] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:20,111] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:20,111] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:55:20,112] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:20,112] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:20,112] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:20,114] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:55:20,114] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:20,115] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:20,115] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:20,116] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:55:20,117] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:55:20,118] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:20,118] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:20,118] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:20,169] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 4 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:55:20,190] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,191] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,192] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,197] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 5 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:55:20,228] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:55:20,233] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:20,233] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:20,233] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:20,235] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:20,240] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:20,348] INFO Session: 0x10004bc647b0004 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:20,348] INFO EventThread shut down for session: 0x10004bc647b0004 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:55:20,350] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:20,350] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,352] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,352] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,352] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,353] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,353] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,353] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,354] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,354] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,354] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,355] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,355] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:20,356] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:55:20,364] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:55:20,365] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:55:20,365] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:55:20,366] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:55:20,367] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:55:20,368] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:55:20,368] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:55:31,902] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:55:32,088] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:55:32,165] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:55:32,165] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:55:32,187] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:32,192] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,193] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,194] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,194] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,194] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,195] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,207] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,209] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,209] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,209] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,210] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,210] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,210] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,211] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,211] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,211] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,211] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,211] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,213] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:32,244] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:55:32,250] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:55:32,251] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:32,252] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:55:32,254] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62254, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:55:32,258] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10004bc647b0006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:55:32,261] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:32,441] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:55:32,487] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:55:32,550] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:32,551] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:32,551] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:32,553] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:32,593] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,607] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:55:32,661] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000002.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:55:32,663] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,665] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,665] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:55:32,672] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,683] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 69ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,693] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-1\00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:55:32,694] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,695] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,695] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-1\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:55:32,696] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,698] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-1, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 13ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,704] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,707] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,712] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,715] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,720] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,722] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,726] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,728] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,733] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,736] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,740] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,743] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,747] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,749] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,754] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,756] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,760] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,762] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,768] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,770] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,774] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,775] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,780] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,782] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,785] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,787] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,791] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,792] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,795] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,797] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,801] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,803] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,806] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:55:32,807] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-16 22:55:32,811] INFO Loaded 19 logs in 217ms (kafka.log.LogManager)
[2025-01-16 22:55:32,813] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:55:32,814] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:55:32,877] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:32,893] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:32,909] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:55:32,931] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:33,276] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:55:33,295] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:55:33,300] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:33,317] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,318] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,318] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,319] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,319] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,328] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:33,329] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:33,374] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:55:33,388] INFO Stat of the created znode at /brokers/ids/1 is: 378,378,1737042933382,1737042933382,1,0,0,72062801224073222,202,0,378
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:55:33,389] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 378 (kafka.zk.KafkaZkClient)
[2025-01-16 22:55:33,391] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:33,392] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:33,393] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:33,437] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,447] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,447] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,465] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,477] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,494] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:55:33,496] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:33,496] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:55:33,497] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:33,498] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:33,498] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:33,530] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:33,561] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:33,579] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:55:33,582] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:55:33,585] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:55:33,586] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:55:33,587] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:55:33,587] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:55:33,593] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:55:33,593] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:55:33,594] INFO Kafka startTimeMs: 1737042933588 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:55:33,596] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-16 22:55:33,702] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,703] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,704] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,705] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,705] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,706] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:33,706] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,707] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,708] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,709] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,710] INFO [Partition kafka-chat-1 broker=1] Log loaded for partition kafka-chat-1 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-16 22:55:33,712] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,713] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,713] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,714] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,714] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,715] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,715] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,716] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:55:33,716] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 4 (kafka.cluster.Partition)
[2025-01-16 22:55:33,718] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:33,737] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:33,738] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:33,740] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),3,4)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:33,745] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),3,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:33,745] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:33,756] INFO [Partition kafka-chat-0 broker=2] ISR updated to 2,1  and version updated to 6 (kafka.cluster.Partition)
[2025-01-16 22:55:33,767] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:33,770] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,1  and version updated to 6 (kafka.cluster.Partition)
[2025-01-16 22:55:33,821] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,822] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,823] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,824] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,824] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,825] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,825] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,826] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,826] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,827] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,827] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,827] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,828] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,831] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,832] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,832] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,833] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,833] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,835] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,836] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,837] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,838] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,839] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,840] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,840] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,840] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,842] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,842] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,842] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,843] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,843] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,844] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,845] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,845] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,846] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,846] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,846] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,848] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:33,848] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,848] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:33,849] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:55:44,302] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 22:55:44,307] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 22:55:44,322] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:44,322] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:44,325] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:44,327] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2025-01-16 22:55:44,330] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:44,331] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:44,331] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:44,331] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:55:44,332] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,333] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:55:44,334] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 21 due to node 0 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,337] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,337] INFO [Controller id=2, targetBrokerId=0] Cancelled in-flight STOP_REPLICA request with correlation id 19 due to node 0 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,338] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:44,338] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,339] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:55:44,340] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 22:55:44,335] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=289106071, epoch=21) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:55:44,341] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:44,341] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:55:44,341] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:44,346] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:44,347] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,349] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 119 due to node 2 being disconnected (elapsed time since creation: 184ms, elapsed time since send: 184ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,351] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=799552023, epoch=119) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 22:55:44,357] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:44,357] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:55:44,358] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 22:55:44,360] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,360] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,360] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,363] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 22:55:44,363] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,364] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,364] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,366] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:55:44,367] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 22:55:44,367] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:44,368] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:44,368] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:55:44,369] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:55:44,370] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:44,370] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,371] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,371] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,371] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,372] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,372] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,372] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:55:44,373] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 22:55:44,374] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:44,374] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:44,374] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:55:44,375] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:44,376] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:55:44,376] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:55:44,377] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 22:55:44,377] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,379] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,379] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,380] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,381] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,381] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,382] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,382] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,382] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,383] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,383] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,383] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,384] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,385] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,385] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:55:44,390] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:44,391] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:44,391] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:55:44,392] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 22:55:44,392] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:44,392] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:44,392] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:44,394] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:55:44,394] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:44,395] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:44,395] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:55:44,396] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 22:55:44,397] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 22:55:44,398] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:44,398] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:44,398] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:55:44,443] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,453] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,454] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,491] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 18 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:55:44,542] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 22:55:44,547] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:44,548] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:44,548] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:55:44,549] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:44,554] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:55:44,664] INFO Session: 0x10004bc647b0005 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:55:44,664] INFO EventThread shut down for session: 0x10004bc647b0005 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:55:44,669] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:55:44,669] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,671] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,671] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,671] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,671] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,671] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,672] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,672] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,672] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,673] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,673] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,673] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:55:44,674] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 22:55:44,683] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 22:55:44,684] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:55:44,685] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:55:44,685] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 22:55:44,686] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 22:55:44,687] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:55:44,687] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 22:56:00,849] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 22:56:01,036] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 22:56:01,115] INFO starting (kafka.server.KafkaServer)
[2025-01-16 22:56:01,115] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 22:56:01,136] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:56:01,140] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,141] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,141] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,142] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,142] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,142] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,154] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,156] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,156] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,156] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,156] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,157] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,157] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,157] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,158] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,158] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,158] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,158] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,160] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 22:56:01,190] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 22:56:01,197] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:56:01,199] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:56:01,200] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:56:01,202] INFO Socket connection established, initiating session, client: /127.0.0.1:62275, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:56:01,209] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 22:56:01,212] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 22:56:01,380] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 22:56:01,425] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 22:56:01,493] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:56:01,493] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:56:01,494] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:56:01,496] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 22:56:01,536] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,548] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 22:56:01,605] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,606] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,607] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:56:01,614] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,625] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 72ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,632] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,633] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,634] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:56:01,635] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,636] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,640] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,643] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,650] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,652] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,657] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,659] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,664] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,666] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,670] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,672] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,676] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,678] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,682] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,684] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,688] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,690] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,693] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,696] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,701] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000017.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 22:56:01,702] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 18 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,702] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 18 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,703] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=18, file=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000018.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 22:56:01,704] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 18 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,705] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18) with 1 segments, local-log-start-offset 0 and log-end-offset 18 in 8ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,708] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,710] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,714] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,716] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,720] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,722] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,726] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,728] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,733] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,735] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,739] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,741] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,745] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 22:56:01,747] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 22:56:01,750] INFO Loaded 19 logs in 212ms (kafka.log.LogManager)
[2025-01-16 22:56:01,752] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 22:56:01,753] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 22:56:01,814] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 22:56:01,832] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 22:56:01,849] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 22:56:01,870] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:56:02,211] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 22:56:02,231] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 22:56:02,235] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:56:02,253] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,253] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,254] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,255] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,255] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,265] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 22:56:02,265] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 22:56:02,307] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 22:56:02,321] INFO Stat of the created znode at /brokers/ids/0 is: 433,433,1737042962314,1737042962314,1,0,0,72062801224073223,202,0,433
 (kafka.zk.KafkaZkClient)
[2025-01-16 22:56:02,322] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 433 (kafka.zk.KafkaZkClient)
[2025-01-16 22:56:02,324] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:56:02,325] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:56:02,326] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:56:02,368] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,374] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,375] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,389] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,399] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,419] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:56:02,423] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 22:56:02,423] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 22:56:02,440] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:56:02,441] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:56:02,443] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 22:56:02,481] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 22:56:02,515] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 22:56:02,538] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 22:56:02,541] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 22:56:02,544] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:56:02,545] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 22:56:02,546] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:56:02,547] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 22:56:02,551] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:56:02,552] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:56:02,552] INFO Kafka startTimeMs: 1737042962547 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 22:56:02,554] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 22:56:02,631] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:56:02,638] INFO [Partition kafka-chat-2 broker=0] Log loaded for partition kafka-chat-2 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-16 22:56:02,640] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,641] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,641] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,642] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,642] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,643] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,643] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,644] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-16 22:56:02,644] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,645] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,646] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 18 (kafka.cluster.Partition)
[2025-01-16 22:56:02,646] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,647] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,648] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,648] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,649] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,649] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,650] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 22:56:02,651] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:56:02,667] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:56:02,669] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),3,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:56:02,673] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=1, host=127.0.0.1:9093),4,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:56:02,673] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 22:56:02,676] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 22:56:02,702] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 22:56:02,707] INFO [Partition kafka-chat-1 broker=1] ISR updated to 1,0  and version updated to 8 (kafka.cluster.Partition)
[2025-01-16 22:56:02,707] INFO [Partition kafka-chat-2 broker=2] ISR updated to 2,0  and version updated to 6 (kafka.cluster.Partition)
[2025-01-16 22:56:02,755] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,760] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,761] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,761] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,762] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,762] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 4 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,763] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,763] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,763] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,764] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,764] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,765] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,765] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,766] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,766] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,767] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,767] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,768] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,769] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,769] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,770] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,770] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,771] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,772] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,773] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,774] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,774] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,775] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,776] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,794] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 22:56:02,815] INFO [GroupCoordinator 0]: Loading group metadata for kafka-sandbox with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 22:56:02,822] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 51 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,824] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 52 milliseconds for epoch 4, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,826] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 53 milliseconds for epoch 4, of which 53 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,828] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 54 milliseconds for epoch 4, of which 54 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,829] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 55 milliseconds for epoch 4, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,831] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 55 milliseconds for epoch 4, of which 55 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,835] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 59 milliseconds for epoch 4, of which 58 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 22:56:02,836] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 59 milliseconds for epoch 4, of which 59 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:02,353] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: Removing member consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:02,353] INFO [GroupCoordinator 0]: Group kafka-sandbox with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:02,353] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) has left group kafka-sandbox through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:09,822] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-0a3fe36b-c656-468a-b4a5-a9337a0f05ec and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:09,829] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 2 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-0a3fe36b-c656-468a-b4a5-a9337a0f05ec with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:09,833] INFO [GroupCoordinator 0]: Stabilized group kafka-sandbox generation 3 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:09,841] INFO [GroupCoordinator 0]: Assignment received from leader consumer-kafka-sandbox-1-0a3fe36b-c656-468a-b4a5-a9337a0f05ec for group kafka-sandbox for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:14,214] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 23:02:14,219] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 23:02:14,234] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:14,235] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:14,235] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:14,235] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2025-01-16 23:02:14,236] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:02:14,240] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:02:14,241] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:02:14,242] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:14,242] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:02:14,243] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,244] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 23:02:14,244] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 727 due to node 2 being disconnected (elapsed time since creation: 66ms, elapsed time since send: 66ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,249] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,249] INFO [Controller id=2, targetBrokerId=0] Cancelled in-flight STOP_REPLICA request with correlation id 9 due to node 0 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,250] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,247] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1296959057, epoch=727) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:02:14,253] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 23:02:14,253] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:14,253] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:14,255] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 23:02:14,259] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:14,259] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,260] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 725 due to node 1 being disconnected (elapsed time since creation: 361ms, elapsed time since send: 361ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,260] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=92909636, epoch=725) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:02:14,263] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:14,263] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:14,267] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:14,268] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:02:14,269] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 23:02:14,271] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,272] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,272] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,273] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 23:02:14,274] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,274] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,274] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,276] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 23:02:14,276] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 23:02:14,276] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:02:14,277] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:02:14,277] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:02:14,278] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 23:02:14,278] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:14,279] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,280] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,280] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,280] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,281] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,281] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,282] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:14,282] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 23:02:14,283] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:02:14,283] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:02:14,283] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:02:14,284] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:14,285] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:14,286] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:02:14,287] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:02:14,287] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,287] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,287] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,288] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,289] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,289] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,289] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,290] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,290] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,290] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,291] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,291] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,291] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,292] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,292] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:14,296] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:02:14,297] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:02:14,297] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:02:14,298] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 23:02:14,298] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:14,299] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:14,299] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:14,300] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 23:02:14,301] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:14,301] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:14,301] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:14,302] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 23:02:14,302] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 23:02:14,304] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:02:14,304] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:02:14,304] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:02:14,342] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 6 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:02:14,365] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 21 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:02:14,366] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,367] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,368] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,396] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 23:02:14,403] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:02:14,403] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:02:14,403] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:02:14,404] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:02:14,409] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:14,508] INFO Session: 0x10004bc647b0007 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:14,508] INFO EventThread shut down for session: 0x10004bc647b0007 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:02:14,510] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:02:14,510] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,512] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,512] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,512] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,513] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,513] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,514] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,514] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,514] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,515] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,516] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,516] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:14,517] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 23:02:14,526] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 23:02:14,527] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 23:02:14,527] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 23:02:14,528] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 23:02:14,529] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 23:02:14,530] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 23:02:14,531] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-16 23:02:23,122] INFO [NodeToControllerChannelManager id=2 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:23,123] WARN [NodeToControllerChannelManager id=2 name=forwarding] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:23,123] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:31,157] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-16 23:02:31,327] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-16 23:02:31,404] INFO starting (kafka.server.KafkaServer)
[2025-01-16 23:02:31,405] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-16 23:02:31,427] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:02:31,431] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,432] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,432] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,433] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,433] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,433] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,445] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,448] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,448] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,448] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,448] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,449] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,449] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,449] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,449] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,450] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,450] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,450] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,452] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:02:31,481] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 23:02:31,487] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:02:31,490] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:02:31,490] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:02:31,493] INFO Socket connection established, initiating session, client: /127.0.0.1:62343, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:02:31,499] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:02:31,502] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:02:31,672] INFO Cluster ID = fwk3Db2GTHWO9UC1VyeIng (kafka.server.KafkaServer)
[2025-01-16 23:02:31,711] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-16 23:02:31,793] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:31,794] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:31,795] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:31,797] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:02:31,848] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,861] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-16 23:02:31,914] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,915] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,916] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:02:31,923] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,934] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 66ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,939] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2\00000000000000000005.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 23:02:31,940] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,941] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,941] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=6, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2\00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:02:31,942] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,944] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-2, topicId=1QcDRAdsThSXtxu8ZQ90yw, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments, local-log-start-offset 0 and log-end-offset 6 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,950] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,953] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,957] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,959] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,964] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,966] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,970] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,972] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,977] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,979] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,983] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,985] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,989] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,991] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:31,996] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:31,998] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,003] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,005] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,011] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000018.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-16 23:02:32,012] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 21 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,012] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 21 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,013] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=21, file=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000021.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:02:32,014] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 21 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,015] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=21) with 1 segments, local-log-start-offset 0 and log-end-offset 21 in 10ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,019] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,020] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,024] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,026] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,030] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,031] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,035] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,037] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,042] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,044] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,048] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,050] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,054] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-16 23:02:32,056] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7, topicId=4ewz50QjRyC4LwUTdedqdQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-16 23:02:32,060] INFO Loaded 19 logs in 210ms (kafka.log.LogManager)
[2025-01-16 23:02:32,063] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-16 23:02:32,063] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-16 23:02:32,123] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:02:32,137] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:02:32,149] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 23:02:32,168] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:32,498] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-16 23:02:32,516] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-16 23:02:32,521] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:32,537] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,538] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,539] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,539] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,540] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,550] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:02:32,551] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:02:32,594] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 23:02:32,607] INFO Stat of the created znode at /brokers/ids/0 is: 490,490,1737043352601,1737043352601,1,0,0,72062801224073224,202,0,490
 (kafka.zk.KafkaZkClient)
[2025-01-16 23:02:32,609] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 490 (kafka.zk.KafkaZkClient)
[2025-01-16 23:02:32,611] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:32,612] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:32,613] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:32,649] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,657] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,657] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,672] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:32,681] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:32,698] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 23:02:32,700] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:02:32,700] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 23:02:32,730] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:32,730] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:32,731] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:02:32,742] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:02:32,769] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:02:32,789] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-16 23:02:32,793] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-16 23:02:32,796] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 23:02:32,797] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-16 23:02:32,799] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 23:02:32,800] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-16 23:02:32,805] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 23:02:32,805] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 23:02:32,806] INFO Kafka startTimeMs: 1737043352800 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 23:02:32,808] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-16 23:02:32,903] INFO [Partition kafka-chat-2 broker=0] Log loaded for partition kafka-chat-2 with initial high watermark 6 (kafka.cluster.Partition)
[2025-01-16 23:02:32,906] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,907] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,908] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,909] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,909] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,910] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,911] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,911] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-16 23:02:32,912] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,913] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,914] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 21 (kafka.cluster.Partition)
[2025-01-16 23:02:32,915] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,916] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,917] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,918] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,918] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,919] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,920] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-16 23:02:32,922] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-1, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:32,932] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:32,951] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:32,955] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),4,6)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:32,960] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:02:32,960] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=1, host=127.0.0.1:9093),5,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:32,963] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:02:32,972] INFO [Partition kafka-chat-2 broker=2] ISR updated to 2,0  and version updated to 8 (kafka.cluster.Partition)
[2025-01-16 23:02:32,974] INFO [Partition kafka-chat-1 broker=1] ISR updated to 1,0  and version updated to 10 (kafka.cluster.Partition)
[2025-01-16 23:02:32,976] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:02:33,024] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,025] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,027] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,027] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,028] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,028] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,029] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,029] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,030] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,031] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,031] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,032] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,032] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 4 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,032] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,033] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,034] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,034] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,035] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,036] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,037] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,038] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,038] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,039] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,039] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 2 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,039] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,040] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,040] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,041] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,042] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,042] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,043] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,043] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,044] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,044] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,044] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,045] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,046] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,046] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,065] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-70f41dd8-9c17-4879-9979-eb64e4217bd8, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 23:02:33,075] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-0a3fe36b-c656-468a-b4a5-a9337a0f05ec, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-16 23:02:33,081] INFO [GroupCoordinator 0]: Loading group metadata for kafka-sandbox with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:02:33,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 46 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,088] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 46 milliseconds for epoch 6, of which 45 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,089] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 46 milliseconds for epoch 6, of which 46 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,090] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 47 milliseconds for epoch 6, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 47 milliseconds for epoch 6, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,093] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 48 milliseconds for epoch 6, of which 47 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,094] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 48 milliseconds for epoch 6, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:02:33,095] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 48 milliseconds for epoch 6, of which 48 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-16 23:06:57,246] WARN Client session timed out, have not heard from server in 18181ms for session id 0x10004bc647b0008 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:57,248] WARN Session 0x10004bc647b0008 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 18181ms for session id 0x10004bc647b0008
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2025-01-16 23:06:57,253] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:62343, session = 0x10004bc647b0008 (org.apache.zookeeper.server.NIOServerCnxn)
[2025-01-16 23:06:57,434] WARN Client session timed out, have not heard from server in 18180ms for session id 0x10004bc647b0003 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:57,435] WARN Session 0x10004bc647b0003 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 18180ms for session id 0x10004bc647b0003
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2025-01-16 23:06:57,438] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:62178, session = 0x10004bc647b0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2025-01-16 23:06:57,718] INFO Expiring session 0x10004bc647b0003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:06:57,719] INFO Expiring session 0x10004bc647b0008, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:06:57,732] WARN Client session timed out, have not heard from server in 17350ms for session id 0x10004bc647b0006 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:57,733] WARN Session 0x10004bc647b0006 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 17350ms for session id 0x10004bc647b0006
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2025-01-16 23:06:57,739] WARN Close of session 0x10004bc647b0006 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-16 23:06:59,040] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,043] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62382, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,046] INFO Invalid session 0x10004bc647b0008 for client /[0:0:0:0:0:0:0:1]:62382, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:06:59,049] WARN Unable to reconnect to ZooKeeper service, session 0x10004bc647b0008 has expired (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,050] INFO EventThread shut down for session: 0x10004bc647b0008 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,052] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:06:59,051] WARN Session 0x10004bc647b0008 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x10004bc647b0008 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 23:06:59,057] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:06:59,067] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:06:59,075] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 23:06:59,077] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,080] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,083] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 23:06:59,085] INFO Socket connection established, initiating session, client: /127.0.0.1:62383, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,104] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0009, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,108] INFO [MetadataCache brokerId=0] Updated cache from existing Some(Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 23:06:59,109] INFO Stat of the created znode at /brokers/ids/0 is: 513,513,1737043619107,1737043619107,1,0,0,72062801224073225,202,0,513
 (kafka.zk.KafkaZkClient)
[2025-01-16 23:06:59,111] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 513 (kafka.zk.KafkaZkClient)
[2025-01-16 23:06:59,280] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:06:59,280] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:06:59,285] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,285] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:06:59,286] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1316 due to node 2 being disconnected (elapsed time since creation: 206ms, elapsed time since send: 206ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:06:59,289] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,290] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:06:59,288] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1015553476, epoch=1316) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:06:59,292] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 496 due to node 2 being disconnected (elapsed time since creation: 211ms, elapsed time since send: 211ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:06:59,293] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,293] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,294] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1700808713, epoch=496) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:06:59,299] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,299] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,520] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,521] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62386, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,525] INFO Invalid session 0x10004bc647b0003 for client /[0:0:0:0:0:0:0:1]:62386, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:06:59,526] WARN Unable to reconnect to ZooKeeper service, session 0x10004bc647b0003 has expired (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,526] WARN Session 0x10004bc647b0003 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x10004bc647b0003 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 23:06:59,527] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:06:59,527] INFO EventThread shut down for session: 0x10004bc647b0003 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,531] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:06:59,531] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:06:59,534] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 23:06:59,535] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,536] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,538] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 23:06:59,538] INFO Socket connection established, initiating session, client: /127.0.0.1:62387, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,541] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b000a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,542] INFO [MetadataCache brokerId=2] Updated cache from existing Some(Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 23:06:59,543] INFO Stat of the created znode at /brokers/ids/2 is: 537,537,1737043619542,1737043619542,1,0,0,72062801224073226,202,0,537
 (kafka.zk.KafkaZkClient)
[2025-01-16 23:06:59,544] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 537 (kafka.zk.KafkaZkClient)
[2025-01-16 23:06:59,562] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:06:59,570] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=1, host=127.0.0.1:9093),5,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:06:59,570] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,576] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:06:59,576] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),6,6)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:06:59,576] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,577] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:06:59,581] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:06:59,607] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,2  and version updated to 9 (kafka.cluster.Partition)
[2025-01-16 23:06:59,662] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition kafka-chat-2 with TruncationState(offset=6, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=2, leaderEpoch=3, endOffset=6) (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:06:59,665] INFO [UnifiedLog partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.UnifiedLog)
[2025-01-16 23:06:59,667] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,669] INFO Socket connection established, initiating session, client: /127.0.0.1:62393, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,675] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b0006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:06:59,688] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:06:59,689] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:06:59,700] INFO [Partition kafka-chat-2 broker=0] ISR updated to 0,2  and version updated to 11 (kafka.cluster.Partition)
[2025-01-16 23:18:05,965] INFO [GroupCoordinator 0]: Member consumer-kafka-sandbox-1-0a3fe36b-c656-468a-b4a5-a9337a0f05ec in group kafka-sandbox has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:05,982] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 3 (__consumer_offsets-34) (reason: removing member consumer-kafka-sandbox-1-0a3fe36b-c656-468a-b4a5-a9337a0f05ec on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:05,985] INFO [NodeToControllerChannelManager id=0 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:05,992] INFO [GroupCoordinator 0]: Group kafka-sandbox with generation 4 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:05,996] INFO [NodeToControllerChannelManager id=2 name=forwarding] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:06,056] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:06,056] INFO [NodeToControllerChannelManager id=1 name=forwarding] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:06,145] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-2ab57371-16b7-4802-bd47-e750fd515476 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:06,152] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 4 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-2ab57371-16b7-4802-bd47-e750fd515476 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:06,160] INFO [GroupCoordinator 0]: Stabilized group kafka-sandbox generation 5 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:06,171] INFO [GroupCoordinator 0]: Assignment received from leader consumer-kafka-sandbox-1-2ab57371-16b7-4802-bd47-e750fd515476 for group kafka-sandbox for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:06,370] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:07,013] WARN Client session timed out, have not heard from server in 421182ms for session id 0x10004bc647b000a (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:07,014] WARN Session 0x10004bc647b000a for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 421182ms for session id 0x10004bc647b000a
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2025-01-16 23:18:07,016] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:62387, session = 0x10004bc647b000a (org.apache.zookeeper.server.NIOServerCnxn)
[2025-01-16 23:18:07,183] WARN Client session timed out, have not heard from server in 421180ms for session id 0x10004bc647b0006 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:07,183] WARN Client session timed out, have not heard from server in 421180ms for session id 0x10004bc647b0009 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:07,184] WARN Session 0x10004bc647b0009 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 421180ms for session id 0x10004bc647b0009
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2025-01-16 23:18:07,184] WARN Session 0x10004bc647b0006 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionTimeoutException: Client session timed out, have not heard from server in 421180ms for session id 0x10004bc647b0006
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1257)
[2025-01-16 23:18:07,188] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:62383, session = 0x10004bc647b0009 (org.apache.zookeeper.server.NIOServerCnxn)
[2025-01-16 23:18:07,188] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:62393, session = 0x10004bc647b0006 (org.apache.zookeeper.server.NIOServerCnxn)
[2025-01-16 23:18:07,894] INFO Expiring session 0x10004bc647b0009, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:18:07,895] INFO Expiring session 0x10004bc647b0006, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:18:07,896] INFO Expiring session 0x10004bc647b000a, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:18:08,524] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,526] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62472, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,529] INFO Invalid session 0x10004bc647b0009 for client /[0:0:0:0:0:0:0:1]:62472, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:18:08,530] WARN Unable to reconnect to ZooKeeper service, session 0x10004bc647b0009 has expired (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,530] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:08,530] INFO EventThread shut down for session: 0x10004bc647b0009 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,533] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:08,531] WARN Session 0x10004bc647b0009 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x10004bc647b0009 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 23:18:08,534] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:18:08,542] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 23:18:08,543] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,545] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,545] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:08,546] INFO Socket connection established, initiating session, client: /127.0.0.1:62473, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,550] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b000b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:08,554] INFO [MetadataCache brokerId=0] Updated cache from existing Some(Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 23:18:08,555] INFO Stat of the created znode at /brokers/ids/0 is: 560,560,1737044288552,1737044288552,1,0,0,72062801224073227,202,0,560
 (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:08,557] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 560 (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:08,645] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:08,671] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:08,676] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:08,677] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:08,678] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 993 due to node 1 being disconnected (elapsed time since creation: 134ms, elapsed time since send: 134ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:08,679] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=874649611, epoch=993) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:18:08,685] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:08,685] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,014] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,015] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:62476, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,017] INFO Invalid session 0x10004bc647b000a for client /[0:0:0:0:0:0:0:1]:62476, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:18:09,018] WARN Unable to reconnect to ZooKeeper service, session 0x10004bc647b000a has expired (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,018] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:09,018] INFO EventThread shut down for session: 0x10004bc647b000a (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,019] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:09,018] WARN Session 0x10004bc647b000a for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x10004bc647b000a has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 23:18:09,020] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:18:09,026] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 23:18:09,027] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,028] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:09,028] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,030] INFO Socket connection established, initiating session, client: /127.0.0.1:62477, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,034] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b000c, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,036] INFO [MetadataCache brokerId=2] Updated cache from existing Some(Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 23:18:09,038] INFO Stat of the created znode at /brokers/ids/2 is: 602,602,1737044289035,1737044289035,1,0,0,72062801224073228,202,0,602
 (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:09,038] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 602 (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:09,051] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,052] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),7,6)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,076] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-11, kafka-chat-0, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,123] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,125] INFO Socket connection established, initiating session, client: /127.0.0.1:62479, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,126] INFO Invalid session 0x10004bc647b0006 for client /127.0.0.1:62479, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-16 23:18:09,128] WARN Unable to reconnect to ZooKeeper service, session 0x10004bc647b0006 has expired (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,131] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,128] WARN Session 0x10004bc647b0006 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
org.apache.zookeeper.ClientCnxn$SessionExpiredException: Unable to reconnect to ZooKeeper service, session 0x10004bc647b0006 has expired
	at org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1439)
	at org.apache.zookeeper.ClientCnxnSocket.readConnectResult(ClientCnxnSocket.java:154)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:86)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 23:18:09,132] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:09,129] INFO EventThread shut down for session: 0x10004bc647b0006 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,132] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 498 due to node 1 being disconnected (elapsed time since creation: 84ms, elapsed time since send: 84ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:09,133] INFO [ZooKeeperClient Kafka server] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:09,134] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1162479363, epoch=498) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:18:09,139] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,139] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,140] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:09,144] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Partition kafka-chat-2 has a newer epoch (7) than the current leader. Retry the partition later. (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,141] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:18:09,150] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-16 23:18:09,151] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,155] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,156] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:09,156] INFO Socket connection established, initiating session, client: /127.0.0.1:62480, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,160] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10004bc647b000d, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:09,163] INFO [MetadataCache brokerId=1] Updated cache from existing Some(Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0)) to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-16 23:18:09,165] INFO Stat of the created znode at /brokers/ids/1 is: 621,621,1737044289162,1737044289162,1,0,0,72062801224073229,202,0,621
 (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:09,166] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 621 (kafka.zk.KafkaZkClient)
[2025-01-16 23:18:09,179] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,189] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=2, host=127.0.0.1:9094),8,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,190] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,195] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(1QcDRAdsThSXtxu8ZQ90yw),BrokerEndPoint(id=0, host=127.0.0.1:9092),7,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,197] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition kafka-chat-0 with TruncationState(offset=5, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=0, leaderEpoch=3, endOffset=5) (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,200] INFO [UnifiedLog partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.UnifiedLog)
[2025-01-16 23:18:09,200] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,204] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition kafka-chat-1 with TruncationState(offset=5, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=1, leaderEpoch=1, endOffset=5) (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:09,206] INFO [UnifiedLog partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.UnifiedLog)
[2025-01-16 23:18:09,208] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Client requested disconnect from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:09,209] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:09,209] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:09,217] INFO [Partition kafka-chat-1 broker=0] ISR updated to 0,1  and version updated to 13 (kafka.cluster.Partition)
[2025-01-16 23:18:09,223] INFO [Partition kafka-chat-0 broker=2] ISR updated to 2,1  and version updated to 13 (kafka.cluster.Partition)
[2025-01-16 23:18:10,177] INFO [Partition kafka-chat-2 broker=0] ISR updated to 0,2  and version updated to 13 (kafka.cluster.Partition)
[2025-01-16 23:18:11,244] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-16 23:18:11,249] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 23:18:11,290] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,290] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,294] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:11,295] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:11,295] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:11,298] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,298] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,299] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:11,301] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 39ms (kafka.server.KafkaServer)
[2025-01-16 23:18:11,305] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:18:11,306] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:18:11,306] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-16 23:18:11,307] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:11,309] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,309] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-16 23:18:11,310] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 501 due to node 0 being disconnected (elapsed time since creation: 133ms, elapsed time since send: 133ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,315] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,316] INFO [Controller id=0, targetBrokerId=2] Cancelled in-flight STOP_REPLICA request with correlation id 15 due to node 2 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,312] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1233169003, epoch=2) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:18:11,318] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:11,318] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:11,319] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,319] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-16 23:18:11,320] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,320] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 23:18:11,322] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:11,325] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-16 23:18:11,328] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,329] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,329] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,330] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-16 23:18:11,331] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,332] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,332] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,334] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 23:18:11,336] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-16 23:18:11,337] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:18:11,337] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:18:11,337] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-16 23:18:11,340] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-16 23:18:11,341] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:11,341] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,342] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,342] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,344] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,345] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,345] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,346] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-16 23:18:11,348] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-16 23:18:11,349] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:18:11,349] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:18:11,349] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-16 23:18:11,350] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,351] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:11,353] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:11,354] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:11,354] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,355] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,355] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,356] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,356] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,356] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,358] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,359] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,359] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,360] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,360] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,360] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,361] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,362] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,362] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-16 23:18:11,370] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:18:11,371] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:18:11,371] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-16 23:18:11,372] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-16 23:18:11,373] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:11,373] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:11,373] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:11,375] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 23:18:11,376] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:11,377] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:11,377] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-16 23:18:11,378] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-16 23:18:11,379] INFO Shutting down. (kafka.log.LogManager)
[2025-01-16 23:18:11,381] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:18:11,382] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:18:11,382] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-16 23:18:11,429] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,430] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,431] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,443] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 6 with 1 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:18:11,458] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 5 with 2 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-16 23:18:11,524] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-16 23:18:11,526] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:18:11,527] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:18:11,527] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-16 23:18:11,528] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:11,533] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:11,633] INFO EventThread shut down for session: 0x10004bc647b000c (org.apache.zookeeper.ClientCnxn)
[2025-01-16 23:18:11,633] INFO Session: 0x10004bc647b000c closed (org.apache.zookeeper.ZooKeeper)
[2025-01-16 23:18:11,634] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-16 23:18:11,635] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,636] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,636] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,637] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,638] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,638] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,639] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,639] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,639] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,640] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,641] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,641] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-16 23:18:11,642] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-16 23:18:11,650] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-16 23:18:11,651] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 23:18:11,652] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 23:18:11,652] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-16 23:18:11,653] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-16 23:18:11,654] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-16 23:18:11,655] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-16 23:18:14,627] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-16 23:18:14,629] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 23:18:14,642] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:14,643] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:14,648] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:14,649] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:14,650] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 11 due to node 0 being disconnected (elapsed time since creation: 358ms, elapsed time since send: 358ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-16 23:18:14,653] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:14,652] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1067014635, epoch=11) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-16 23:18:14,655] INFO [KafkaServer id=1] Controlled shutdown request returned after 20ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 23:18:14,658] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:14,658] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-16 23:18:14,661] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:14,662] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:17,584] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-16 23:18:17,590] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-16 23:18:17,614] INFO [KafkaServer id=0] Controlled shutdown request returned after 9ms with 2 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 23:18:19,660] INFO [KafkaServer id=1] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2025-01-16 23:18:19,668] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:19,671] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:19,674] INFO [KafkaServer id=1] Controlled shutdown request returned after 11ms with 1 partitions remaining to move (kafka.server.KafkaServer)
[2025-01-16 23:18:19,678] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-16 23:18:19,680] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-16 23:18:22,359] WARN Session 0x10004bc647b000d for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-16 23:18:22,359] WARN Session 0x10004bc647b000b for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
