[2025-01-18 18:52:08,720] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,732] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,732] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,733] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,733] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,735] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-18 18:52:08,736] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-18 18:52:08,736] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-18 18:52:08,736] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-18 18:52:08,737] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-18 18:52:08,738] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,739] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,740] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,740] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,740] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-18 18:52:08,743] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-18 18:52:08,757] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@9353778 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-18 18:52:08,761] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-18 18:52:08,762] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-18 18:52:08,764] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-18 18:52:08,773] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,774] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,774] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,774] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,775] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,775] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,776] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,776] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,777] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,777] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,783] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,784] INFO Server environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,784] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,785] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,785] INFO Server environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,786] INFO Server environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,794] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,796] INFO Server environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,796] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,797] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,797] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,797] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,798] INFO Server environment:user.name=mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,798] INFO Server environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,798] INFO Server environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,798] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,799] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,799] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,799] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,799] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,800] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,800] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,800] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,800] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,801] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,802] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-18 18:52:08,803] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,803] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,804] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-18 18:52:08,805] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-18 18:52:08,806] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-18 18:52:08,806] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-18 18:52:08,807] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-18 18:52:08,807] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-18 18:52:08,807] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-18 18:52:08,807] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-18 18:52:08,811] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,812] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,812] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-18 18:52:08,813] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-18 18:52:08,813] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir .\tmp\zookeeper\version-2 snapdir .\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,819] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-18 18:52:08,820] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-18 18:52:08,821] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-18 18:52:08,856] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-18 18:52:08,875] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-18 18:52:08,876] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-18 18:52:08,877] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-18 18:52:08,878] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-18 18:52:08,882] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-18 18:52:08,889] INFO Reading snapshot .\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2025-01-18 18:52:08,894] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2025-01-18 18:52:08,936] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-18 18:52:08,955] INFO 369 txns loaded in 50 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-18 18:52:08,955] INFO Snapshot loaded in 77 ms, highest zxid is 0x171, digest is 303783861083 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-18 18:52:08,956] INFO Snapshotting: 0x171 to .\tmp\zookeeper\version-2\snapshot.171 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-18 18:52:08,960] INFO Snapshot taken in 4 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:08,968] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-18 18:52:08,968] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-18 18:52:08,984] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-18 18:52:13,405] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:52:13,620] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:52:13,702] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:52:13,704] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:52:13,729] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:13,742] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,743] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,744] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,744] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,745] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,745] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,754] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,756] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,756] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,757] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,757] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,757] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,758] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,758] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,758] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,759] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,759] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,759] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,762] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:13,797] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:52:13,806] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:13,809] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:13,810] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:13,814] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:64132, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:13,820] INFO Creating new log file: log.172 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-18 18:52:13,830] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000e2d56750000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:13,832] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:14,044] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:52:14,100] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:52:14,187] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:14,187] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:14,188] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:14,192] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:14,269] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,297] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:52:14,366] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:52:14,368] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,369] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,370] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:14,383] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 13ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,402] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 99ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,416] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:52:14,417] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,418] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,418] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:14,423] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,427] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 24ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,438] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,450] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 22ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,456] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,459] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,465] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,468] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,472] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,478] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,488] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,492] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,498] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,501] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,506] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,509] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,515] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,517] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,521] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,524] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,543] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:52:14,544] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,545] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 12 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,545] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=12, file=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000012.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:14,552] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 12 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,555] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=12) with 1 segments, local-log-start-offset 0 and log-end-offset 12 in 30ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,560] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,563] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,568] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,571] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,577] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,580] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,586] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,588] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,596] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,599] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,603] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,606] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,612] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:14,615] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:52:14,618] INFO Loaded 19 logs in 348ms (kafka.log.LogManager)
[2025-01-18 18:52:14,622] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:52:14,623] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:52:14,696] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:14,718] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:14,750] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:52:14,832] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:15,228] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:52:15,253] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:52:15,259] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:15,282] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,283] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,283] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,284] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,284] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,298] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:15,302] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:15,352] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:15,374] INFO Stat of the created znode at /brokers/ids/0 is: 385,385,1737201135366,1737201135366,1,0,0,72073181924753408,202,0,385
 (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:15,376] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 385 (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:15,423] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,434] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,435] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,455] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:15,466] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:15,502] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:52:15,506] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:52:15,506] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:52:15,576] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:15,619] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:52:15,647] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-18 18:52:15,650] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-18 18:52:15,654] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:52:15,655] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:52:15,655] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:52:15,656] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:52:15,661] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:15,662] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:15,662] INFO Kafka startTimeMs: 1737201135656 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:15,665] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-18 18:52:16,298] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:52:16,520] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:52:16,605] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:52:16,606] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:52:16,632] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:16,636] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,637] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,637] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,637] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,637] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,638] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,647] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,649] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,650] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,650] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,650] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,650] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,651] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,651] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,651] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,651] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,652] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,652] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,654] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:16,690] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:52:16,697] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:16,699] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:16,700] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:16,703] INFO Socket connection established, initiating session, client: /127.0.0.1:64134, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:16,708] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000e2d56750001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:16,712] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:16,924] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:52:17,018] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:52:17,116] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:17,116] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:17,117] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:17,120] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:17,189] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,212] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:52:17,326] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000002.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:52:17,329] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,330] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,331] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:17,348] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 17ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,363] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 145ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,389] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000001.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:52:17,390] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,391] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,391] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:17,402] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 11ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,406] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 41ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,415] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,421] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 14ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,431] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,435] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,442] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,447] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,454] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,457] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,465] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,468] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,474] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,479] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,487] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,490] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,498] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,505] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 13ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,517] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,520] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,529] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,532] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,538] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,542] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,549] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,552] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,559] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,562] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,567] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:52:17,567] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,570] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,578] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,581] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,587] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,590] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,596] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:17,599] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:17,604] INFO Loaded 19 logs in 414ms (kafka.log.LogManager)
[2025-01-18 18:52:17,607] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:52:17,609] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:52:17,681] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:17,698] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:17,717] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:52:17,742] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:17,863] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:52:18,005] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:52:18,006] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:52:18,075] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:18,088] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,089] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,089] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,090] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,091] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,092] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,114] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,117] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,118] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,119] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,119] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,119] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,120] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,121] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,121] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,122] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,122] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,122] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,129] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,176] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:52:18,184] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:18,185] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:18,186] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:18,188] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:64136, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:18,196] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000e2d56750002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:18,200] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:18,296] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:52:18,320] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:52:18,325] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,354] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,355] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,356] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,357] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,358] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,373] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:18,373] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:18,438] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:18,459] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '0x1000bbcd1310004' does not match current session '0x1000e2d56750001' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2025-01-18 18:52:18,465] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:18,469] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:52:18,469] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:52:18,471] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:52:18,476] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:18,485] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:52:18,489] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-18 18:52:18,490] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:18,491] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:18,492] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:18,494] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:18,496] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:18,497] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:52:18,498] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:52:18,498] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,499] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,499] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,501] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,502] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,502] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,503] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,503] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,503] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,504] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,505] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,505] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,506] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,507] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,507] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:18,516] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:18,516] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:18,516] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:18,518] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-18 18:52:18,519] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,519] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,519] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,521] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:52:18,522] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,523] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,523] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:18,525] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:52:18,529] INFO Shutting down. (kafka.log.LogManager)
[2025-01-18 18:52:18,536] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:18,540] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:18,540] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:18,559] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:52:18,654] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,655] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,656] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,660] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,701] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-18 18:52:18,705] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:18,706] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:18,706] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:18,710] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:18,729] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,759] INFO Skipping recovery of 18 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:52:18,828] INFO Session: 0x1000e2d56750001 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:18,828] INFO EventThread shut down for session: 0x1000e2d56750001 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:18,829] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:18,830] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,832] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,832] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,833] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,833] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,833] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,834] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,834] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,834] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,835] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,836] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,836] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:18,837] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-18 18:52:18,851] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000002.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:52:18,854] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,855] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,855] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:18,857] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-18 18:52:18,858] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:52:18,859] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:52:18,861] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-18 18:52:18,864] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:18,865] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-18 18:52:18,865] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:18,867] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:52:18,867] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 12ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,880] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 113ms (1/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,887] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,887] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,888] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:18,889] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,892] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 11ms (2/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,899] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,903] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-11, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (3/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,909] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,912] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-14, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (4/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,920] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,923] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-17, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (5/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,929] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,931] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-2, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (6/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,936] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,939] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-20, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (7/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,946] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,949] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-23, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (8/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,954] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,957] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-26, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (9/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,964] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,966] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-29, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (10/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,971] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,974] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-32, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (11/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,982] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,984] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-35, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (12/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:18,990] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:18,994] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-38, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (13/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:19,002] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:19,006] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-41, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (14/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:19,015] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:19,020] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-44, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (15/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:19,029] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:19,032] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-47, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (16/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:19,039] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:19,044] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-5, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (17/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:19,053] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:19,060] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-8, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (18/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:19,066] INFO Loaded 18 logs in 335ms (kafka.log.LogManager)
[2025-01-18 18:52:19,070] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:52:19,071] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:52:19,163] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:19,187] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:19,205] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:52:19,246] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,690] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:52:19,719] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:52:19,726] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,769] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,770] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,770] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,771] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,772] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,788] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:19,788] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:19,880] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:19,898] ERROR Error while creating ephemeral at /brokers/ids/2, node already exists and owner '0x1000bbcd1310005' does not match current session '0x1000e2d56750002' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2025-01-18 18:52:19,905] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:19,909] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:52:19,912] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:52:19,915] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:19,925] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:52:19,927] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2025-01-18 18:52:19,928] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:19,929] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:19,929] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:19,930] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:19,931] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:19,932] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:52:19,932] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:52:19,932] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,933] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,933] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,934] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,935] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,935] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,936] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,936] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,937] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,937] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,938] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,938] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,939] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,939] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,939] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:19,946] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:19,947] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:19,947] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:19,948] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2025-01-18 18:52:19,949] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,949] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,949] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,950] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:52:19,951] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,952] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,952] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:19,952] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:52:19,953] INFO Shutting down. (kafka.log.LogManager)
[2025-01-18 18:52:19,954] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:19,956] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:19,956] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:20,073] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-18 18:52:20,078] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:20,079] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:20,079] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:20,081] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:20,198] INFO Session: 0x1000e2d56750002 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:20,198] INFO EventThread shut down for session: 0x1000e2d56750002 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:20,199] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:20,199] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,201] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,201] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,202] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,202] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,202] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,203] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,203] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,203] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,204] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,205] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,205] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:20,206] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2025-01-18 18:52:20,232] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2025-01-18 18:52:20,233] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:52:20,233] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:52:20,236] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-18 18:52:20,242] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:20,243] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2025-01-18 18:52:20,244] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:20,247] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:52:24,576] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:52:24,772] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:52:24,850] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:52:24,851] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:52:24,880] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:24,885] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,885] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,886] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,886] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,886] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,887] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,896] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,897] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,898] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,898] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,898] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,898] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,899] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,899] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,899] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,899] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,900] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,900] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,902] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:24,934] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:52:24,940] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:24,943] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:24,943] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:24,945] INFO Socket connection established, initiating session, client: /127.0.0.1:64145, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:24,952] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000e2d56750003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:24,955] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:25,168] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:52:25,220] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:52:25,276] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:25,276] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:25,277] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:25,279] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:25,327] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,338] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:52:25,404] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,406] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,406] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:25,415] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,428] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 84ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,434] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,435] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,435] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:25,436] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,438] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 8ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,442] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,445] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,449] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,451] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,454] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,456] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,460] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,462] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,464] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,466] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,469] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,471] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,475] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,477] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,480] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,482] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,485] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,486] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,489] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,491] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,495] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,496] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,499] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,500] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,503] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,504] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,508] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,510] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,513] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,514] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,517] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,518] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,521] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:25,522] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:25,526] INFO Loaded 19 logs in 198ms (kafka.log.LogManager)
[2025-01-18 18:52:25,528] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:52:25,529] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:52:25,600] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:25,618] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:25,633] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:52:25,678] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,110] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:52:26,132] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:52:26,136] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,165] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,166] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,166] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,167] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,167] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,179] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:26,180] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:26,232] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:26,248] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '0x1000bbcd1310004' does not match current session '0x1000e2d56750003' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2025-01-18 18:52:26,253] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:26,257] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:52:26,259] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:52:26,262] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:26,269] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:52:26,271] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-18 18:52:26,272] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:26,273] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:26,273] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:26,274] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:26,275] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:26,276] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:52:26,277] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:52:26,277] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,278] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,278] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,279] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,280] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,280] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,280] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,281] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,281] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,282] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,282] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,282] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,283] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,283] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,283] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:26,289] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:26,289] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:26,289] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:26,292] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-18 18:52:26,293] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,293] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,293] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,294] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:52:26,295] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,295] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,295] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:26,296] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:52:26,296] INFO Shutting down. (kafka.log.LogManager)
[2025-01-18 18:52:26,298] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:26,299] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:26,299] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:26,430] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-18 18:52:26,433] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:26,433] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:26,433] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:26,435] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:26,540] INFO Session: 0x1000e2d56750003 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:26,540] INFO EventThread shut down for session: 0x1000e2d56750003 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:26,541] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:26,541] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,543] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,543] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,543] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,544] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,544] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,544] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,545] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,545] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,545] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,545] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,545] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:26,546] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-18 18:52:26,560] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-18 18:52:26,561] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:52:26,561] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:52:26,562] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-18 18:52:26,565] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:26,566] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-18 18:52:26,566] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-18 18:52:26,568] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:52:29,686] INFO Expiring session 0x1000bbcd1310004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:29,688] INFO Expiring session 0x1000bbcd1310005, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-18 18:52:29,942] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:29,965] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,966] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,967] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,968] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,968] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,969] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,970] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,970] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 3 (kafka.cluster.Partition)
[2025-01-18 18:52:29,971] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,972] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,978] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 12 (kafka.cluster.Partition)
[2025-01-18 18:52:29,979] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:29,979] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,986] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,987] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,989] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,990] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,992] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,993] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:29,994] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 3 (kafka.cluster.Partition)
[2025-01-18 18:52:30,031] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:30,099] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,100] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,102] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,103] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,104] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,104] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,105] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,106] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,107] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,107] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,108] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,110] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,110] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,111] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,111] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,112] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 10 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,113] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,114] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,115] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,116] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,116] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,117] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,117] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,119] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 11 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,119] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,120] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,121] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,122] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,122] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 11 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,124] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,125] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,127] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,132] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,141] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,125] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,142] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,145] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,187] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-8c68ed87-7ab9-4479-b90e-c53ab1aaba19, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-18 18:52:30,220] INFO [GroupCoordinator 0]: Loading group metadata for kafka-sandbox with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:30,228] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 111 milliseconds for epoch 4, of which 27 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,229] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 110 milliseconds for epoch 4, of which 110 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 111 milliseconds for epoch 4, of which 111 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,235] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 109 milliseconds for epoch 4, of which 109 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,236] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 104 milliseconds for epoch 4, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 96 milliseconds for epoch 4, of which 96 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 96 milliseconds for epoch 4, of which 96 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:30,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 92 milliseconds for epoch 4, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:34,254] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:52:34,467] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:52:34,558] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:52:34,559] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:52:34,580] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:34,584] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,585] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,586] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,586] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,586] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,587] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,596] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,598] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,598] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,598] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,598] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,599] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,599] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,599] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,599] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,599] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,600] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,600] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,602] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:34,634] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:52:34,640] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:34,642] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:34,643] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:34,646] INFO Socket connection established, initiating session, client: /127.0.0.1:64150, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:34,651] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000e2d56750004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:34,654] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:34,845] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:52:34,889] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:52:34,974] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:34,974] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:34,976] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:34,978] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:35,034] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,057] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:52:35,115] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,116] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,116] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:35,125] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,136] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 72ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,143] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,144] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,144] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:35,145] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,147] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,150] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,153] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,157] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,159] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,162] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,164] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,167] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,169] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,173] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,175] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,179] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,180] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,183] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,185] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,188] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,191] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,195] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,196] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,200] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,201] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,204] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,206] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,210] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,212] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,215] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,216] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,221] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,223] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,226] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,228] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,231] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,232] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,235] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:35,236] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:52:35,240] INFO Loaded 19 logs in 205ms (kafka.log.LogManager)
[2025-01-18 18:52:35,242] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:52:35,243] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:52:35,319] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:35,334] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:35,349] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:52:35,371] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:35,787] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:52:35,820] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:52:35,827] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:35,848] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,848] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,849] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,849] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,850] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,862] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:35,863] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:35,912] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:35,927] INFO Stat of the created znode at /brokers/ids/1 is: 509,509,1737201155920,1737201155920,1,0,0,72073181924753412,202,0,509
 (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:35,928] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 509 (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:35,936] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:35,940] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:35,942] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:35,973] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:35,986] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,995] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:52:35,997] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,998] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:35,998] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=1, host=127.0.0.1:9093),5,3)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:36,003] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,004] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,005] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,006] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 127.0.0.1:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:109)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:52:36,011] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={kafka-chat-0=PartitionData(topicId=khLWI56kRUSmMzowhsIXZA, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[2])}, isolationLevel=read_uncommitted, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 127.0.0.1:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:109)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:52:36,025] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,060] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,061] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,063] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,062] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,095] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:52:36,099] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:52:36,099] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:52:36,147] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:36,179] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,180] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,181] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:36,185] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:52:36,214] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-18 18:52:36,216] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-18 18:52:36,219] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:52:36,220] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:52:36,221] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:52:36,222] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:52:36,227] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:36,228] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:36,228] INFO Kafka startTimeMs: 1737201156222 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:36,231] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-18 18:52:36,352] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:36,384] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:36,397] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,398] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,399] INFO [Partition kafka-chat-2 broker=1] Log loaded for partition kafka-chat-2 with initial high watermark 2 (kafka.cluster.Partition)
[2025-01-18 18:52:36,400] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,400] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,401] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,401] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,402] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,402] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,403] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,403] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,404] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,404] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,405] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,405] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,406] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,407] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,407] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:36,408] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 4 (kafka.cluster.Partition)
[2025-01-18 18:52:36,427] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, kafka-chat-2, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, kafka-chat-0, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:36,495] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,496] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,497] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,498] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,498] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,499] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,499] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,500] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,500] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,501] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,501] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,502] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,502] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,503] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,503] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,503] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,504] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 6 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,504] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,505] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 6 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,505] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,506] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 6 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,506] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,508] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 7 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,508] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,509] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 7 milliseconds for epoch 4, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,509] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,510] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 7 milliseconds for epoch 4, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,511] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 6 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,512] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,513] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 3 milliseconds for epoch 4, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,514] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 2 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,515] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,516] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,517] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,517] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,517] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,518] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,518] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,519] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,520] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,520] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,522] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:36,522] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,522] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:36,524] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:37,128] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,0  and version updated to 8 (kafka.cluster.Partition)
[2025-01-18 18:52:39,431] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:52:39,645] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:52:39,725] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:52:39,726] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:52:39,751] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:39,757] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,758] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,758] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,758] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,759] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,759] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,769] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,771] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,772] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,772] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,772] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,773] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,773] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,773] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,774] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,774] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,774] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,774] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,777] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:52:39,809] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:52:39,831] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:39,834] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:39,835] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:39,838] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:64159, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:39,846] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000e2d56750005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:52:39,849] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:52:40,031] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:52:40,085] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:52:40,171] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:40,172] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:40,173] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:40,176] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:52:40,239] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,252] INFO Skipping recovery of 18 logs from D:\DA_project\kafka\.\tmp\kafka-logs2 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:52:40,313] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,314] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,315] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=3, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1\00000000000000000003.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:40,330] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 16ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,343] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-1, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments, local-log-start-offset 0 and log-end-offset 3 in 85ms (1/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,349] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,350] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,350] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2\00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:52:40,351] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,353] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\kafka-chat-2, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 8ms (2/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,357] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,360] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-11, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,363] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,365] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-14, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (4/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,369] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,370] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-17, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (5/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,374] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,376] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-2, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,379] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,381] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-20, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (7/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,384] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,386] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-23, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,390] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,392] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-26, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (9/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,395] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,397] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-29, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,400] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,402] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-32, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (11/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,406] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,408] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-35, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (12/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,412] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,413] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-38, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,416] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,418] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-41, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (14/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,421] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,424] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-44, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (15/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,427] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,428] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-47, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,432] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,433] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-5, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (17/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,436] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\DA_project\kafka\.\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:52:40,438] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs2\__consumer_offsets-8, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (18/18 completed in D:\DA_project\kafka\.\tmp\kafka-logs2) (kafka.log.LogManager)
[2025-01-18 18:52:40,442] INFO Loaded 18 logs in 202ms (kafka.log.LogManager)
[2025-01-18 18:52:40,445] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:52:40,446] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:52:40,535] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:52:40,551] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:52:40,566] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:52:40,608] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:41,050] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:52:41,077] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:52:41,098] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:41,118] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,119] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,120] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,120] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,121] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,132] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:52:41,132] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:52:41,182] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:41,196] INFO Stat of the created znode at /brokers/ids/2 is: 545,545,1737201161191,1737201161191,1,0,0,72073181924753413,202,0,545
 (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:41,197] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://127.0.0.1:9094, czxid (broker epoch): 545 (kafka.zk.KafkaZkClient)
[2025-01-18 18:52:41,200] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,201] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,201] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,218] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:41,225] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:52:41,225] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=2, host=127.0.0.1:9094),5,3)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:41,226] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,227] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,228] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,228] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 127.0.0.1:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:109)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:52:41,232] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={kafka-chat-1=PartitionData(topicId=khLWI56kRUSmMzowhsIXZA, fetchOffset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[5], lastFetchedEpoch=Optional[2])}, isolationLevel=read_uncommitted, removed=, replaced=, metadata=(sessionId=INVALID, epoch=INITIAL), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 127.0.0.1:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:109)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:52:41,250] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,257] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,258] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,270] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,281] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,299] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:52:41,302] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:52:41,302] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:52:41,317] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,318] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (/127.0.0.1:9094) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,318] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:52:41,361] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:52:41,399] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:52:41,425] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)
[2025-01-18 18:52:41,428] INFO Awaiting socket connections on 127.0.0.1:9094. (kafka.network.DataPlaneAcceptor)
[2025-01-18 18:52:41,432] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:52:41,432] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:52:41,433] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:52:41,434] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:52:41,441] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:41,442] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:41,442] INFO Kafka startTimeMs: 1737201161434 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:52:41,444] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2025-01-18 18:52:41,533] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:41,574] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,576] INFO [Partition kafka-chat-2 broker=2] Log loaded for partition kafka-chat-2 with initial high watermark 2 (kafka.cluster.Partition)
[2025-01-18 18:52:41,578] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,578] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,579] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,579] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,580] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,580] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,581] INFO [Partition kafka-chat-1 broker=2] Log loaded for partition kafka-chat-1 with initial high watermark 3 (kafka.cluster.Partition)
[2025-01-18 18:52:41,581] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,582] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,582] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,582] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,583] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,583] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,583] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,584] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,584] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:52:41,592] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:41,598] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:52:41,617] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:52:41,620] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=1, host=127.0.0.1:9093),5,2)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:41,636] INFO [Partition kafka-chat-2 broker=1] ISR updated to 1,2  and version updated to 8 (kafka.cluster.Partition)
[2025-01-18 18:52:41,639] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, kafka-chat-1, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:52:41,693] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,694] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,695] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,696] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,696] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,697] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,697] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,697] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,698] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,698] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,699] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,699] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,700] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,700] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 4 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,700] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,700] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,701] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,701] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,701] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,702] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,702] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,703] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,703] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,704] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,704] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,705] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,705] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,707] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 4 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,707] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,707] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 3 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,708] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,708] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,709] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,709] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,710] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,711] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,711] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,711] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,712] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,712] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,712] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,713] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,713] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,713] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,714] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:52:41,715] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,715] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:41,716] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:52:42,271] INFO [Partition kafka-chat-1 broker=2] ISR updated to 2,0  and version updated to 8 (kafka.cluster.Partition)
[2025-01-18 18:53:15,249] INFO [GroupCoordinator 0]: Member consumer-kafka-sandbox-1-8c68ed87-7ab9-4479-b90e-c53ab1aaba19 in group kafka-sandbox has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:53:15,261] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: removing member consumer-kafka-sandbox-1-8c68ed87-7ab9-4479-b90e-c53ab1aaba19 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:53:15,267] INFO [GroupCoordinator 0]: Group kafka-sandbox with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:54:55,581] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group kafka-sandbox in Empty state. Created a new member id consumer-kafka-sandbox-1-86f2f074-41da-4e95-900a-ebe22581a990 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:54:55,589] INFO [GroupCoordinator 0]: Preparing to rebalance group kafka-sandbox in state PreparingRebalance with old generation 2 (__consumer_offsets-34) (reason: Adding new member consumer-kafka-sandbox-1-86f2f074-41da-4e95-900a-ebe22581a990 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:54:55,594] INFO [GroupCoordinator 0]: Stabilized group kafka-sandbox generation 3 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:54:55,606] INFO [GroupCoordinator 0]: Assignment received from leader consumer-kafka-sandbox-1-86f2f074-41da-4e95-900a-ebe22581a990 for group kafka-sandbox for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:56:42,279] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:56:42,281] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-18 18:56:42,295] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:56:42,295] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:56:42,296] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:56:42,296] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:56:42,298] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2025-01-18 18:56:42,300] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:56:42,301] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,302] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:56:42,302] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 471 due to node 2 being disconnected (elapsed time since creation: 159ms, elapsed time since send: 159ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,302] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:56:42,302] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:56:42,303] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=153451230, epoch=471) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:56:42,303] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:56:42,305] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:56:42,305] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:56:42,307] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:56:42,308] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,309] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,308] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,308] INFO [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,309] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,309] INFO [Controller id=0, targetBrokerId=0] Cancelled in-flight STOP_REPLICA request with correlation id 20 due to node 0 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,309] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 482 due to node 1 being disconnected (elapsed time since creation: 260ms, elapsed time since send: 260ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,312] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=13215920, epoch=482) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:56:42,312] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:56:42,312] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,314] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:56:42,314] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:56:42,315] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-18 18:56:42,317] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:56:42,317] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:56:42,318] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-18 18:56:42,319] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,319] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,319] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,321] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-18 18:56:42,321] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,322] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,322] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,323] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:56:42,324] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-18 18:56:42,325] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:56:42,325] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:56:42,325] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:56:42,327] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:56:42,327] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:56:42,328] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,329] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,329] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,329] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,330] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,330] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,330] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:56:42,331] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-18 18:56:42,332] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:56:42,332] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:56:42,332] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:56:42,332] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:56:42,333] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:56:42,334] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:56:42,334] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:56:42,334] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,335] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,335] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,335] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,336] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,336] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,336] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,337] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,337] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,337] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,337] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,337] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,338] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,338] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,338] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:56:42,343] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:56:42,344] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:56:42,344] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:56:42,345] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-18 18:56:42,345] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:56:42,345] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:56:42,345] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:56:42,346] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:56:42,347] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:56:42,347] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:56:42,347] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:56:42,348] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:56:42,348] INFO Shutting down. (kafka.log.LogManager)
[2025-01-18 18:56:42,349] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:56:42,349] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:56:42,349] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:56:42,401] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 5 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:56:42,418] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,419] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,420] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,421] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 17 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:56:42,429] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 4 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:56:42,467] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-18 18:56:42,471] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:56:42,476] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:56:42,477] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:56:42,477] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:56:42,478] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:56:42,586] INFO Session: 0x1000e2d56750000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:56:42,586] INFO EventThread shut down for session: 0x1000e2d56750000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:56:42,588] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:56:42,588] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,591] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,592] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,593] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,594] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,594] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,595] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,596] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,596] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,597] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,597] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,597] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:56:42,600] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-18 18:56:42,616] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-18 18:56:42,618] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:56:42,618] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:56:42,618] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:56:42,620] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-18 18:56:42,621] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:56:42,621] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-18 18:57:57,454] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:57:57,643] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:57:57,724] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:57:57,724] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:57:57,749] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:57:57,758] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,759] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,760] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,761] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,761] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,761] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,772] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,774] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,774] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,774] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,774] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,776] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,776] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,777] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,777] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,777] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,777] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,778] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,780] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:57:57,812] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:57:57,818] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:57:57,820] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:57:57,821] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:57:57,823] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:64626, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:57:57,828] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000e2d56750006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:57:57,831] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:57:58,004] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:57:58,047] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:57:58,125] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:57:58,125] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:57:58,126] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:57:58,128] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:57:58,183] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,197] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:57:58,254] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:57:58,256] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,257] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,257] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=5, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000005.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:57:58,266] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 5 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,276] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5) with 1 segments, local-log-start-offset 0 and log-end-offset 5 in 71ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,282] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000003.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:57:58,283] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,284] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,284] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:57:58,285] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,287] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,291] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,294] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,300] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,302] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,306] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,308] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,312] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,315] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,320] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,322] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,325] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,327] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,333] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,335] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,339] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,341] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,345] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,347] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,352] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000012.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:57:58,353] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 17 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,353] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,354] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=17, file=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000017.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:57:58,355] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 17 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,356] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17) with 1 segments, local-log-start-offset 0 and log-end-offset 17 in 7ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,360] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,362] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,366] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,368] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,372] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,373] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,377] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,378] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,384] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,386] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,389] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,391] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,394] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:57:58,396] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:57:58,404] INFO Loaded 19 logs in 219ms (kafka.log.LogManager)
[2025-01-18 18:57:58,408] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:57:58,409] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:57:58,479] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:57:58,496] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:57:58,508] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:57:58,532] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:57:58,936] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:57:58,960] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:57:58,966] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:57:58,985] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:58,986] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:58,987] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:58,987] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:58,988] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:58,999] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:57:58,999] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:57:59,048] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:57:59,061] INFO Stat of the created znode at /brokers/ids/0 is: 604,604,1737201479056,1737201479056,1,0,0,72073181924753414,202,0,604
 (kafka.zk.KafkaZkClient)
[2025-01-18 18:57:59,062] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 604 (kafka.zk.KafkaZkClient)
[2025-01-18 18:57:59,070] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,071] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,072] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,111] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:59,121] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:59,121] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:59,138] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,146] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,167] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:57:59,171] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:57:59,171] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:57:59,181] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,182] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,183] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,238] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:57:59,278] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:57:59,288] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,288] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,289] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,305] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-18 18:57:59,307] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-18 18:57:59,310] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:57:59,311] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:57:59,311] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:57:59,312] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:57:59,316] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:57:59,316] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:57:59,317] INFO Kafka startTimeMs: 1737201479312 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:57:59,319] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-18 18:57:59,476] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,477] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,477] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,478] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,478] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,478] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,479] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,481] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 4 (kafka.cluster.Partition)
[2025-01-18 18:57:59,483] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,483] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,484] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 17 (kafka.cluster.Partition)
[2025-01-18 18:57:59,484] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,485] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,485] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,485] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,486] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,486] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,487] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:57:59,487] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 5 (kafka.cluster.Partition)
[2025-01-18 18:57:59,488] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:57:59,505] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:57:59,509] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:57:59,511] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=2, host=127.0.0.1:9094),6,4)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:57:59,518] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=1, host=127.0.0.1:9093),6,5)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:57:59,518] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:57:59,521] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:57:59,555] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:57:59,562] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,562] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Client requested disconnect from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:57:59,562] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:57:59,562] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:57:59,584] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,0  and version updated to 10 (kafka.cluster.Partition)
[2025-01-18 18:57:59,590] INFO [Partition kafka-chat-1 broker=2] ISR updated to 2,0  and version updated to 10 (kafka.cluster.Partition)
[2025-01-18 18:57:59,624] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,625] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,626] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,627] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,628] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,628] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,628] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,629] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,630] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,631] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,631] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 5 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,632] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,634] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,634] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,635] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,635] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,635] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,637] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 8 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,637] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,638] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 8 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,638] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,639] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 8 milliseconds for epoch 6, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,639] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,640] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,640] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,642] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,643] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,643] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,643] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,644] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,644] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,645] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,645] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,646] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,647] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,648] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,648] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,666] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-8c68ed87-7ab9-4479-b90e-c53ab1aaba19, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-18 18:57:59,673] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-86f2f074-41da-4e95-900a-ebe22581a990, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-18 18:57:59,676] INFO [GroupCoordinator 0]: Loading group metadata for kafka-sandbox with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:57:59,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 42 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,683] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 41 milliseconds for epoch 6, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,684] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 41 milliseconds for epoch 6, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,685] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 41 milliseconds for epoch 6, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,686] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 41 milliseconds for epoch 6, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 41 milliseconds for epoch 6, of which 41 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,688] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 40 milliseconds for epoch 6, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:57:59,688] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 39 milliseconds for epoch 6, of which 39 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:17,575] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:58:17,576] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-18 18:58:17,591] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:17,592] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:17,593] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:17,595] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2025-01-18 18:58:17,596] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:17,598] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:17,598] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:17,601] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:17,601] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:17,602] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:17,602] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:17,602] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:17,603] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:58:17,604] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:17,605] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1052820659, epoch=37) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:58:17,610] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:17,611] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:17,614] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:58:17,616] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-18 18:58:17,618] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-18 18:58:17,623] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,624] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,624] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,626] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-18 18:58:17,627] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,628] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,628] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,631] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:58:17,632] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-18 18:58:17,632] INFO [TxnMarkerSenderThread-1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:17,632] INFO [TxnMarkerSenderThread-1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:17,632] INFO [TxnMarkerSenderThread-1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:17,634] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:58:17,635] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:17,636] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,637] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,637] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,637] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,638] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,638] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,639] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:17,639] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2025-01-18 18:58:17,640] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:17,640] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:17,640] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:17,641] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:17,642] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:17,642] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:58:17,643] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:58:17,643] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,643] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,643] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,645] INFO [ExpirationReaper-1-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,646] INFO [ExpirationReaper-1-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,646] INFO [ExpirationReaper-1-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,647] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,648] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,648] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,649] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,649] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,649] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,650] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,650] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,650] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:17,655] INFO [AddPartitionsToTxnSenderThread-1]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:17,655] INFO [AddPartitionsToTxnSenderThread-1]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:17,655] INFO [AddPartitionsToTxnSenderThread-1]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:17,656] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2025-01-18 18:58:17,656] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:17,657] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:17,657] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:17,658] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:58:17,659] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:17,659] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:17,659] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:17,660] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:58:17,661] INFO Shutting down. (kafka.log.LogManager)
[2025-01-18 18:58:17,662] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:17,663] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:17,663] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:17,718] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 45 with 2 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:17,727] INFO [ProducerStateManager partition=kafka-chat-2] Wrote producer snapshot at offset 43 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:17,781] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-18 18:58:17,786] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:17,787] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:17,787] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:17,788] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:17,894] INFO Session: 0x1000e2d56750004 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:17,894] INFO EventThread shut down for session: 0x1000e2d56750004 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:17,897] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:17,898] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,900] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,900] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,901] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,901] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,901] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,902] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,903] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,903] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,903] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,903] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,903] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:17,904] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2025-01-18 18:58:17,914] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2025-01-18 18:58:17,915] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:58:17,916] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:58:17,916] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:58:17,918] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-18 18:58:17,918] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:58:17,919] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2025-01-18 18:58:42,674] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:58:42,884] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:58:42,963] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:58:42,964] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:58:42,986] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:42,990] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:42,991] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:42,992] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:42,992] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:42,992] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:42,993] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,001] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,003] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,003] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,003] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,004] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,004] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,004] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,004] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,005] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,005] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,005] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,005] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,007] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:43,038] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:58:43,045] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:43,047] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:43,048] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:43,050] INFO Socket connection established, initiating session, client: /127.0.0.1:64657, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:43,055] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000e2d56750007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:43,059] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:43,248] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:58:43,304] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:58:43,362] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:43,362] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:43,363] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:43,365] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:43,410] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,422] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs1 since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:58:43,484] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:58:43,486] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 45 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,487] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 45 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,487] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=45, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0\00000000000000000045.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:43,495] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 45 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,506] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=45) with 1 segments, local-log-start-offset 0 and log-end-offset 45 in 77ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,513] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000002.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:58:43,513] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 43 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,514] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Reloading from producer snapshot and rebuilding producer state from offset 43 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,515] INFO [ProducerStateManager partition=kafka-chat-2] Loading producer state from snapshot file 'SnapshotFile(offset=43, file=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2\00000000000000000043.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:43,516] INFO [LogLoader partition=kafka-chat-2, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 43 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,518] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\kafka-chat-2, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=43) with 1 segments, local-log-start-offset 0 and log-end-offset 43 in 10ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,523] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,527] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-0, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,532] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,534] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-12, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,539] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,542] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-15, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,546] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,548] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-18, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,551] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,553] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-21, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,557] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,560] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-24, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,564] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,566] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-27, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,570] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,572] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-3, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,577] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,578] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-30, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,582] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,583] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-33, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,587] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,588] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-36, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,593] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,595] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-39, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,598] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,600] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-42, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,603] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,604] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-45, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,609] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,611] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-48, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,615] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,616] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-6, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,619] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\DA_project\kafka\.\tmp\kafka-logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:58:43,621] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs1\__consumer_offsets-9, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs1) (kafka.log.LogManager)
[2025-01-18 18:58:43,624] INFO Loaded 19 logs in 213ms (kafka.log.LogManager)
[2025-01-18 18:58:43,628] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:58:43,628] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:58:43,694] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:43,712] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:43,728] INFO [MetadataCache brokerId=1] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:58:43,752] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:44,154] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:58:44,174] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:58:44,181] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:44,200] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,201] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,201] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,202] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,202] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,214] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:44,214] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:44,260] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:58:44,274] INFO Stat of the created znode at /brokers/ids/1 is: 659,659,1737201524268,1737201524268,1,0,0,72073181924753415,202,0,659
 (kafka.zk.KafkaZkClient)
[2025-01-18 18:58:44,275] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://127.0.0.1:9093, czxid (broker epoch): 659 (kafka.zk.KafkaZkClient)
[2025-01-18 18:58:44,278] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,279] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,280] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,323] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,331] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,331] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,346] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,355] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,375] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:58:44,378] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:44,378] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:58:44,387] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,387] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,388] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,438] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:44,472] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:44,494] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,495] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (/127.0.0.1:9093) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,495] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-01-18 18:58:44,496] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:44,498] INFO Awaiting socket connections on 127.0.0.1:9093. (kafka.network.DataPlaneAcceptor)
[2025-01-18 18:58:44,501] INFO [KafkaServer id=1] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:58:44,502] INFO [KafkaServer id=1] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:58:44,503] INFO [KafkaServer id=1] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:58:44,503] INFO [KafkaServer id=1] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:58:44,508] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:58:44,508] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:58:44,509] INFO Kafka startTimeMs: 1737201524504 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:58:44,511] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2025-01-18 18:58:44,688] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,689] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,692] INFO [Partition kafka-chat-2 broker=1] Log loaded for partition kafka-chat-2 with initial high watermark 43 (kafka.cluster.Partition)
[2025-01-18 18:58:44,694] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,695] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,695] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,695] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,696] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,696] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,697] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,697] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,698] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,698] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,699] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,699] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,700] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,700] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,700] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:58:44,701] INFO [Partition kafka-chat-0 broker=1] Log loaded for partition kafka-chat-0 with initial high watermark 45 (kafka.cluster.Partition)
[2025-01-18 18:58:44,702] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-2) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:44,723] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:44,726] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(kafka-chat-2 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=2, host=127.0.0.1:9094),6,43)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:44,727] INFO [zk-broker-1-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:44,727] INFO [zk-broker-1-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:44,731] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=0, host=127.0.0.1:9092),7,45)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:44,731] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:44,766] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:44,772] INFO [Partition kafka-chat-2 broker=2] ISR updated to 2,1  and version updated to 10 (kafka.cluster.Partition)
[2025-01-18 18:58:44,787] INFO [Partition kafka-chat-0 broker=0] ISR updated to 0,1  and version updated to 12 (kafka.cluster.Partition)
[2025-01-18 18:58:44,821] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,822] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,823] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,823] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,824] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,825] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,825] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,826] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,826] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,827] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,827] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,827] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,828] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,829] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,829] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,829] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,830] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,830] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,831] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,831] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,832] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,832] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,833] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 6 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,833] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,833] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 5 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,834] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,834] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 6 milliseconds for epoch 6, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,835] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 6 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,836] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,836] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 4 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,837] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,837] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,838] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 3 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,838] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,839] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,839] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,840] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 2 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,840] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,841] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds for epoch 6, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,842] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,843] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:44,843] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,843] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:44,844] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 6, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:58:47,333] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-18 18:58:47,338] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-18 18:58:47,366] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:47,366] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(kafka-chat-0) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:47,371] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:47,372] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2025-01-18 18:58:47,375] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:47,376] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:47,377] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:47,377] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:58:47,378] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:58:47,379] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,380] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 7 due to node 0 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,385] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,382] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=279091429, epoch=7) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:58:47,386] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:47,386] INFO [Controller id=2, targetBrokerId=0] Cancelled in-flight STOP_REPLICA request with correlation id 18 due to node 0 being disconnected (elapsed time since creation: 10ms, elapsed time since send: 10ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,386] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:47,388] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,389] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:47,390] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(kafka-chat-1) (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:58:47,391] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-18 18:58:47,392] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-18 18:58:47,396] INFO [ReplicaFetcherThread-0-2]: Shutting down (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:47,397] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,397] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 94 due to node 2 being disconnected (elapsed time since creation: 438ms, elapsed time since send: 438ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,398] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=542749802, epoch=94) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:114)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:317)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:130)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:136)
[2025-01-18 18:58:47,401] INFO [ReplicaFetcherThread-0-2]: Stopped (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:47,401] INFO [ReplicaFetcherThread-0-2]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:58:47,402] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-18 18:58:47,404] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,404] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,404] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,406] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-18 18:58:47,406] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,407] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,407] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,410] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:58:47,410] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-18 18:58:47,411] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:47,411] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:47,411] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:58:47,413] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:58:47,413] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:47,414] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,415] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,415] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,416] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,416] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,416] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,418] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:58:47,419] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-18 18:58:47,419] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:47,419] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:47,419] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:58:47,420] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:47,421] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:58:47,421] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:58:47,422] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-18 18:58:47,422] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,422] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,422] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,423] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,424] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,424] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,425] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,426] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,426] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,427] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,427] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,427] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,428] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,428] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,428] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:58:47,432] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:47,433] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:47,433] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:58:47,434] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-18 18:58:47,434] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:47,434] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:47,434] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:47,436] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:58:47,437] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:47,437] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:47,437] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:58:47,438] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-18 18:58:47,438] INFO Shutting down. (kafka.log.LogManager)
[2025-01-18 18:58:47,439] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:47,440] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:47,440] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:58:47,497] INFO [ProducerStateManager partition=kafka-chat-0] Wrote producer snapshot at offset 46 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:47,498] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,499] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,499] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,523] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 24 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:47,534] INFO [ProducerStateManager partition=kafka-chat-1] Wrote producer snapshot at offset 43 with 2 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:58:47,573] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-18 18:58:47,579] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:47,579] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:47,579] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:58:47,581] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:47,585] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:58:47,686] INFO Session: 0x1000e2d56750006 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:47,686] INFO EventThread shut down for session: 0x1000e2d56750006 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:47,689] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:47,690] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,692] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,692] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,693] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,694] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,694] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,694] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,695] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,695] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,695] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,695] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,695] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:58:47,696] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-18 18:58:47,705] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-18 18:58:47,706] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:58:47,706] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:58:47,706] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-18 18:58:47,708] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-18 18:58:47,709] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:58:47,709] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-18 18:58:59,541] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-18 18:58:59,740] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-18 18:58:59,820] INFO starting (kafka.server.KafkaServer)
[2025-01-18 18:58:59,821] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-18 18:58:59,846] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:59,850] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,851] INFO Client environment:host.name=DESKTOP-JN5NMG8 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,851] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,852] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,852] INFO Client environment:java.home=C:\Program Files\Java\jdk-23 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,852] INFO Client environment:java.class.path=D:\DA_project\kafka\libs\activation-1.1.1.jar;D:\DA_project\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\DA_project\kafka\libs\argparse4j-0.7.0.jar;D:\DA_project\kafka\libs\audience-annotations-0.12.0.jar;D:\DA_project\kafka\libs\caffeine-2.9.3.jar;D:\DA_project\kafka\libs\commons-beanutils-1.9.4.jar;D:\DA_project\kafka\libs\commons-cli-1.4.jar;D:\DA_project\kafka\libs\commons-collections-3.2.2.jar;D:\DA_project\kafka\libs\commons-digester-2.1.jar;D:\DA_project\kafka\libs\commons-io-2.14.0.jar;D:\DA_project\kafka\libs\commons-lang3-3.12.0.jar;D:\DA_project\kafka\libs\commons-logging-1.2.jar;D:\DA_project\kafka\libs\commons-validator-1.7.jar;D:\DA_project\kafka\libs\connect-api-3.9.0.jar;D:\DA_project\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\DA_project\kafka\libs\connect-file-3.9.0.jar;D:\DA_project\kafka\libs\connect-json-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-3.9.0.jar;D:\DA_project\kafka\libs\connect-mirror-client-3.9.0.jar;D:\DA_project\kafka\libs\connect-runtime-3.9.0.jar;D:\DA_project\kafka\libs\connect-transforms-3.9.0.jar;D:\DA_project\kafka\libs\error_prone_annotations-2.10.0.jar;D:\DA_project\kafka\libs\hk2-api-2.6.1.jar;D:\DA_project\kafka\libs\hk2-locator-2.6.1.jar;D:\DA_project\kafka\libs\hk2-utils-2.6.1.jar;D:\DA_project\kafka\libs\jackson-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-core-2.16.2.jar;D:\DA_project\kafka\libs\jackson-databind-2.16.2.jar;D:\DA_project\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\DA_project\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\DA_project\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\DA_project\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\DA_project\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\DA_project\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\DA_project\kafka\libs\jakarta.inject-2.6.1.jar;D:\DA_project\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\DA_project\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\DA_project\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\DA_project\kafka\libs\javassist-3.29.2-GA.jar;D:\DA_project\kafka\libs\javax.activation-api-1.2.0.jar;D:\DA_project\kafka\libs\javax.annotation-api-1.3.2.jar;D:\DA_project\kafka\libs\javax.servlet-api-3.1.0.jar;D:\DA_project\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\DA_project\kafka\libs\jaxb-api-2.3.1.jar;D:\DA_project\kafka\libs\jersey-client-2.39.1.jar;D:\DA_project\kafka\libs\jersey-common-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\DA_project\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\DA_project\kafka\libs\jersey-hk2-2.39.1.jar;D:\DA_project\kafka\libs\jersey-server-2.39.1.jar;D:\DA_project\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\DA_project\kafka\libs\jline-3.25.1.jar;D:\DA_project\kafka\libs\jopt-simple-5.0.4.jar;D:\DA_project\kafka\libs\jose4j-0.9.4.jar;D:\DA_project\kafka\libs\jsr305-3.0.2.jar;D:\DA_project\kafka\libs\kafka-clients-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-metadata-3.9.0.jar;D:\DA_project\kafka\libs\kafka-raft-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-3.9.0.jar;D:\DA_project\kafka\libs\kafka-server-common-3.9.0.jar;D:\DA_project\kafka\libs\kafka-shell-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-3.9.0.jar;D:\DA_project\kafka\libs\kafka-storage-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\DA_project\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-3.9.0.jar;D:\DA_project\kafka\libs\kafka-tools-api-3.9.0.jar;D:\DA_project\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\DA_project\kafka\libs\kafka_2.13-3.9.0.jar;D:\DA_project\kafka\libs\lz4-java-1.8.0.jar;D:\DA_project\kafka\libs\maven-artifact-3.9.6.jar;D:\DA_project\kafka\libs\metrics-core-2.2.0.jar;D:\DA_project\kafka\libs\metrics-core-4.1.12.1.jar;D:\DA_project\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-codec-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-handler-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\DA_project\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\DA_project\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\DA_project\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\DA_project\kafka\libs\paranamer-2.8.jar;D:\DA_project\kafka\libs\pcollections-4.0.1.jar;D:\DA_project\kafka\libs\plexus-utils-3.5.1.jar;D:\DA_project\kafka\libs\protobuf-java-3.25.5.jar;D:\DA_project\kafka\libs\reflections-0.10.2.jar;D:\DA_project\kafka\libs\reload4j-1.2.25.jar;D:\DA_project\kafka\libs\rocksdbjni-7.9.2.jar;D:\DA_project\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\DA_project\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\DA_project\kafka\libs\scala-library-2.13.14.jar;D:\DA_project\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\DA_project\kafka\libs\scala-reflect-2.13.14.jar;D:\DA_project\kafka\libs\slf4j-api-1.7.36.jar;D:\DA_project\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\DA_project\kafka\libs\snappy-java-1.1.10.5.jar;D:\DA_project\kafka\libs\swagger-annotations-2.2.8.jar;D:\DA_project\kafka\libs\trogdor-3.9.0.jar;D:\DA_project\kafka\libs\zookeeper-3.8.4.jar;D:\DA_project\kafka\libs\zookeeper-jute-3.8.4.jar;D:\DA_project\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,862] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-23\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\MinGW\bin;C:\Program Files\Git\cmd;D:\Flutter\flutter\bin;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;C:\Program Files\nodejs\;D:\Program\openssl-0.9.8k_WIN32\bin;C:\Program Files\Java\jdk-23\bin;C:\Program Files\Maven\apache-maven-3.9.9\bin;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Python312\;C:\Users\mawjngvux\AppData\Local\Programs\Python\Launcher\;C:\Users\mawjngvux\AppData\Local\Microsoft\WindowsApps;C:\Users\mawjngvux\AppData\Local\Programs\Microsoft VS Code\bin;C:\xampp\php;C:\Users\mawjngvux\AppData\Local\ComposerSetup\bin;C:\Users\mawjngvux\AppData\Roaming\Composer\vendor\bin;C:\xampp\php\php.exe;C:\Users\mawjngvux\AppData\Roaming\npm;C:\Users\mawjngvux\AppData\Local\Pub\Cache\bin;;c:\Users\mawjngvux\AppData\Roaming\Code\User\globalStorage\github.copilot-chat\debugCommand;. (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,863] INFO Client environment:java.io.tmpdir=C:\Users\MAWJNG~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,864] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,864] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,864] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,864] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,864] INFO Client environment:user.name=mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,865] INFO Client environment:user.home=C:\Users\mawjngvux (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,865] INFO Client environment:user.dir=D:\DA_project\kafka (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,865] INFO Client environment:os.memory.free=981MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,865] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,865] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,867] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b7dc788 (org.apache.zookeeper.ZooKeeper)
[2025-01-18 18:58:59,898] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-18 18:58:59,904] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:59,907] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:58:59,908] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:59,910] INFO Socket connection established, initiating session, client: /127.0.0.1:64678, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:59,916] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000e2d56750008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-18 18:58:59,919] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-18 18:59:00,096] INFO Cluster ID = r45TsbmVTQi_1qORhQZKzA (kafka.server.KafkaServer)
[2025-01-18 18:59:00,146] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = ./tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-18 18:59:00,234] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:59:00,234] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:59:00,235] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:59:00,238] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-18 18:59:00,298] INFO Loading logs from log dirs ArrayBuffer(D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,313] INFO Skipping recovery of 19 logs from D:\DA_project\kafka\.\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-18 18:59:00,371] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000005.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:59:00,372] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,374] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,374] INFO [ProducerStateManager partition=kafka-chat-0] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:59:00,382] INFO [LogLoader partition=kafka-chat-0, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,394] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-0, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 75ms (1/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,400] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000004.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:59:00,401] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,401] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 43 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,402] INFO [ProducerStateManager partition=kafka-chat-1] Loading producer state from snapshot file 'SnapshotFile(offset=43, file=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1\00000000000000000043.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:59:00,402] INFO [LogLoader partition=kafka-chat-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 43 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,404] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\kafka-chat-1, topicId=khLWI56kRUSmMzowhsIXZA, topic=kafka-chat, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=43) with 1 segments, local-log-start-offset 0 and log-end-offset 43 in 9ms (2/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,411] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,414] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-1, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (3/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,419] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,421] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-10, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (4/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,428] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,430] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-13, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,434] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,436] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-16, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (6/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,441] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,443] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-19, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (7/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,447] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,449] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-22, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (8/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,453] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,456] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-25, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (9/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,460] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,462] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-28, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (10/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,466] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,468] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-31, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (11/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,474] INFO Deleted producer state snapshot D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000017.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-01-18 18:59:00,475] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,475] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 24 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,476] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'SnapshotFile(offset=24, file=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34\00000000000000000024.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-18 18:59:00,477] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 24 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,479] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-34, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=24) with 1 segments, local-log-start-offset 0 and log-end-offset 24 in 10ms (12/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,485] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,486] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-37, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (13/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,491] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,493] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-4, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (14/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,497] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,498] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-40, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (15/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,502] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,503] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-43, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (16/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,507] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,509] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-46, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (17/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,513] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,514] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-49, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (18/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,519] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\DA_project\kafka\.\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-18 18:59:00,520] INFO Completed load of Log(dir=D:\DA_project\kafka\.\tmp\kafka-logs\__consumer_offsets-7, topicId=d5RXmrD2TvqbHCkJ2YabLw, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (19/19 completed in D:\DA_project\kafka\.\tmp\kafka-logs) (kafka.log.LogManager)
[2025-01-18 18:59:00,524] INFO Loaded 19 logs in 225ms (kafka.log.LogManager)
[2025-01-18 18:59:00,527] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-18 18:59:00,527] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-18 18:59:00,618] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-18 18:59:00,637] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-18 18:59:00,653] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-18 18:59:00,684] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:59:01,177] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-18 18:59:01,198] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-18 18:59:01,203] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:59:01,223] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,224] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,225] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,225] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,226] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,237] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-18 18:59:01,238] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-18 18:59:01,287] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-18 18:59:01,301] INFO Stat of the created znode at /brokers/ids/0 is: 714,714,1737201541296,1737201541296,1,0,0,72073181924753416,202,0,714
 (kafka.zk.KafkaZkClient)
[2025-01-18 18:59:01,302] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://127.0.0.1:9092, czxid (broker epoch): 714 (kafka.zk.KafkaZkClient)
[2025-01-18 18:59:01,304] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,305] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,307] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,358] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,368] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,368] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,386] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,399] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,413] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,414] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,414] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,430] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:59:01,434] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-18 18:59:01,434] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-18 18:59:01,521] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-18 18:59:01,524] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,528] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,531] INFO [Controller id=2, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-18 18:59:01,574] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-18 18:59:01,602] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-18 18:59:01,606] INFO Awaiting socket connections on 127.0.0.1:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-18 18:59:01,612] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:59:01,613] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-18 18:59:01,615] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:59:01,616] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-18 18:59:01,621] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:59:01,621] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:59:01,622] INFO Kafka startTimeMs: 1737201541616 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-18 18:59:01,627] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-18 18:59:01,737] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:59:01,761] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,762] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,763] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,763] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,764] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,764] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,764] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,766] INFO [Partition kafka-chat-1 broker=0] Log loaded for partition kafka-chat-1 with initial high watermark 43 (kafka.cluster.Partition)
[2025-01-18 18:59:01,767] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 127.0.0.1:9094 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-18 18:59:01,768] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,768] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,769] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 24 (kafka.cluster.Partition)
[2025-01-18 18:59:01,769] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,770] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,770] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,771] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,771] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,772] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,773] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-18 18:59:01,774] INFO [Partition kafka-chat-0 broker=0] Log loaded for partition kafka-chat-0 with initial high watermark 46 (kafka.cluster.Partition)
[2025-01-18 18:59:01,776] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(kafka-chat-0, kafka-chat-1) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:59:01,803] INFO [ReplicaFetcherThread-0-2]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:59:01,805] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(kafka-chat-1 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=2, host=127.0.0.1:9094),7,43)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:59:01,810] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(kafka-chat-0 -> InitialFetchState(Some(khLWI56kRUSmMzowhsIXZA),BrokerEndPoint(id=1, host=127.0.0.1:9093),8,46)) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:59:01,810] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2025-01-18 18:59:01,820] INFO [Partition kafka-chat-1 broker=2] ISR updated to 2,0  and version updated to 12 (kafka.cluster.Partition)
[2025-01-18 18:59:01,829] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-18 18:59:01,896] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,897] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,899] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,900] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,901] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,901] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,902] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,902] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,903] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,903] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,904] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,905] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,906] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,908] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 6 milliseconds for epoch 8, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,908] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,910] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 8, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,910] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,912] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 10 milliseconds for epoch 8, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,912] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,913] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds for epoch 8, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,913] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,915] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 11 milliseconds for epoch 8, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,915] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,916] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds for epoch 8, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,917] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,918] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 8 milliseconds for epoch 8, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,918] INFO [Partition kafka-chat-0 broker=1] ISR updated to 1,0  and version updated to 14 (kafka.cluster.Partition)
[2025-01-18 18:59:01,918] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,919] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 6 milliseconds for epoch 8, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,920] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,921] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 4 milliseconds for epoch 8, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,921] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,923] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,924] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,925] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,925] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,926] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,926] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,927] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,927] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,928] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,928] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,929] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,929] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,944] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-8c68ed87-7ab9-4479-b90e-c53ab1aaba19, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2025-01-18 18:59:01,952] INFO Loaded member MemberMetadata(memberId=consumer-kafka-sandbox-1-86f2f074-41da-4e95-900a-ebe22581a990, groupInstanceId=None, clientId=consumer-kafka-sandbox-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group kafka-sandbox with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2025-01-18 18:59:01,956] INFO [GroupCoordinator 0]: Loading group metadata for kafka-sandbox with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2025-01-18 18:59:01,961] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 41 milliseconds for epoch 8, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,962] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 40 milliseconds for epoch 8, of which 40 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,963] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 38 milliseconds for epoch 8, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,964] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 38 milliseconds for epoch 8, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,964] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 37 milliseconds for epoch 8, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 37 milliseconds for epoch 8, of which 37 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,966] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 37 milliseconds for epoch 8, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 18:59:01,966] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 36 milliseconds for epoch 8, of which 36 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-18 19:09:01,854] INFO [NodeToControllerChannelManager id=2 name=alter-partition] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-18 19:09:02,145] INFO [NodeToControllerChannelManager id=1 name=alter-partition] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
